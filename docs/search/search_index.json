{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"a primer on cloud-based maps of landscape change","text":"<p>Jeff Howarth Associate Professor of Geography Middlebury College, Middlebury, Vermont, USA jhowarth@middlebury.edu </p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"introduction/","title":"Introduction","text":"<p>These materials aim to help undergraduate students in Geography and Environmental Studies learn geospatial methods for investigating changes in the global environment. While most of the lessons introduce methods and workflows in Google Earth Engine, I also show students around QGIS and how to move between the two platforms. The ultimate goal of the materials is to help students learn timeless concepts of geospatial analysis that transcend specific software platforms. That is the goal at least.  </p>"},{"location":"intro/gee_gui/","title":"GEE User Interface","text":""},{"location":"intro/gee_gui/#introduction","title":"Introduction","text":"<p>In this course, we will work with Google Earth Engine via the GEE Code Editor. The tutorial below provides an overview of the different components of the Code Editor\u2019s graphical user interface (GUI).   </p>"},{"location":"intro/gee_gui/#tutorial","title":"Tutorial","text":"<p>I split this tutorial into separate videos. If I show code in the video, you can find the snippets below each video.  </p> <p>To follow along with the videos, you will need to open the GEE Code Editor in a web browser. Please see the previous tutorial if you forget how to access the editor. </p>"},{"location":"intro/gee_gui/#explore-the-map-interface","title":"Explore the map interface.","text":""},{"location":"intro/gee_gui/#write-a-header","title":"Write a header.","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Name:     gee_ui.js \n//  Author:   Jeff Howarth\n//  Date:     9/7/2023 \n//  Purpose:  Introduce Earth Engine Graphical User Interface (Code Editor)\n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  \n</code></pre>"},{"location":"intro/gee_gui/#center-map-and-set-zoom-level","title":"Center map and set zoom level.","text":"<pre><code>//  Center and set zoom level the map.\n\nMap.setCenter(\n-50,                  // Longitude\n40,                  // Latitude\n3                    // Zoom level\n)\n;\n</code></pre>"},{"location":"intro/gee_gui/#set-the-default-base-map","title":"Set the default base map.","text":"<pre><code>//  Set the default base map. \n\nMap.setOptions('SATELLITE');\n</code></pre>"},{"location":"intro/gee_gui/#load-lst-module","title":"Load LST module.","text":"<pre><code>//  Load module\n\nvar tool = require('users/jhowarth/eePrimer:modules/modis_lst_demo.js');\n\n// You can then call functions in the module as methods of this object.\n\ntool.makeMap();\n</code></pre>"},{"location":"intro/gee_gui/#inspect-data","title":"Inspect data.","text":"<pre><code>// Print info about map layers. \n\nprint(\"Layers on this map:\", Map.layers());\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.</p>"},{"location":"intro/js101/","title":"Javascript 101","text":""},{"location":"intro/js101/#introduction","title":"Introduction","text":"<p>To use GEE, you will need to write code.    </p> <p>In this course, we will use the GEE Code Editor, which means that we will be coding in JavaScript.    </p>"},{"location":"intro/js101/#tutorial","title":"Tutorial","text":"<p>I made the videos below to help walk you through through some basic JavaScript syntax, data types, and methods. I broke the tutorial into a set of short videos, rather than recording one long one. You should work through all the videos in the set.     </p> <p>To follow along, you will need to open the GEE Code Editor in a web browser.  </p> <p>I recommend that you use Google Chrome when working with the GEE Code Editor.     </p> <p>This is the web address to the Code Editor: </p> <p>https://code.earthengine.google.com/</p> <p>Honestly, you might as well bookmark that page and move the bookmark to the left corner of your toolbar. You will be visiting this site a lot over the semester.  </p> <p>Below the video, you should find snippets for the code shown in the video. If you hover your cursor over the upper-right corner of the snippet, you should see a little button that you can click to copy the code. You can then paste the code into the Code Editor while you watch the video. My intention is to save you some time and reduce errors that come from typos.  </p>"},{"location":"intro/js101/#quick-tour","title":"Quick tour","text":""},{"location":"intro/js101/#new-repo-save-file","title":"New Repo, Save File","text":""},{"location":"intro/js101/#data-types-1","title":"Data types (1)","text":""},{"location":"intro/js101/#line-comment","title":"Line Comment","text":"<pre><code>// This is a line comment. \n</code></pre>"},{"location":"intro/js101/#string","title":"String","text":"<pre><code>'Hello, world'  // Single quotes defines a string. \n</code></pre>"},{"location":"intro/js101/#variable","title":"Variable","text":"<pre><code>// Use var keyword to define a variable to store data. \n\nvar hello = 'Hello, world!' // This variable stores a string. \n</code></pre>"},{"location":"intro/js101/#semi-colon","title":"Semi-colon","text":"<pre><code>// End statements with semi-colons so that the editor does not complain.\n\nvar hello_again = 'Hola Mundo';\n</code></pre>"},{"location":"intro/js101/#double-quotes","title":"Double quotes","text":"<pre><code>// You can also define strings with double quotes. \n\nvar who_dat = \"Who's there?\";\n</code></pre>"},{"location":"intro/js101/#parentheses","title":"Parentheses","text":"<pre><code>// You can pass variables to functions within parentheses. \n\nprint(hello_again);\n</code></pre>"},{"location":"intro/js101/#comma","title":"Comma","text":"<pre><code>// You can pass more than one variable separated by commas.\n\nprint(hello_again, who_dat);\n</code></pre>"},{"location":"intro/js101/#data-types-2","title":"Data types (2)","text":""},{"location":"intro/js101/#number","title":"Number","text":"<pre><code>// This variable stores a number. \n\nvar year = 2023;\n</code></pre>"},{"location":"intro/js101/#list","title":"List","text":"<pre><code>// Square brackets defines a list. \n\nvar some_vt_towns = ['Middlebury', 'New Haven', 'Bristol'];\n</code></pre>"},{"location":"intro/js101/#index","title":"Index","text":"<pre><code>// Use square brackets after list object to call index of items in list.\n\nprint(some_vt_towns, some_vt_towns[0]);\n</code></pre>"},{"location":"intro/js101/#methods","title":"Methods","text":"<pre><code>// Use dot notation to call methods associated with the data type. \n\nprint(some_vt_towns.sort());\n</code></pre>"},{"location":"intro/js101/#data-types-3","title":"Data types (3)","text":""},{"location":"intro/js101/#dictionary","title":"Dictionary","text":"<pre><code>// Use curly brackets (or braces) to define dictionaries. \n\nvar midd = {\n\"name\": \"Middlebury\",  // Dictionaries are composed of key:value pairs.\n\"pop_2010\": 8496,\n\"pop_2020\": 9152\n};\n\nprint('Middlebury', midd);\n</code></pre>"},{"location":"intro/js101/#key-values","title":"Key values","text":"<pre><code>// Use dot notation to call the value of object key.  \n\nprint(midd.name);\n\nprint(\"Population change\", midd.pop_2020 - midd.pop_2010);\n</code></pre>"},{"location":"intro/js101/#data-types-4","title":"Data types (4)","text":""},{"location":"intro/js101/#functions","title":"Functions","text":"<pre><code>// Functions can be defined as a way to reuse code and make it easier to read.  \n\nvar i_love_function = function(some_string) {\nreturn 'I love ' + some_string + '!';\n};\n\nprint(i_love_function('maps'));\n</code></pre>"},{"location":"intro/js101/#modules","title":"Modules","text":"<pre><code>// Modules can be used to share functions across multiple scripts by:\n\n// 1. storing the module as a variable,\n\nvar tool = require('users/jhowarth/eePrimer:modules/tissot.js');\n\n// 2. calling functions in the module as methods of this variable.\n\ntool.drawTissot();\n</code></pre>"},{"location":"intro/js101/#mercator-distortion","title":"Mercator distortion","text":"<p>The True Size of</p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.</p>"},{"location":"intro/qgis_gui/","title":"QGIS User Interface","text":""},{"location":"intro/qgis_gui/#introduction","title":"Introduction","text":"<p>QGIS is a powerful desktop GIS, but also a labyrinth of point-and-clicks. This tutorial provides a very brief introduction to the graphical user interface (GUI).  </p>"},{"location":"intro/qgis_gui/#graphical-user-interface-gui","title":"Graphical User Interface (GUI)","text":""},{"location":"intro/qgis_gui/#working-with-a-project","title":"Working with a Project","text":""},{"location":"intro/qgis_gui/#add-a-google-basemap-layer","title":"Add a Google basemap layer","text":""},{"location":"intro/qgis_gui/#google-satellite","title":"Google satellite","text":"<pre><code>https://mt1.google.com/vt/lyrs=s&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre>"},{"location":"intro/qgis_gui/#google-hybrid","title":"Google hybrid","text":"<pre><code>https://mt1.google.com/vt/lyrs=y&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre>"},{"location":"intro/qgis_gui/#google-terrain","title":"Google terrain","text":"<pre><code>https://mt1.google.com/vt/lyrs=p&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre>"},{"location":"intro/qgis_gui/#google-map","title":"Google map","text":"<pre><code>https://mt1.google.com/vt/lyrs=m&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre>"},{"location":"intro/qgis_gui/#de-emphasized-road-map","title":"De-emphasized road map","text":"<pre><code>https://mt1.google.com/vt/lyrs=r&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.</p>"},{"location":"rudiments/additive_color/","title":"In Additive Color","text":""},{"location":"rudiments/additive_color/#introduction","title":"Introduction","text":"<p>We see color because light enters our eyes. </p> <p>Light often enters our eyes because it reflects off an object\u2019s surface. We see color in the textiles of our clothing, the paint on a wall, the ink in a book, the plastic of a bottle. In all these cases, we see color because objects absorb some parts of the visible spectrum and reflect the difference.  </p> <p>Many people learn how color works by working with one of these materials. As a result, many people think that the primary colors are red, yellow, and blue and secondary colors are made by mixing these primaries: blue and yellow make green, red and yellow make orange, and red and blue make violet. </p> <p>This can make the following fact a little confusing: a computer monitor makes yellow by mixing red and green. </p> <p> <pre><code>graph LR\n  red[\"R\"]  --&gt; yellow[\" Y \"]  \n  green[\" G \"] --&gt; yellow  \n\n  style red fill:#FF0000,stroke-width:0px\n  style green fill:#00FF00,stroke-width:0px\n  style yellow fill:#FFFF00,stroke-width:0px</code></pre> <p></p> <p>This is because computer monitors emit light, rather than reflect it. As a result, computer monitors create color with the additive color system. This is a powerful method for visualizing data in images. This page aims to help you better understand how this color system works. </p>"},{"location":"rudiments/additive_color/#color-blindness","title":"Color blindness","text":"<p>Before we continue, we should first understand that not all people see color the same way. For example, about 6% of men will see the graphic above like this:</p> <p> <p></p> <p></p> <p>This is a common form of red-green color blindness called deuteranopia. I use a little program called Color Oracle to check how colors that I use on maps will look to people with different forms of color blindness in an effort to make information universally accessible. Using additive color to visualize images, however, challenges goals of universal design and some people may have difficulty reading RGB composites or will need to learn how to read them with additional scaffolding. If you know that you see colors differently, or if the two figures above do not look different to you, please be in contact with me so that we can figure out strategies to make this portion of the course accessible to you. Thank you.  </p>"},{"location":"rudiments/additive_color/#first-color-image","title":"First color image","text":"<p>Tartan Ribbon, by Thomas Sutton and James Clerk Maxwell, 1861 </p> <p></p> <p>Tartan Montage, by Celtus, 2008 </p>"},{"location":"rudiments/additive_color/#additive-color-system","title":"Additive color system","text":"<p>In the additive color system, three primary colors (red, green, blue) make three secondary colors (yellow, magenta, and cyan). The absence of all three primaries makes black, while full amounts of the three primaries make white.  </p> <p></p> <p>You can recreate these colors and explore other intermediary colors with the RGB mixer below.  </p> <p> </p>"},{"location":"rudiments/additive_color/#rgb-composites","title":"RGB Composites","text":"<p>Additive color is a powerful method to visualize pixels values across three rasters all at once. The image below shows an example. The image contains three bands that represent the brightness of nighttime lights in three different years (2013, 2003, 1993). For each band, the image displays brightness value with a different color channel; it shows pixel values in the first band (2013) with red, pixel values in the second band (2003) with green, and pixel values in the third band (1993) with blue. The result is called an RGB composite. The order of the bands (1,2,3) determines the colors used to display the band\u2019s pixel values (RGB).   </p> <p></p> <p>Change in nighttime lights 1993 - 2013, Shanghai, China</p>"},{"location":"rudiments/additive_color/#what-are-nighttime-lights","title":"What are nighttime lights?","text":"<p>Night Lights Change in the Middle East </p> <p>Old Night Vision Meets New </p> <p>DMSP OLS </p> <p>VIIRS Nighttime Lights</p> <p></p>"},{"location":"rudiments/additive_color/#workflow-for-image","title":"Workflow for image","text":"<p>The diagram below outlines how I used additive color to show changes in the DMSP OLS dataset with Earth Engine.  </p> <p></p>"},{"location":"rudiments/additive_color/#exploring-additive-color","title":"Exploring additive color","text":"<p>You can use the app below to explore this RGB composite and become more familiar with how additive color works as a method for visualizing geographic change.   </p> <p> </p> <p>Link to app </p>"},{"location":"rudiments/additive_color/#temporal-scale-and-change","title":"Temporal scale and change","text":"<p>You can also use the app to think a little about how the temporal scale of the change image may influence the kinds of change that you can see.   </p> <p> Temporal Concepts Changes in the Night image Value Average brightness of stable lights Resolution 1 year Interval 10 years Extent 20 years <p> </p> <p>What do the different visual patterns (Holiday Lights, Aurora, Heat, and Red Giant) tell you about the temporal characteristics of the physical changes to the Earth\u2019s surface?</p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"rudiments/hello_feature_collection/","title":"Hello Feature Collection","text":""},{"location":"rudiments/hello_feature_collection/#introduction","title":"Introduction","text":"<p>The videos below introduce geometry and feature objects in Google Earth Engine. They walk you through how to import a table as an asset, how to construct a feature from scratch in the Code Editor, and how to convert vector into raster in Earth Engine.  </p>"},{"location":"rudiments/hello_feature_collection/#start-a-new-script","title":"Start a new script","text":"<pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Hello Feature Collection\n//\n//  Jeff Howarth \n//  Geography 251\n//\n//  Oct 1, 2023\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre>"},{"location":"rudiments/hello_feature_collection/#import-a-table-as-an-asset","title":"Import a table as an Asset","text":""},{"location":"rudiments/hello_feature_collection/#load-feature-collection-from-string","title":"Load Feature Collection from String","text":"<pre><code>graph LR\n  method[\"ee.FeatureCollection.()\"] --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n  arg_att([pathname\\n\\nSTRING]) --&gt; method\n\n  style method fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att fill:#DCDCDC,stroke-width:0px</code></pre> <pre><code>// --------------------------------------------------------------------------\n//  Load Feature Collection from String (collection name). \n//\n//  Updated: 9/30/23\n// --------------------------------------------------------------------------\n\nvar hello_pond ;\n\nprint(\n'HELLO FEATURE COLLECTION:',\nhello_pond,\nhello_pond.size(),\nhello_pond.first()\n)\n;\n</code></pre>"},{"location":"rudiments/hello_feature_collection/#center-map-on-object","title":"Center map on Object","text":"<pre><code>// --------------------------------------------------------------------------\n//  Center Map on Object.\n//\n//  Updated: 9/30/23\n// -------------------------------------------------------------------------- \n\nMap.centerObject();\nMap.setOptions();\n</code></pre>"},{"location":"rudiments/hello_feature_collection/#add-feature-collection-as-map-layer","title":"Add Feature Collection as Map Layer","text":"<pre><code>// --------------------------------------------------------------------------\n//  Add Feature Collection as Map Layer.\n//\n//  Updated: 9/30/23\n// --------------------------------------------------------------------------\n\nMap.addLayer();\n</code></pre>"},{"location":"rudiments/hello_feature_collection/#create-a-geometry","title":"Create a geometry","text":"<pre><code>// --------------------------------------------------------------------------\n//  Create a Geometry.\n//\n//  Updated: 9/30/23\n// --------------------------------------------------------------------------\n\nprint(\n'Pond Geometry:',\ngeometry\n)\n;\n</code></pre>"},{"location":"rudiments/hello_feature_collection/#construct-a-feature","title":"Construct a feature","text":"<pre><code>graph LR\n  method[\"ee.Feature()\"] --&gt; output&gt;output\\n\\nFEATURE];\n  arg_geom([GEOMETRY]) --&gt; method;\n  arg_att([attributes\\n\\nDICTIONARY]) --&gt; method;\n\n  style method fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_geom fill:#E1C3E6,stroke-width:0px\n  style arg_att fill:#DCDCDC,stroke-width:0px</code></pre> <pre><code>// --------------------------------------------------------------------------\n//  Construct a Feature.\n//\n//  Updated: 9/30/23\n// --------------------------------------------------------------------------\n\nvar pond_attributes ;\n\nvar pond_feature ;\n\nprint(\n\"HELLO POND FEATURE:\",\n\"geometry:\", geometry,\n\"attributes:\", pond_attributes,\n\"feature:\", pond_feature\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"rudiments/hello_feature_collection/#convert-feature-collection-into-an-image","title":"Convert feature collection into an image","text":"<pre><code>graph LR\n  input[/input\\n\\nFEATURE COLLECTION/] --&gt; method[\".reduceToImage()\"]\n  method --&gt; output&gt;output\\n\\nIMAGE];\n  arg_att1([property key\\n\\nLIST]) --&gt; method;\n  arg_att2([\"ee.Reducer()\"]) --&gt; method;\n\n  style input fill:#E1C3E6,stroke-width:0px\n  style method fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#ADD8E6,stroke-width:0px</code></pre> <pre><code>// ---------------------------------------------------------------------------\n//  Convert feature collection into an image. \n//\n//  Updated: 10/01/23\n// ---------------------------------------------------------------------------\n\nvar pond_image ;\n\nprint(\n\"HELLO POND IMAGE:\", pond_image\n)\n;\n\nMap.addLayer();\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"rudiments/hello_vector/","title":"Hello Vector","text":""},{"location":"rudiments/hello_vector/#introduction","title":"Introduction","text":"<p>This tutorial introduces the vector data model with QGIS. It walks you through a simple task of creating and populating a vector table stored as a shapefile, and aims to get you thinking about relationships between detail, accuracy, map scale, and mapping purpose.  </p>"},{"location":"rudiments/hello_vector/#create-a-new-shapefile","title":"Create a new shapefile","text":""},{"location":"rudiments/hello_vector/#digitize-a-feature","title":"Digitize a feature","text":""},{"location":"rudiments/hello_vector/#add-a-new-field","title":"Add a new field","text":""},{"location":"rudiments/hello_vector/#display-by-attribute","title":"Display by attribute","text":"<p>Please note: I edited this video in YouTube Studio this morning (9/28) so that it should now end at 7:15 mark. Sometimes Studio takes some time to process edits, so if the video served to you keeps going after 7:15, you are welcome to stop it and move onto next one. Thanks. </p>"},{"location":"rudiments/hello_vector/#under-the-shapefile-hood","title":"Under the shapefile hood","text":""},{"location":"rudiments/hello_vector/#deliverable","title":"Deliverable","text":"<p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"rudiments/natural_and_false_color/","title":"In Natural and False Color","text":""},{"location":"rudiments/natural_and_false_color/#introduction","title":"Introduction","text":"<p>A remote sensing system observes conditions on Earth (or other planets) without making direct contact with the observed subject. This generally involves a sensor (typically onboard a vehicle) and a ground station (that receives data from the vehicle).  </p> <p>Some systems passively observe conditions by measuring energy that is generated by another source, while others emit energy in some form and measure how it returns.  </p> <p> <p> </p> <p></p> <p>source: Arkarjun (2013)</p> <p>Today we will focus on passive systems and try to better understand what they measure and how we can use additive color to see things in imagery that we cannot see in the real world.  </p>"},{"location":"rudiments/natural_and_false_color/#electromagnetic-spectrum","title":"Electromagnetic Spectrum","text":"<p>The electromagnetic spectrum describes the range of energy wavelengths in sunlight.  </p> <p> </p> <p>source: serc.carleton.edu</p>"},{"location":"rudiments/natural_and_false_color/#spectral-bands-of-sensors","title":"Spectral Bands of Sensors","text":"<p>A sensor onboard a vehicle will be able to measure the amount of energy that it receives in different spectral bands, or portions of the EM spectrum.  </p> <p></p> <p> Acronym Name MSS Multispectral Scanner TM Thematic Mapper ETM+ Enhanced Thematic Mapper OLI/OLI-2 Operational Land Imager TIRS/TIRS-2 Thermal Infrared Sensor <p></p>"},{"location":"rudiments/natural_and_false_color/#bands","title":"Bands","text":"<p>Each band captures the amount of energy at each pixel. The picture below shows the pixel values of an individual band that are displayed with a grayscale (black to white) palette.  </p> <p> <p></p> <p></p>"},{"location":"rudiments/natural_and_false_color/#stretch-enhancement","title":"Stretch enhancement","text":"<p>The image above looks a little drab because we are not using our display values very efficiently. We can improve the contrast of this image with stretch enhancement.  </p> <p> </p> <p>Link to app </p>"},{"location":"rudiments/natural_and_false_color/#natural-color","title":"Natural color","text":"<p>Now we can take advantage of additive color and display the bands that report the amount of energy in the red, green, and blue portions of the EM spectrum with the red, green, and blue color channels. The result is called a natural color composite because it looks natural to human eyes, or similar to the world that we experience, or at least it looks like the world that we can see from an airplane window.    </p> <p> <p></p> <p> </p> <p>In a natural color composite, we use a straight mapping between the EM band and the display color channel.  </p> <p> Band Color Channel Red Red Green Green Blue Blue <p></p>"},{"location":"rudiments/natural_and_false_color/#false-color","title":"False color","text":"<p>The remote sensing instruments onboard satellites will often report data in portions of the EM spectrum that we cannot see. When we use additive color to visualize energy that we cannot otherwise see, the results are called false color composites. The picture below shows a NIR false color. </p> <p></p> <p>So now the colors are false and this can be a little weird to think through, but the main point is to remember that we can use different colors to display different ranges of the EM spectrum (even though we naturally see some of these ranges as color).   </p> <p> Band Color Channel NIR Red Red Green Green Blue <p></p> <p>There are a lot of different false color composites that you can make with additive color. For example, here is another common false color composite that displays shortwave energy.</p> <p> <p></p> Band Color Channel SWIR2 Red NIR Green Green Blue <p></p>"},{"location":"rudiments/natural_and_false_color/#make-some-composites","title":"Make some composites","text":"<p>Go ahead and try to make the color composites shown above and use stretch enhancement to improve the contrast of each image.  </p> <p> </p> <p>Link to app. </p> <p>As a guide for exploring color composites, here is a very helpful resource that identifies useful band combinations for different thematic applications in environmental science and geography. </p>"},{"location":"rudiments/natural_and_false_color/#what-do-the-colors-mean","title":"What do the colors mean?","text":"<p>Spectral signature charts show how reflectance changes with wavelength for different land cover types.    </p> <p> </p> <p>source: Hartley Bulcock</p> <p>We can explore spectral signature with this app.</p> <p> </p> <p>Link to app </p> <p>S2 band spec sheet</p>"},{"location":"rudiments/natural_and_false_color/#summary","title":"Summary","text":"<p>Remote sensing involves capturing data about a place without being in contact with the place. We capture this data with sensors onboard vehicles, like satellites, drones, and airplanes. These sensors measure the amount of energy that reflects or radiates from the Earth, storing this data in each pixel of a raster dataset. Most sensors capture this data within specific ranges of the electromagnetic spectrum, which are called spectral bands; this includes both visible and non-visible portions of the spectrum. We can use additive color to display the values of three spectral bands at once and we can use stretch enhancement to improve the contrast of the resulting images. The color composites that result help us visualize three slices of the spectral signatures of land cover. We can also use the spectral signatures of land cover to help guide our choice of band combinations to make color composites.   </p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"rudiments/on_distance/","title":"On Distance","text":"<p>INCOMPLETE DRAFT October 5, 2023</p>"},{"location":"rudiments/on_distance/#introduction","title":"Introduction","text":"<p>I find working with distance methods on raster datasets in Earth Engine to be a little confusing, so I made the app below to better understand how these things work. The text below walks you through how to make sense of it. </p> <p> </p>"},{"location":"rudiments/on_distance/#test-point-feature-collection","title":"Test point feature collection","text":"<p>You should see a yellow point on the 50 yard line of Youngman Field. If you click on the Layers widget, you should see a list of layers that you can add to the map. When you first load the embedded app, the layer at the bottom should be the only one checked; this is the layer with the little yellow dot, called Test point (Feature Collection) because it is a feature collection with one feature in it.  </p>"},{"location":"rudiments/on_distance/#test-point-image","title":"Test point image","text":"<p>The next layer up from the bottom is called  Test Point Image. It is the same point at midfield, but now is is stored as a binary image. The little white pixel in the center marks the location of the test point; this pixel has a value of 1. All the black pixels have a value of 0.  </p> <p>If you zoom out a little (by clicking the - button on the upper left), you should see the extent of the image. There is an edge to the raster beyond which you can see the underlying satellite base map. The extent is 300 meters by 300 meters.  </p>"},{"location":"rudiments/on_distance/#simple-distance-image","title":"Simple distance image","text":"<p>Still moving from bottom up in the layer panel, the next layer is called Simple Test Distance Image and represents the distance from the test point image. The figure below shows how I made it.</p> <pre><code>graph LR\n  input[/test point image/] --&gt; method1[\".distance()\"] ;\n  method1 --&gt; method2([\"ee.Kernel.euclidean()\"])\n  arg_att1([\"radius: 100\"]) --&gt; method2;\n  arg_att2([\"units: 'meters'\"]) --&gt; method2;\n  method2 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px</code></pre> <p>Notice that the .distance() method takes the ee.Kernel.euclidian() method as an argument. (I use blue to indicate methods and rounded shapes to indicate arguments, or things that get put into a method\u2019s parentheses). </p> <p>A kernel is an analysis window. In this case, the kernel defines the spatial extent of the euclidean distance operation. When we say that we want the radius of the kernel to be 100 meters, we are defining the size of our analysis window. This is a little confusing, because I think Earth Engine actually uses a square as the kernel shape, not a circle, but more on that later.  </p> <p>In this case, the extent of the Simple Test Distance Image represents the kernel extent; it shows the size of the window that was centered on the only pixel in the binary image with a non-zero value. Within this kernel window, Earth Engine computed the Euclidean distance from the single non-zero pixel to all the other zero pixels in the kernel extent.</p> <p>The fact that the extent of the Simple Test Distance Image is smaller than the extent of the Test Point Image also tells us something important. Remember that the Test Point Image was the input to the distance method (I use the parallelogram shape to represent data inputs because I am trying to suggest they are moving or about to undergo change). So the difference between the two extents means that the .distance() method does not make computations across the entire extent of the input image. If it did, the extent of the output would be the same as the input. Instead, the .distance() method computes distance within the extent of the kernel that you feed it. Any locations outside of the kernel extent get masked. </p>"},{"location":"rudiments/on_distance/#simple-distance-threshold","title":"Simple distance threshold","text":"<p>You may have noticed that if you zoom out too far when looking at the test point image extent in the previous section, Earth Engine stops drawing the Simple Test Distance Image on the map. That is perhaps the first clue that something is weird here. </p> <p>Why would the ability to draw the layer depend on the zoom level? </p> <p>If this fuels a sense of doubt and you begin to wonder how much you should trust what the layer claims to show you, I would like to double-down on such concerns by looking at the next layer, called Threshold Simple Distance at 50 Yards. Here is how I made it:  </p> <pre><code>graph LR\n  input[/test point image/] \n  method1[\".lt()\"] ;\n  method2[\".selfMask()\"]\n  arg1([\"45.72\"]) \n  output&gt;output\\n\\nIMAGE];\n\n  input --&gt; method1 ;\n  arg1 --&gt; method1 ;\n  method1 --&gt; method2 ;\n  method2 --&gt; output\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg1 fill:#DCDCDC,stroke-width:0px</code></pre> <p>The output is a binary image, where all locations that are 50 yards (45.72 meters) or less from the midfield point are displayed in white and all other locations are masked. If you turn off all the other layers, you should be able to see the satellite base layer and compare this circle to hatch marks on the football field. The circle should reach the goal line, but it does not. It seems instead to leave a long field goal.      </p> <p>Why does this distance layer under represent distance? </p> <p>There are two things that help understand why this happens when we use the Code Editor: </p> <ol> <li>Pixel scale changes with zoom level.   </li> <li>Zoom level determines analysis scale, unless we specify otherwise. </li> </ol> <p>Google Earth Engine stores all image assets in a stack of different resolutions defined by zoom level. The idea is that each zoom level serves you an image with the same number of pixels. As a result, pixel scale changes as you move between zoom levels. Here is another way to think about this: you do not get more pixels on your monitor to see more detail, you simply get pixels that represent smaller distances on the Earth\u2019s surface.     </p> <p> source: Google</p> <p>The image above shows how each pixel generalizes the values of a 2x2 block of pixels at the next, more detailed zoom level. As a result, pixel scale resembles a pyramid as you move from small scale to large scale zoom levels. </p> <p>When you use a kernel method in the Code Editor, the zoom level of the map in the Code Editor determines the scale of the analysis. That is why the results appear to change as you zoom in and out; by changing the zoom level, you change the scale of the analysis. </p>"},{"location":"rudiments/on_distance/#distance-image-with-reprojectcrs","title":"Distance image with .reproject(crs)","text":"<p>To be continued\u2026</p> <pre><code>graph LR\n  input[/test point image/] --&gt; method1[\".distance()\"] ;\n  method1 --&gt; method2([\"ee.Kernel.euclidean()\"])\n  arg_att1([\"radius: 250\"]) --&gt; method2;\n  arg_att2([\"units: 'meters'\"]) --&gt; method2;\n  method2 --&gt; method3[\".reproject()\"]\n  arg_att3([\"crs: 'EPSG: 32145'\"]) --&gt; method3;\n  method3 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"rudiments/on_distance/#source-code","title":"Source code","text":"<pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  On distance in Earth Engine\n//\n//  Jeff Howarth\n//\n//  Updated: Oct 5, 2023\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n// -----------------------------------------------------------------------------\n// Make test point at 50 yard line.\n// -----------------------------------------------------------------------------\n\nvar test_point1 = ee.Geometry.Point([-73.17965925111653, 44.00167387729651]);\n\nMap.centerObject(test_point1, 17);\nMap.setOptions('HYBRID');\n\n// Map.addLayer(test_point, {color: 'red'}, \"Test Point\", false);\n\n// -----------------------------------------------------------------------------\n// Put test point in a feature collection.\n// -----------------------------------------------------------------------------\n\nvar test_fc = ee.FeatureCollection(\n[\nee.Feature(test_point1, {'tag': 1}),\n]\n);\n\nMap.addLayer(test_fc, {color: 'Yellow'}, \"Test point (Feature Collection)\");\n\n// -----------------------------------------------------------------------------\n// Define an abitrary test extent.\n// -----------------------------------------------------------------------------\n\nvar test_extent = test_point1.buffer(150).bounds();\n\n// -----------------------------------------------------------------------------\n// Convert point to an image.\n// -----------------------------------------------------------------------------\n\nvar crs = \"EPSG: 32145\";\n\nvar test_image = ee.FeatureCollection(test_fc)\n.reduceToImage([\"tag\"], ee.Reducer.max())\n.reproject({crs: crs})\n.unmask()\n.rename(\"test_image\")\n.clip(test_extent)\n;\n\nprint(\"test image\", test_image, test_image.projection());\n\nMap.addLayer(test_image, {min:0, max:1}, \"Test point Image\", false);\n\n// -----------------------------------------------------------------------------\n// Make test distance image without .reproject(crs).\n// -----------------------------------------------------------------------------\n\nvar kernel_radius = ee.Number(100);\n\nvar test_distance_image_without_crs = test_image\n.distance(ee.Kernel.euclidean({radius: kernel_radius, units: 'meters'}))\n// .reproject({crs: crs})                                         \n.rename('distance')\n;\n\nprint(\"test distance image:\", test_distance_image_without_crs, test_distance_image_without_crs.projection());\n\nvar inferno = [\"#000004\", \"#320A5A\", \"#781B6C\", \"#BB3654\", \"#EC6824\", \"#FBB41A\", \"#FCFFA4\"].reverse();\n\nMap.addLayer(test_distance_image_without_crs,  {min:0, max: 100, palette: inferno}, \"Simple Test Distance Image\", false);\n\n// -----------------------------------------------------------------------------\n// Threshold distance image without crs at 50 yards. \n// -----------------------------------------------------------------------------\n\nvar test_image_buffer_without_crs = test_distance_image_without_crs.lt(45.72).selfMask();\n\nMap.addLayer(test_image_buffer_without_crs, {min:0, max:1}, 'Threshold Simple Distance at 50 Yards', false);\n\n\n// -----------------------------------------------------------------------------\n// Make test distance image with .reproject(crs).\n// -----------------------------------------------------------------------------\n\nvar test_distance_image_with_crs = test_image\n.distance(ee.Kernel.euclidean({radius: 100, units: 'meters'}))\n.reproject({crs: crs})                                         .rename('distance')\n;\n\nprint(\"test distance image:\", test_distance_image_with_crs, test_distance_image_with_crs.projection());\n\nvar inferno = [\"#000004\", \"#320A5A\", \"#781B6C\", \"#BB3654\", \"#EC6824\", \"#FBB41A\", \"#FCFFA4\"].reverse();\n\nMap.addLayer(test_distance_image_with_crs,  {min:0, max: 100, palette: inferno}, \"Test Distance Image with Reproject\", false);\n\n// -----------------------------------------------------------------------------\n// Threshold distance image with crs at 50 yards. \n// -----------------------------------------------------------------------------\n\nvar test_image_buffer_with_crs = test_distance_image_with_crs.lt(45.72).selfMask();\n\nMap.addLayer(test_image_buffer_with_crs, {min:0, max:1}, 'Thresholded Test Distance Image with Reproject ', false);\n\n// -----------------------------------------------------------------------------\n// Convert threshold image with crs to vector. \n// -----------------------------------------------------------------------------\n\nvar test_image_buffer_to_vector_without_crs = test_image_buffer_without_crs.reduceToVectors(\n{\nreducer: ee.Reducer.countEvery(), geometry: test_extent, scale: 1, geometryType: 'polygon', eightConnected: true, crs: crs,\nmaxPixels: 1e12, geometryInNativeProjection: true\n}\n);\n\nMap.addLayer(test_image_buffer_to_vector_without_crs, {color: 'magenta'}, \"Threshold Simple Distance Image Converted to Feature\", false);\n\n\n// -----------------------------------------------------------------------------\n// Convert threshold image with crs to vector. \n// -----------------------------------------------------------------------------\n\nvar test_image_buffer_to_vector_with_crs = test_image_buffer_with_crs.reduceToVectors(\n{\nreducer: ee.Reducer.countEvery(), geometry: test_extent, scale: 1, geometryType: 'polygon', eightConnected: true, crs: crs,\nmaxPixels: 1e12, geometryInNativeProjection: true\n}\n);\n\nMap.addLayer(test_image_buffer_to_vector_with_crs, {color: 'cyan'}, \"Threshold Distance Image with Reproject Converted to Feature\", false);\n\n\n// -----------------------------------------------------------------------------\n// Buffer vector at 50 yards.\n// -----------------------------------------------------------------------------\n\nvar makeBuffer = function(f) {\nreturn f.buffer(45.72);\n};\n\nvar test_buffer_vector = test_fc.map(makeBuffer);\n\nMap.addLayer(test_buffer_vector, {color: 'Yellow'}, \"Vector buffer Method\", false);\n\n// -----------------------------------------------------------------------------\n// What is the shape of the Euclidean Kernel?\n// -----------------------------------------------------------------------------\n\nvar kernel_extent = test_distance_image_with_crs.gte(0).reduceToVectors(\n{\nreducer: ee.Reducer.countEvery(), geometry: null, scale: 1, geometryType: 'bb', eightConnected: true, crs: \"EPSG: 32145\", maxPixels: 1e12, geometryInNativeProjection: true\n}\n);\n\nMap.addLayer(kernel_extent, {color: 'White'}, \"Kernel Extent Test Image with Reproject\", false);\n\n\nvar test_kernel_max = test_distance_image_with_crs.reduceRegion(\n{\nreducer: ee.Reducer.max(), geometry: kernel_extent, scale: 1, crs: \"EPSG: 32145\", maxPixels: 1e12, tileScale: 1\n}\n);\n\nvar pythag = kernel_radius.multiply(kernel_radius).multiply(2).sqrt();\n\nprint(\n\"Test Kernel max:\", test_kernel_max,\n\"pythag diagonal:\", pythag\n)\n;\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"toolbox/GEE/","title":"Google Earth Engine","text":""},{"location":"toolbox/GEE/#introduction","title":"Introduction","text":"<p>Google Earth Engine (GEE) is cloud-based geographic information system (GIS) that is (currently) free to use for educational and research purposes. We will be using GEE for most of the heavy lifting in this course: accessing large datasets, crunching them in computational workflows, and visualizing them with web maps. The lovely thing about GEE is that all of this work gets done on Google\u2019s servers in the cloud. All you will need to work with GEE is a web browser, preferably Google Chrome, and a decent internet connection. All you need to do is sign up for the Google Earth Engine cloud service. </p> <p>Please complete the steps below on the first day of class (or 24 hours before our first lab meeting). </p>"},{"location":"toolbox/GEE/#sign-up-for-earth-engine","title":"Sign up for Earth Engine","text":"<ol> <li> <p>Go to the bottom of the Google Earth Engine page and click \u2018Sign Up Now\u2019.</p> <p></p> </li> <li> <p>You want to sign up for a noncommercial cloud project. The next page will likely only show one option, so go ahead and click that.</p> <p></p> </li> <li> <p>As a student, you do not have to pay for your use of Earth Engine. So click \u2018Unpaid usage\u2019 and then select \u2018Academic and Research\u2019 from the pull-down options. Click \u2018Next\u2019 to move on.   </p> <p></p> </li> <li> <p>You should create a new Google Cloud Project. You can try doing this under the middlebury.edu organization. Your user name should be \u2018ee-your-midd-email-address-name\u2019 with no spaces. For example, \u2018ee-jhowarth\u2019. Then click \u2018Continue to Summary\u2019.    </p> <p></p> </li> <li> <p>Affirm the summary to finalize the project. </p> </li> <li> <p>It may take a little time for you to receive approval. When you are successful, you should be able to open the Code Editor and get to a page that looks similar to the one below. </p> <p></p> </li> </ol>"},{"location":"toolbox/QGIS/","title":"QGIS","text":""},{"location":"toolbox/QGIS/#introduction","title":"Introduction","text":"<p>QGIS is a free, open-source, and powerful geographic information system (GIS). We will be using QGIS for some light lifting in this course: mostly data visualization and layouts. Because QGIS is free and powerful, I would like you to know your way around it and be comfortable moving data from GEE to QGIS and vice versa. </p> <p>Unlike GEE, QGIS is a desktop GIS, which means in most cases the program needs to be installed on a local computer. All of the workstations in the Geography Department computer lab have QGIS installed, so you can use any of these computers to complete course work that requires QGIS. It will be far more convenient for you to keep up with the study materials in this course, however, if you install QGIS on your laptop. It\u2019s free and the software runs on both a Mac and Windows.  </p> <p>Please complete the steps below before our first lab meeting.</p>"},{"location":"toolbox/QGIS/#install-qgis-for-first-time","title":"Install QGIS for first time","text":"<ol> <li>Go to QGIS home page. </li> <li>Click \u2018Download Now\u2019. </li> <li>Choose your Operating System. This will start the download, which may take some time to finish.  </li> <li>Double-click the downloaded installer and follow the directions.  </li> </ol> <p>If on a Mac, after installation is complete: </p> <ol> <li>Navigate to application folder.</li> <li>Right-click on QGIS app.</li> <li>Select \u2018Open\u2019. </li> <li>You will see a warning that you have downloaded the app from the internet and questioning whether you trust the source. Affirm. </li> </ol> <p>After you have told your OS to trust the app, you can open the app through Spotlight in the future.  </p>"},{"location":"toolbox/QGIS/#on-updating-your-qgis-version","title":"On updating your QGIS version","text":"<p>If you have installed QGIS recently (2022-2023), you should be fine. </p> <p>We will be using GEE for most of the heavy lifting in this course and will largely use QGIS for some visualization and layout tasks. My QGIS demos will use 3.32.2-Lima (accessed 9.6.23), but it is ok if your version predates this a little. </p> <p>If you want to update your version, I tend to first remove the existing version and then install the new version. </p>"},{"location":"workflows/changes_in_the_night/","title":"Changes in the Night","text":""},{"location":"workflows/changes_in_the_night/#introduction","title":"Introduction","text":"<p>This tutorial walks you through how to construct an RGB composite that visualizes change in the DMSP/OLS dataset between 1993 and 2013 like the image shown in the additive color chapter.  </p> <p>The diagram below illustrates the general workflow.  </p> <p></p> <p>The tutorial also shows you how to compose your script (using a dictionary and a custom function) so that you can easily change the three years used to define the RGB composite. In other words, the purpose of your script is not simply to deliver a map product, but instead to create a flexible tool for exploring and visualizing the nighttime lights dataset with additive color. </p>"},{"location":"workflows/changes_in_the_night/#start-a-new-script","title":"Start a new script","text":"<pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Name:     changes_in_the_night.js \n//  Author:   Jeff Howarth\n//  Date:     10/10/2023 \n//  Purpose:  Introduce additive color, nighttime lights, and patterns of change.\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  \n</code></pre>"},{"location":"workflows/changes_in_the_night/#load-image-collection-and-select-a-band","title":"Load image collection and select a band","text":"<pre><code>graph LR\n  arg1([\"pathname\\n\\nSTRING\"]) --&gt; method1[\"ee.ImageCollection()\"] ;\n  method1 --&gt; method2[\".select()\"] ;\n  arg2([\"band name\\n\\nSTRING\"]) --&gt; method2 ;\n  method2 --&gt; output&gt;\"output\\n\\nIMAGE COLLECTION\"];\n\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style arg1 fill:#DCDCDC,stroke-width:0px\n  style arg2 fill:#DCDCDC,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n</code></pre> <pre><code>// -----------------------------------------------------------------------\n//  Load image collection and select a band.  \n// -----------------------------------------------------------------------\n\n// Image Collection pathname: \"NOAA/DMSP-OLS/NIGHTTIME_LIGHTS\"\n// Band: \"stable_lights\"\n\nvar collection ;\n\nprint(\n\"Collection\",\ncollection,\ncollection.size(),                            collection.first(),\ncollection.first().bandNames()                )\n;\n</code></pre>"},{"location":"workflows/changes_in_the_night/#create-dictionary-for-study-years","title":"Create dictionary for study years","text":"<pre><code>// -----------------------------------------------------------------------\n//  Create a dictionary for study years to assign band 1, 2, 3\n// -----------------------------------------------------------------------\n\n// Your goal is to display pixel values in each layer with these colors:\n//  2013 with red,\n//  2003 with green,\n//  1992 with blue.\n\nvar yrs = {\n\n};\n</code></pre>"},{"location":"workflows/changes_in_the_night/#make-image-for-band-1","title":"Make image for Band 1","text":"<pre><code>graph LR\n  input[/\"collection\\n\\nIMAGE COLLECTION\"/] --&gt; method1[\".filter()\"] ;\n  arg1([\"study year\\n\\nDICTIONARY KEY\"]) --&gt; method2([\"ee.Filter.calendarRange()\"]) ;\n  arg2([\"time unit\\n\\nSTRING\"]) --&gt; method2 ;\n  method2 --&gt; method1 ;\n  method1 --&gt; method3[\".first()\"] ;\n  method3 --&gt; method4[\".rename()\"] ;\n  method5([\"String()\\n\\nFUNCTION\"]) --&gt; method4 ;\n  arg1 --&gt; method5 ;\n  method4 --&gt; output&gt;\"output\\n\\nIMAGE\"] ;\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style method4 fill:#ADD8E6,stroke-width:0px\n  style method5 fill:#ADD8E6,stroke-width:0px\n  style arg1 fill:#DCDCDC,stroke-width:0px\n  style arg2 fill:#DCDCDC,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n</code></pre> <pre><code>// -----------------------------------------------------------------------\n//  Make an image for band 1  \n// -----------------------------------------------------------------------\n\nvar b1 = collection\n;\n\nprint(\n\"Band 1:\",\nb1\n)\n;\n</code></pre>"},{"location":"workflows/changes_in_the_night/#display-image-as-a-map-layer","title":"Display image as a map layer","text":"<pre><code>// -----------------------------------------------------------------------\n//  Display image as layer on the map.\n// -----------------------------------------------------------------------\n\nMap.setCenter(126.8, 33.485, 5);\nMap.setOptions('HYBRID');\n\nvar viz ;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/changes_in_the_night/#make-and-display-image-for-band-2","title":"Make and display image for Band 2","text":"<pre><code>graph LR\n  input[/\"collection\\n\\nIMAGE COLLECTION\"/] --&gt; method1[\".filter()\"] ;\n  arg1([\"study year\\n\\nDICTIONARY KEY\"]) --&gt; method2([\"ee.Filter.calendarRange()\"]) ;\n  arg2([\"time unit\\n\\nSTRING\"]) --&gt; method2 ;\n  method2 --&gt; method1 ;\n  method1 --&gt; method3[\".mean()\"] ;\n  method3 --&gt; method4[\".rename()\"] ;\n  method5([\"String()\\n\\nFUNCTION\"]) --&gt; method4 ;\n  arg1 --&gt; method5 ;\n  method4 --&gt; output&gt;\"output\\n\\nIMAGE\"];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style method4 fill:#ADD8E6,stroke-width:0px\n  style method5 fill:#ADD8E6,stroke-width:0px\n  style arg1 fill:#DCDCDC,stroke-width:0px\n  style arg2 fill:#DCDCDC,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n</code></pre> <pre><code>// -----------------------------------------------------------------------\n//  Make and display image for band 2.  \n// -----------------------------------------------------------------------\n\nvar b2 ;\n\nprint(\n\"Band 2:\",\nb2\n)\n;\n\nMap.addLayer();\n</code></pre> <p>Source</p>"},{"location":"workflows/changes_in_the_night/#write-a-function","title":"Write a function","text":"<pre><code>// -----------------------------------------------------------------------\n//  Write a function  \n// -----------------------------------------------------------------------\n\nvar makeImageForBand ;\n\n// Call the function\n\nvar b1 ;\n\n// Display result as a layer. \n\n// Map.addLayer();\n</code></pre>"},{"location":"workflows/changes_in_the_night/#test-generality-of-function","title":"Test generality of function","text":"<pre><code>// -----------------------------------------------------------------------\n//  Test generality of function.  \n// -----------------------------------------------------------------------\n\n// Does .first() and .mean() deliver identical results for b1 case?\n\nvar test ;\n\n// Map.addLayer();\n</code></pre>"},{"location":"workflows/changes_in_the_night/#revise-script-to-apply-function","title":"Revise script to apply function","text":"<pre><code>// -----------------------------------------------------------------------\n//  Revise script to apply function. \n// -----------------------------------------------------------------------\n\n// 1. Comment out sections above that made and drew b1 and b2;\n\n// 2. Redefine map options and viz parameters (that were commented out).\n\nMap.setCenter(126.8, 33.485, 5);\nMap.setOptions('HYBRID');\n\nvar viz = {min:0, max: 63};\n\n// 3. Call function to remake all bands\n\nvar b1 ;\nvar b2 ;\nvar b3 ;\n\n// 4. Add results as layers to map.\n\nMap.addLayer();\n// \n</code></pre>"},{"location":"workflows/changes_in_the_night/#make-and-display-rgb-composite-image","title":"Make and display RGB composite image","text":"<pre><code>graph LR\n  input[/\"Band 1\\n\\nIMAGE\"/] --&gt; method1[\".addBands()\"] ;\n  method1 --&gt; method2[\".addBands()\"] ;\n  arg1([\"Band 2\\n\\nIMAGE\"]) --&gt; method1 ;\n  arg2([\"Band 3\\n\\nIMAGE\"]) --&gt; method2 ;\n  method2 --&gt; output&gt;\"output\\n\\nIMAGE\"];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style arg1 fill:#C5E6A1,stroke-width:0px\n  style arg2 fill:#C5E6A1,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n</code></pre> <pre><code>// -----------------------------------------------------------------------\n//  Construct and display three band image from the three images.  \n// -----------------------------------------------------------------------\n\n// Create image. \n\nvar change_image ;\n\nprint(\n\"Change Image\",\nchange_image\n)\n;\n\n// Display result as a map layer. \n\nMap.addLayer();\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"workflows/grassland_bird_habitat/","title":"Grassland Bird Habitat","text":""},{"location":"workflows/grassland_bird_habitat/#introduction","title":"Introduction","text":"<p>This tutorial aims to answer the question:  </p> <p>In 2016, where was the best potential habitat for grassland birds in the Champlain Valley that was owned by Middlebury College?</p> <p>To answer this question, we will develop a model based on these guidelines developed by the Vermont Agency of Natural Resources.  </p>"},{"location":"workflows/grassland_bird_habitat/#background","title":"Background","text":"<p>The Bobolink (Dolichonyx oryzivorus) is a grassland bird species with a bubbling song and a remarkable life cycle. Bobolinks winter in South America, primarily Paraguay, Argentina, and Bolivia. In the spring, they migrate back to their breeding habitats in North America, including grassland habitat here in the Champlain Valley. Interestingly, Bobolinks seem to have keen spatial memory and sense of place; they tend to return to the same specific field each summer to breed and research indicates that this \u201csite fidelity\u201d improves breeding success. </p> <p></p> <p>source: iNaturalist</p> <p>Bobolinks are also an interesting example of a \u201cnew native\u201d species. During Abenaki times, Bobolinks did not breed in Vermont, because there was very little grassland habitat for them to do so. Open, grassy habitat was uncommon in what we now call the Champlain Valley; the landscape here was largely forested, save for the margins of water bodies and places where Abekai cultivated crops or set fires at a frequency that prevented trees from growing. Following the American Revolution, white migrants appropriated Abenaki lands in the Champlain Valley and pitched farms, claiming the land by clearing it of trees. This created large expanses of open habitat in the formerly forested landscape. Bobolinks soon colonized this new habitat, migrating from native breeding territories on the midwestern prairies of North America.  </p> <p>Today, Vermont plays an important role in the conservation of Bobolinks and other native North American grassland species. Since the 1940s, breeding populations of Bobolinks have significantly declined across North America, primarily from habitat loss caused by both changes in agricultural practices and the conversion of agricultural land into other land uses. </p> <p>This tutorial develops a model with Earth Engine to identify where Middlebury College owns land that could contribute to the conservation of native North American grassland bird species by protecting the open structure of the habitat and working with farmers to adapt land use practices that do not conflict with breeding cycles of grassland birds.   </p>"},{"location":"workflows/grassland_bird_habitat/#criteria","title":"Criteria","text":"<p>According to the ANR guidelines, the best potential habitat for Bobolink and other grassland bird species should meet the following criteria: </p> <ol> <li>Open land cover (grass/shrub, water, bare);</li> <li>Buffered from the edge, or with a core area that is at least 50 meters from closed habitat structure (tree canopy) or developed land (roads, buildings, pavement, etc);  </li> <li>Large, or at least 20 acres in area;</li> <li>With a large interior, or a perimeter-area ratio of 0.015 or less. </li> </ol>"},{"location":"workflows/grassland_bird_habitat/#workflow-overview","title":"Workflow overview","text":"<p>The diagram below shows the general workflow for the model, or how each step in the tutorial connects to other steps. The color represents the format of the result (or output) of each step as shown below.  </p> <p> <pre><code>graph TD\n  vector[vector] ;\n  raster[raster] ;\n  task[task] ;\n\nstyle vector fill:#E1C3E6,stroke-width:0px\nstyle raster fill:#C5E6A1,stroke-width:0px\nstyle task fill:#ADD8E6,stroke-width:0px</code></pre> <p></p> <p>Here is how each step in the workflow connects to another step.     </p> <p> <pre><code>graph LR\n  step01[1] ;\n  step02[2] ;\n  step03[3] ;\n  step04[4] ;\n  step05[5] ;\n  step06[6] ;\n  step07[7] ;\n  step08[8] ;\n  step09[9] ;\n  step10[10] ;\n  step11[11] ;\n  step12[12] ;\n  step13[13] ;\n  step14[14] ;\n  step15[15] ;\n  step16[16] ;\n\n  step01 --&gt; step02 --&gt; step03  \n  step04 --&gt; step05\n  step03 --&gt; step06\n  step05 --&gt; step06\n  step06 --&gt; step07 \n  step07 --&gt; step08  \n  step08 --&gt; step09\n  step02 --&gt; step10\n  step09 --&gt; step10  \n  step09 --&gt; step11\n  step11 --&gt; step12\n  step03 --&gt; step12\n  step12 --&gt; step13  \n  step02 --&gt; step13\n  step13 --&gt; step14  \n  step14 --&gt; step15\n  step15 --&gt; step16\n\n  style step01 fill:#E1C3E6,stroke-width:0px\n  style step02 fill:#E1C3E6,stroke-width:0px\n  style step03 fill:#E1C3E6,stroke-width:0px\n  style step04 fill:#C5E6A1,stroke-width:0px\n  style step05 fill:#C5E6A1,stroke-width:0px\n  style step06 fill:#C5E6A1,stroke-width:0px\n  style step07 fill:#C5E6A1,stroke-width:0px\n  style step08 fill:#C5E6A1,stroke-width:0px\n  style step09 fill:#C5E6A1,stroke-width:0px\n  style step10 fill:#E1C3E6,stroke-width:0px\n  style step11 fill:#C5E6A1,stroke-width:0px\n  style step12 fill:#E1C3E6,stroke-width:0px\n  style step13 fill:#E1C3E6,stroke-width:0px\n  style step14 fill:#E1C3E6,stroke-width:0px\n  style step15 fill:#E1C3E6,stroke-width:0px\n  style step16 fill:#ADD8E6,stroke-width:0px</code></pre> <p></p> <p>The connections are made because the output of one step provides an input or argument for another step. This makes the workflow one long chain, or a series of connected input-method-output links. </p> <p>The videos below walk you through each step in this workflow.    </p>"},{"location":"workflows/grassland_bird_habitat/#start-a-new-script","title":"Start a new script","text":"<pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//\n//  Grassland bird habitat on Middlebury College Lands in Champlain Valley. \n//  \n//  Jeff Howarth \n//  Sept 30, 2023\n//\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#1-load-feature-collection-and-filter-by-attribute","title":"1. Load feature collection and filter by attribute","text":""},{"location":"workflows/grassland_bird_habitat/#template","title":"template","text":"<pre><code>// Load feature collection and filter by attribute.    \n\nvar output = ee.FeatureCollection(\"path\")\n.filter(ee.Filter.eq(\"propertyKey\", \"value\"))\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram","title":"diagram","text":"<pre><code>graph LR\n  method1[\"ee.FeatureCollection()\"] ;\n  arg_att1([pathname\\n\\nSTRING]) --&gt; method1;\n\n  method1 --&gt; method2[\".filter()\"];\n  method2 --&gt; method3([\"ee.Filter.eq()\"]);\n\n  method3 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n  arg_att2([property key\\n\\nSTRING]) --&gt; method3;\n  arg_att3([value\\n\\nSTRING]) --&gt; method3;\n\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  1. Load feature collection and filter by attribute.\n//\n//  Isolate Champlain Lowlands.\n// ---------------------------------------------------------------------------\n\nvar region = ee.FeatureCollection(\"projects/conservation-atlas/assets/regions/Ecoregion_07232023\");\n\nprint(\n\"STEP 1:\"\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#2-load-feature-collection-and-filter-by-location","title":"2. Load feature collection and filter by location","text":""},{"location":"workflows/grassland_bird_habitat/#template_1","title":"template","text":"<pre><code>// Load feature collection and filter by location.  \n\nvar output = ee.FeatureCollection(\"path\")\n.filterBounds(target)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_1","title":"diagram","text":"<pre><code>graph LR\n  method1[\"ee.FeatureCollection()\"] ;\n  arg_att1([path\\n\\nSTRING]) --&gt; method1;\n\n  method1 --&gt; method2[\".filterBounds()\"];\n  method2 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n  arg_att2([target\\n\\nGEOMETRY or FEATURE]) --&gt; method2;\n\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#E1C3E6,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_1","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_1","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  2. Load feature collection and filter by location,\n//\n//  Isolate College Lands in Champlain Valley.\n// ---------------------------------------------------------------------------\n\nvar college_lands = ee.FeatureCollection(\"projects/conservation-atlas/assets/cadastre/Midd_College_Parcels_withattributes\");\n\nprint(\n\"STEP 2:\"\n)\n;\n\nMap.centerObject();\nMap.setOptions();\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#3-define-study-region","title":"3. Define study region","text":""},{"location":"workflows/grassland_bird_habitat/#template_2","title":"template","text":"<pre><code>// Define study region  \n\nvar output = FC\n.union(maxError)       .geometry() .bounds(maxError) .buffer(distance, maxError)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_2","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nFEATURE COLLECTION/] --&gt; method1[\".union()\"] ;\n\n  method1 --&gt; method2[\".geometry()\"];\n  method2 --&gt; method3[\".bounds()\"];\n  method3 --&gt; method4[\".buffer()\"]\n  method4 --&gt; output&gt;output\\n\\nGEOMETRY];\n\n  arg_att1([maxError\\n\\nNUMBER]) --&gt; method1 ;\n  arg_att2([maxError\\n\\nNUMBER])  --&gt; method3 ;\n  arg_att3([distance\\n\\nNUMBER])  --&gt; method4 ;\n  arg_att4([maxError\\n\\nNUMBER])  --&gt; method4 ;\n\n\n  style input fill:#E1C3E6,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style method4 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px\n  style arg_att4 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_2","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_2","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n// 3. Define study region\n// ---------------------------------------------------------------------------\n\nvar bounds ;\n\nprint(\n\"STEP 3:\",\nbounds\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#4-load-an-image","title":"4. Load an image","text":""},{"location":"workflows/grassland_bird_habitat/#template_3","title":"template","text":"<pre><code>// Load an image.  \n\nvar output = ee.Image(\"path\")\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_3","title":"diagram","text":"<pre><code>graph LR\n  method1[\"ee.Image()\"] ;\n  arg_att1([path\\n\\nSTRING]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_3","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_3","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  4. Load an image\n//\n//  Import land cover image for Vermont.\n// ---------------------------------------------------------------------------\n\nvar lc ;\n\nvar lc_viz = {\nmin: 1,\nmax: 8,\npalette: [\n'#ABD998',    //   1. Tree Canopy  \n'#EBF09C',    //   2. Grass/Shrub \n'#f7f7f7',    //   3. Bare soil\n'#95E6D5',    //   4. Water\n'#525252',    //   5. Buildings    \n'#F7F7F7',    //   6. Roads\n'#cccccc',    //   7. 0ther pavement\n'#F7F7F7',    //   8. Railroads  \n]\n};\n\nprint(\n\"STEP 4:\", lc,\nlc.projection()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#5-reclassify-an-image","title":"5. Reclassify an image","text":""},{"location":"workflows/grassland_bird_habitat/#template_4","title":"template","text":"<pre><code>// Reclassify an image.  \n\nvar output = input.remap(\n[\"o\",\"l\",\"d\"],\n[\"n\",\"e\",\"w\"],\n);\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_4","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".remap()\"] ;\n  arg_att1([old values\\n\\nLIST]) --&gt; method1;\n  arg_att2([new values\\n\\nLIST]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_4","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_4","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  5. Reclassify an image\n//\n//  Make a binary image of grasslands.  \n// ---------------------------------------------------------------------------\n\nvar lc_binary ;\n\nprint(\n\"STEP 5:\",\nlc_binary,\nlc_binary.projection()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#6-clip-image-by-region","title":"6. Clip image by region","text":""},{"location":"workflows/grassland_bird_habitat/#template_5","title":"template","text":"<pre><code>// Clip image by region.  \n\nvar output = input.clip(region)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_5","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".clip()\"] ;\n  arg_att1([region or aoi\\n\\nGEOMETRY, FEATURE or\\nFEATURE COLLECTION]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_5","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_5","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  6. Clip image by region\n//\n//  Isolate grasslands in study region. \n// ---------------------------------------------------------------------------\n\nvar lc_binary_bounds ;\n\nprint(\n\"STEP 6:\",\nlc_binary_bounds,\nlc_binary_bounds.projection()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#7-select-by-pixel-value","title":"7. Select by pixel value","text":""},{"location":"workflows/grassland_bird_habitat/#template_6","title":"template","text":"<pre><code>// Select a pixel value (make a binary).\n\nvar output = input.ee(value)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_6","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".eq()\"] ;\n  arg_att1([value\\n\\nNUMBER]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_6","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_6","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  7. Select by pixel value.\n//\n//  Invert the grassland binary. \n// ---------------------------------------------------------------------------\n\nvar invert_binary ;\n\nprint(\n\"STEP 7:\",\ninvert_binary,\ninvert_binary.projection()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#8-compute-distance","title":"8. Compute distance","text":""},{"location":"workflows/grassland_bird_habitat/#template_7","title":"template","text":"<pre><code>// Compute distance with a euclidean kernel.   \n\nvar output = input\n.distance(\nee.Kernel.euclidean(radius, \"units\")\n)\n.reproject(\"crs\")       // When should you comment out this line?\n.unmask(value)          )\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_7","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".distance()\"] ;\n  method1 --&gt; method2([\"ee.Kernel.euclidean()\"])\n  arg_att1([radius\\n\\nNUMBER]) --&gt; method2;\n  arg_att2([units\\n\\nSTRING]) --&gt; method2;\n  method2 --&gt; method3[\".reproject()\"]\n  arg_att3([crs\\n\\nSTRING]) --&gt; method3;\n  method3 --&gt; method4(\".unmask()\")\n  arg_att4([value\\n\\nNUMBER]) --&gt; method4;\n  method4 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style method4 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px\n  style arg_att4 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_7","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_7","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  8. Compute distance \n//\n//  Calculate distance from edge of grasslands towards interior\n// ---------------------------------------------------------------------------\n\nvar crs = \"EPSG: 32145\"; // Vermont State Plane North American Datum 1983\n\nvar grassland_distance ;\n\nprint(\n\"Step 8:\",\ngrassland_distance,\ngrassland_distance.projection()\n)\n;\n\n// Here is a nice palette that looks good for distance when you reverse it.\n\nvar inferno = [\"#000004\", \"#320A5A\", \"#781B6C\", \"#BB3654\", \"#EC6824\", \"#FBB41A\", \"#FCFFA4\"].reverse();\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#9-select-by-a-threshold-value","title":"9. Select by a threshold value","text":""},{"location":"workflows/grassland_bird_habitat/#template_8","title":"template","text":"<pre><code>// Select by threshold value (and output a binary).\n\nvar output = input.gt(value)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_8","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".gt()\"] ;\n  arg_att1([value\\n\\nNUMBER]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_8","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_8","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  9. Select by threshold value \n//\n//  Isolate all pixels that are greater than 50 meters from grassland edge. \n// ---------------------------------------------------------------------------\n\nvar grassland_cores ;\n\nprint(\n\"Step 9:\",\ngrassland_cores,\ngrassland_cores.projection()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#10-zonal-overlay","title":"10. Zonal overlay","text":""},{"location":"workflows/grassland_bird_habitat/#template_9","title":"template","text":"<pre><code>// Zonal overlay.\n\nvar output = input.reduceRegions(\n{\ncollection: cutter,\nreducer: ee.Reducer(),\nscale: number,\ncrs: \"string\"\n}\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_9","title":"diagram","text":"<pre><code>graph LR\n  input[/\"input 'dough'\"\\n\\nIMAGE/] --&gt; method1[\".reduceRegions()\"] ;\n  arg_att1([\"collection 'cutter'\"\\n\\nFEATURE COLLECTION]) --&gt; method1;\n  arg_att2([reducer\\n\\nREDUCER]) --&gt; method1;\n  arg_att3([scale\\n\\nNUMBER]) --&gt; method1;\n  arg_att4([crs\\n\\nSTRING]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#E1C3E6,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px\n  style arg_att4 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_9","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_9","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  10. Zonal overlay \n//\n//  Find college parcels that overlap core grassland habitat. \n// ---------------------------------------------------------------------------\n\nvar college_with_core ;\n\nvar college_with_core_filter ;\n\nprint(\n\"STEP 10:\",\ncollege_with_core.size(),\ncollege_with_core_filter.size()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#11-mask-an-image","title":"11. Mask an image.","text":""},{"location":"workflows/grassland_bird_habitat/#template_10","title":"template","text":"<p>Case 1: to use an image to mask another image.</p> <pre><code>/// Use an image to mask another image.  \n\nvar output = input.updateMask(mask)\n;\n</code></pre> <p>Case 2: to use an image to mask itself.  </p> <pre><code>/// Use an image to mask itself.  \n\nvar output = input.selfMask()\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_10","title":"diagram","text":"<p>Case 1: to use an image to mask another image.</p> <pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".updateMask()\"] ;\n  arg_att1([mask\\n\\nIMAGE]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#C5E6A1,stroke-width:0px</code></pre> <p>Case 2: to use an image to mask itself.  </p> <pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".selfMask()\"] ;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_10","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_10","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  11. Mask an image\n//\n//  Ignore all pixels that are not grasslands. \n// ---------------------------------------------------------------------------\n\nvar grassland_cores_masked;      print(\n\"STEP 11:\",\ngrassland_cores_masked,\ngrassland_cores_masked.projection()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#12-make-objects","title":"12. Make objects","text":""},{"location":"workflows/grassland_bird_habitat/#template_11","title":"template","text":"<pre><code>// Make objects from a binary image. \n\nvar output = input.reduceToVectors(\n{\nreducer: ee.Reducer(),\ngeometry: aoi, // area of interest   \nscale: number,\ngeometryType: \"string\",\neightConnected: boolean,  maxPixels: 1e12, geometryInNativeProjection: boolean }\n);\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_11","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".reduceToVectors()\"] ;\n  method1 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n  arg_att1([reducer\\n\\nREDUCER]) --&gt; method1;\n  arg_att2([aoi\\n\\nGEOMETRY]) --&gt; method1;\n  arg_att3([scale\\n\\nNUMBER]) --&gt; method1;\n  arg_att4([geometryType\\n\\nSTRING]) --&gt; method1;\n  arg_att5([eightConnected\\n\\nBOOLEAN]) --&gt; method1;\n  arg_att6([maxPixels\\n\\nNUMBER]) --&gt; method1;\n  arg_att7([geometryInNativeProjection\\n\\nBOOLEAN]) --&gt; method1;\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n\n  style arg_att1 fill:#ADD8E6,stroke-width:0px\n  style arg_att2 fill:#E1C3E6,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px\n  style arg_att4 fill:#DCDCDC,stroke-width:0px\n  style arg_att5 fill:#DCDCDC,stroke-width:0px\n  style arg_att6 fill:#DCDCDC,stroke-width:0px\n  style arg_att7 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_11","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_11","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  12. Make objects. \n//\n//  Identify contiguous regions of grassland. \n// ---------------------------------------------------------------------------\n\nvar grassland_objects ;\n\nprint(\n\"STEP 12:\",\ngrassland_objects\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#13-select-by-location","title":"13. Select by location","text":""},{"location":"workflows/grassland_bird_habitat/#template_12","title":"template","text":"<pre><code>// Select by location.  \n\nvar output = input\n.filterBounds(target)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_12","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nFEATURE COLLECTION/] --&gt; method2[\".filterBounds()\"];\n  method2 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n  arg_att1([target\\n\\nGEOMETRY or FEATURE]) --&gt; method2;\n\n  style input fill:#E1C3E6,stroke-width:0px  \n  style method2 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#E1C3E6,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_12","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_12","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  13. Select by location.\n//\n//  Isolate grasslands on College Lands. \n// ---------------------------------------------------------------------------\n\nvar college_grasslands ;\n\nprint(\n\"STEP 13:\",\ncollege_grasslands.size(),\ncollege_grasslands.first()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#14-map-function-over-collection","title":"14. Map function over collection","text":""},{"location":"workflows/grassland_bird_habitat/#template_13","title":"template","text":"<pre><code>// Step 1: Write a function that takes a feature input. \n\nvar myFunction = function(feature) {\n\nvar crs = string ; var area = feature.area(1, crs) ;\n\nreturn feature.set(\"area\", area) ;\n}\n\n// Step 2: Apply the function to every feature in a collection.   \n\nvar output = input.map(myFunction)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_13","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nFEATURE COLLECTION/] --&gt; method2[\".map()\"];\n  method2 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n  arg_att1([getArea\\n\\nFUNCTION]) --&gt; method2;\n\n  style input fill:#E1C3E6,stroke-width:0px  \n  style method2 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#ADD8E6,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_13","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_13","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  14. Compute spatial attributes.\n//\n//  Calculate area and perimeter-area ratios.\n// ---------------------------------------------------------------------------\n\nvar getArea = function(f) {\nvar crs = \"EPSG: 32145\"; // Vermont State Plane North American Datum 1983\nvar area = f.area(1, crs).divide(4046.86);\nvar pa = f.perimeter(1, crs).divide(f.area(1, crs));\nreturn f.set({\"area\": area, \"pa\": pa});\n};\n\nvar grasslands_with_criteria ;\n\nprint(\n\"STEP 14:\",\ngrasslands_with_criteria.size(),\ngrasslands_with_criteria.first()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#15-select-by-two-attributes","title":"15. Select by two attributes","text":""},{"location":"workflows/grassland_bird_habitat/#template_14","title":"template","text":"<pre><code>// Select features from a collection by two attributes.\n\nvar output = input.filter(\nee.Filter.and(\nee.Filter.first(\"property\",\"value\"),\nee.Filter.second(\"property\",\"value\")\n)\n);\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_14","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nFEATURE COLLECTION/] --&gt; method1[\".filter()\"];\n  method1 --&gt; method2([\"ee.Filter.and()\"])\n\n  method3([\"ee.Filter.gt()\"]) --&gt; method2;\n  method4([\"ee.Filter.lte()\"]) --&gt; method2;\n\n  arg_att1([property\\n\\nSTRING]) --&gt;method3;\n  arg_att2([value\\n\\nNUMBER]) --&gt;method3;\n\n  arg_att3([property\\n\\nSTRING]) --&gt;method4;\n  arg_att4([value\\n\\nNUMBER]) --&gt;method4;\n\n  method2 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n\n  style input fill:#E1C3E6,stroke-width:0px  \n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style method4 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px\n  style arg_att4 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_14","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_14","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  15. Select by two attributes\n//\n//  Identify grasslands that meet both criteria.\n// ---------------------------------------------------------------------------\n\nvar best_grassland_habitat ;\n\nprint(\n\"STEP 15:\",\nbest_grassland_habitat.size(),\nbest_grassland_habitat.first()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#16-export-to-ee-asset","title":"16. Export to EE Asset","text":""},{"location":"workflows/grassland_bird_habitat/#template_15","title":"template","text":"<pre><code>// Export feature collection to Asset.  \n\nExport.table.toAsset({\ncollection: FeatureCollection, description: \"string\", assetId: \"string\"\n}\n);\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_15","title":"diagram","text":"<pre><code>graph LR\n  method1[\"Export.table.toAsset()\"] --&gt; output&gt;output\\n\\nTASK];\n\n  arg_att1([collection\\n\\nFEATURE COLLECTION]) --&gt; method1;\n  arg_att2([description\\n\\nSTRING]) --&gt; method1\n  arg_att3([assetId\\n\\nSTRING]) --&gt; method1\n\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#ADD8E6,stroke-width:0px\n  style arg_att1 fill:#E1C3E6,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_15","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_15","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  16. Export to EE Asset\n//\n//  To run workflow with crs condition on distance (Step 10).\n// ---------------------------------------------------------------------------\n\nvar x_name = \"Best_college_grasslands_0930_2023\"; Export.table.toAsset({\ncollection: best_grassland_habitat, description: x_name, assetId: x_name\n}\n);\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"workflows/image_collections/","title":"Basic Image Collections","text":""},{"location":"workflows/image_collections/#introduction","title":"Introduction","text":"<p>This tutorial introduces a common workflow for processing and visualizing image collections with Earth Engine. You will use a MODIS Land Surface Temperature product to make a map that shows the mean LST for January 2023 in degrees Celsius. By the end of the tutorial, you should have a map that looks like the image below. </p> <p></p>"},{"location":"workflows/image_collections/#start-a-new-script","title":"Start a new script","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  TITLE:      wk02_tutorial.js\n//  AUTHOR:     your name\n//  DATE:       today's date\n//  PURPOSE:    A basic workflow for processing image collections.     \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n\n// Load check module. \n\nvar check = require('users/jhowarth/eePrimer:modules/checks.js');\n\n// ----------------------------------------------------------------\n//  Process the image collection.\n// ----------------------------------------------------------------\n</code></pre>"},{"location":"workflows/image_collections/#load-image-collection","title":"Load image collection","text":"<pre><code>// Step 1: Load image collection\n\nvar step_1 = ee.ImageCollection();\n</code></pre>"},{"location":"workflows/image_collections/#filter-by-date","title":"Filter by date","text":"<pre><code>// Step 2: Filter image collection by date.\n\nvar step_2 = step_1.filter(ee.Filter.date());\n</code></pre>"},{"location":"workflows/image_collections/#select-band","title":"Select band","text":"<pre><code>// Step 3: Select band.\n\nvar step_3 = step_2.select();\n</code></pre>"},{"location":"workflows/image_collections/#reduce-to-image","title":"Reduce to image","text":"<pre><code>// Step 4: Reduce image collection.\n\nvar step_4 = step_3;\n</code></pre>"},{"location":"workflows/image_collections/#scale-data-if-necessary","title":"Scale data (if necessary)","text":"<pre><code>// Step 5: Apply scalar (if EE data catalog tells you the data are scaled).\n\nvar step_5 = step_4;\n</code></pre>"},{"location":"workflows/image_collections/#convert-units-if-necessary","title":"Convert units (if necessary)","text":"<pre><code>// Step 6: Convert units (if units need conversion).\n\nvar step_6 = step_5;\n</code></pre>"},{"location":"workflows/image_collections/#visualize-results-as-layer","title":"Visualize results as layer","text":"<pre><code>// ----------------------------------------------------------------\n//  Visualize results as layer.\n// ----------------------------------------------------------------\n\n//  Set base map.\n\n\n\n//  Load community palettes. \n\nvar palettes = require('users/gena/packages:palettes');\n\n// print('Community palettes', palettes);\n\n//  Define visualization parameters. \n\n// var viz = {\n//   bands: ,\n//   min: ,\n//   max: , \n//   palette: palettes.colorbrewer.RdBu[11]\n// };\n\n//  Display the data values with the visualization parameters.\n\n// Map.addLayer();\n</code></pre>"},{"location":"workflows/image_collections/#add-a-legend","title":"Add a legend","text":"<pre><code>// ---------------------------------------------------------------------\n//  Add a legend.\n// ---------------------------------------------------------------------\n\n//  Load cart module.\n\nvar cart = require('users/jhowarth/eePrimer:modules/cart.js');\n\n// Call makeGradientLegend function and pass three parameters.\n\nvar legend = cart                                           // module\n.makeGradientLegend(                                      // function\nviz,                                                    // viz parameters\n'degrees (C)',                                          // a label for legend\n'bottom-left'                                           // position on map\n)\n;\n\n// Add legend to map. \n\n// Map.add();\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"}]}