{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"A primer on cloud-based maps of landscape change","text":"<p>Jeff Howarth Associate Professor of Geography Middlebury College, Middlebury, Vermont, USA jhowarth@middlebury.edu </p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"introduction/","title":"Introduction","text":"<p>These materials aim to help undergraduate students in Geography and Environmental Studies learn geospatial methods for investigating changes in the global environment. While most of the lessons introduce methods and workflows in Google Earth Engine, I also show students around QGIS and how to move between the two platforms. The ultimate goal of the materials is to help students learn timeless concepts of geospatial analysis that transcend specific software platforms. That is the goal at least.  </p>"},{"location":"glossary/anomalies/","title":"Anomalies","text":"<p>DRAFT </p>"},{"location":"glossary/anomalies/#introduction","title":"Introduction","text":"<p>Anomalies report differences between one or more parts and the whole. They are comparisons that investigate how something \u201cdiffers from normal\u201d. </p>"},{"location":"glossary/anomalies/#temporal-case","title":"Temporal Case","text":"<p>The temporal case compares a short-interval of time to a longer interval of time. Temporal anomalies are commonplace in discussions of climate change.  </p>"},{"location":"glossary/anomalies/#spatial-case","title":"Spatial case","text":"<p>The spatial case compares a sub-region of space to a larger region that includes the sub-region. Spatial anomalies are commonplace in discussions of environmental justice and heterogeneity. Spatial anomalies challenge the ecological fallacy, or the idea that the characteristics of a population hold for all individuals of the population.    </p>"},{"location":"glossary/fire-scars/","title":"Fire scars","text":""},{"location":"glossary/fire-scars/#key-terms","title":"Key terms","text":"<ul> <li>Fire intensity: intensity of fire while active  </li> <li>Burn severity: degree to which fire alters an area      </li> </ul>"},{"location":"glossary/fire-scars/#fire-scars","title":"Fire scars","text":"<p>Here are a few examples of false color composites that show fire scars on a landscape.  </p> <p> <p> </p> <p>Woolsey Burn Scar</p> <p> </p> <p>The Scars of Mendocino</p> <p></p> <p>Thomas Fire Burn Scar</p> <p></p>"},{"location":"glossary/fire-scars/#normalized-burn-rato","title":"Normalized Burn Rato","text":"<p>The images above all use data in three bands to show scars with additive color. In order to document a fire scar with a single band, we can compute a normalized band ratio.</p> <p> <p>= Band A - Band B / Band A + Band B</p> <p> </p> <p>For fire scars, the normalized burn ratio works with the NIR and SWIR2 bands for Band A and Band B, respectively.  </p> <p> <p></p> <p> </p> <p>To understand how this works, we need to consider the spectral signatures of health vegetation versus bare ground.  </p> <p> <p> </p> <p>A high NBR indicates healthy vegetation while a low NBR value indicates bare ground and recently burnt areas.   </p> <p></p>"},{"location":"glossary/fire-scars/#burn-severity","title":"Burn severity","text":"<p>We can then compare the normalized burn ratio following a fire to the normalized burn ratio of the same season prior to the fire. The difference in the two ratios represents a measure of the burn severity.   </p> <p> <p> </p> <p> </p> <p>Here is an example for two lightning complex fires in California.    </p> <p> <p></p> <p> </p> <p>Assessing California Fire Scars </p>"},{"location":"glossary/fire-scars/#severity-classes","title":"Severity classes","text":"<p>Although the real-world impacts of this burn severity index likely varies geographically, the US Geological Survey uses a standard classification scheme to help fire managers compare the impacts of fire across space and over time.   </p> <p></p> <p>USGS Severity classes </p>"},{"location":"glossary/landsat-lexicon/","title":"Landsat lexicon","text":"<p>There are a number of different Landsat collections in the Earth Engine Data Catalog. To be able navigate the collection, you should be comfortable with the following key terms.   </p>"},{"location":"glossary/landsat-lexicon/#missions","title":"Missions","text":"<p>The Landsat program consists of a series of missions. Each mission deploys one or more sensors on a satellite. Very practically, the mission\u2019s name denotes the launch sequence. Landsat 1 launched July 23, 1972. Landsat 9 launched September 27, 2021.  </p>"},{"location":"glossary/landsat-lexicon/#sensors","title":"Sensors","text":"<p>The sensors onboard the Landsat satellites have steadily aimed to improve upon Norwood\u2019s original MSS.  </p> <ul> <li>MSS: Multispectral Scanner  </li> <li>TM: Thematic Mapper  </li> <li>ETM+: Enhanced Thematic Mapper  </li> <li>OLI/OLI-2: Operational Land Imager    </li> <li>TIRS/TIRS-2: Thermal Infrared Sensor</li> </ul> <p></p>"},{"location":"glossary/landsat-lexicon/#collections","title":"Collections","text":"<p>There have been two major reprocessing efforts by USGS to improve data quality. Collection 2 is the most recent and has the best geolocation accuracy which improves time series analyses.    </p>"},{"location":"glossary/landsat-lexicon/#tiers","title":"Tiers","text":"<p>Within a collection, Tier 1 data have the highest radiometric and positional quality. USGS recommends using Tier 1 data for all future time-series analysis.  </p>"},{"location":"glossary/landsat-lexicon/#levels","title":"Levels","text":"<p>Distinguishes the level of data processing applied to products.    </p> <ul> <li> <p>Level-1 includes processing to improve locational accuracy of data.  </p> </li> <li> <p>Level-2 products are built from Level 1, but also provide atmospheric correction to create surface reflectance and surface temperature products. Level-2 science products also include spectral indices derived from surface reflectance products.  </p> </li> <li> <p>Level-3 products are built from Level-2 products and include Analysis Ready Data (ARD), including Fractional Snow Covered Area and Burned Area, and Scene-based Inputs, including Provisional Actual Evapotranspiration.   </p> </li> </ul>"},{"location":"glossary/landsat-lexicon/#what-do-the-sensors-measure","title":"What do the sensors measure?","text":"<p>Here are two key terms:  </p> <ul> <li> <p>Radiance is the amount of energy measured by a sensor, typically reported in units of watt per pixel area. </p> </li> <li> <p>Reflectance is the proportion (ratio) of the amount of energy reflected from the surface versus the total amount of energy striking the surface. </p> </li> </ul>"},{"location":"glossary/landsat-lexicon/#whatof-where-do-the-sensors-measure","title":"What/of where do the sensors measure?","text":"<p>Here are three common terms:    </p> <ul> <li> <p>Raw scenes: DN (digital number) values represent scaled, calibrated at-sensor radiance.  </p> </li> <li> <p>Top of atmosphere (TOA): calibrated top-of-atmosphere reflectance.  </p> </li> <li> <p>Surface reflectance: atmospherically corrected surface reflectance and land surface temperature.     </p> </li> </ul>"},{"location":"glossary/lst/","title":"Land surface temperature","text":""},{"location":"glossary/lst/#definition","title":"Definition","text":"<p>\u201cLand surface temperature (LST) is a measurement of how hot the land is to the touch. It differs from air temperature (the temperature given in weather reports) because land heats and cools more quickly than air.\u201d    </p> <p>source </p>"},{"location":"glossary/lst/#applications","title":"Applications","text":"<p>\u201cUrban Heat Islands </p> <p>\u201cSummer in the City is Hot, but Some Neighborhoods Suffer More\u201d </p> <p>\u201cThe Effects of Historical Housing Policies on Resident Exposure to Intra-Urban Heat: A Study of 108 Urban Areas\u201d </p> <p>\u201cRacist Housing Practices From the 1930s Linked to Hotter Neighborhoods Today </p> <p>\u201cHow Decades of Racist Housing Policy Left Neighborhoods Sweltering </p>"},{"location":"glossary/lst/#data-products","title":"Data products","text":"<p>Earth Observatory </p>"},{"location":"glossary/lst/#module","title":"Module","text":"<p>Sophia Ermida </p> <ul> <li> <p>Landsat_SMW_LST </p> </li> <li> <p>\u201cGoogle Earth Engine Open-Source Code for Land Surface Temperature Estimation from the Landsat Series\u201d </p> </li> </ul>"},{"location":"glossary/lst/#explore","title":"Explore","text":"<p>Link to app </p>"},{"location":"intro/gee_gui/","title":"GEE User Interface","text":""},{"location":"intro/gee_gui/#introduction","title":"Introduction","text":"<p>In this course, we will work with Google Earth Engine via the GEE Code Editor. The tutorial below provides an overview of the different components of the Code Editor\u2019s graphical user interface (GUI).   </p>"},{"location":"intro/gee_gui/#tutorial","title":"Tutorial","text":"<p>I split this tutorial into separate videos. If I show code in the video, you can find the snippets below each video.  </p> <p>To follow along with the videos, you will need to open the GEE Code Editor in a web browser. Please see the previous tutorial if you forget how to access the editor. </p>"},{"location":"intro/gee_gui/#explore-the-map-interface","title":"Explore the map interface.","text":""},{"location":"intro/gee_gui/#write-a-header","title":"Write a header.","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Name:     gee_ui.js \n//  Author:   Jeff Howarth\n//  Date:     9/7/2023 \n//  Purpose:  Introduce Earth Engine Graphical User Interface (Code Editor)\n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  \n</code></pre>"},{"location":"intro/gee_gui/#center-map-and-set-zoom-level","title":"Center map and set zoom level.","text":"<pre><code>//  Center and set zoom level the map.\n\nMap.setCenter(\n-50,                  // Longitude\n40,                  // Latitude\n3                    // Zoom level\n)\n;\n</code></pre>"},{"location":"intro/gee_gui/#set-the-default-base-map","title":"Set the default base map.","text":"<pre><code>//  Set the default base map. \n\nMap.setOptions('SATELLITE');\n</code></pre>"},{"location":"intro/gee_gui/#load-lst-module","title":"Load LST module.","text":"<pre><code>//  Load module\n\nvar tool = require('users/jhowarth/eePrimer:modules/modis_lst_demo.js');\n\n// You can then call functions in the module as methods of this object.\n\ntool.makeMap();\n</code></pre>"},{"location":"intro/gee_gui/#inspect-data","title":"Inspect data.","text":"<pre><code>// Print info about map layers. \n\nprint(\"Layers on this map:\", Map.layers());\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.</p>"},{"location":"intro/history-remote-sensing/","title":"History of Remote Sensing","text":"<p>Here is a brief history of remote sensing, or efforts to capture pictures of the Earth from a distance. It outlines early experiments with different vehicles for carrying cameras that captured pictures on film and ends with the birth of the digital age.     </p>"},{"location":"intro/history-remote-sensing/#beginning-with-balloons","title":"Beginning with Balloons","text":"<p>In 1858, \u201cNadar\u201d (aka Gaspard-F\u00e9lix Tournachon) took a picture of Paris from a hot air balloon and the field of remote sensing was born. </p> <p> </p> <p>Nadar with His Wife, Ernestine, in a Balloon</p> <p>The picture below is an example of his work, though it is not the first image he took.  </p> <p></p> <p>Aerial view of Paris, 1868 </p> <p>In 1860, James Wallace Black photographed Boston from Samuel King\u2019s hot air balloon The Queen of the Air.  </p> <p></p> <p>Balloon View of Boston 1860 </p> <p>In July 1863, Wendell Holmes helped popularize the image with a piece in the Atlantic Monthly:  </p> <p>Boston, as the eagle and wild goose see it, is a very different object from the same place as the solid citizen looks up at its eaves and chimneys. The Old South [Meeting House] and Trinity Church [left center and lower right] are two landmarks not to be mistaken. Washington Street [bottom] slants across the picture as a narrow cleft. Milk Street [left center] winds as if the old cowpath which gave it a name had been followed by the builders of its commercial palaces. Windows, chimneys, and skylights attract the eye in the central parts of the view, exquisitely defined, bewildering in numbers\u2026As a first attempt [at aerial photography] it is on the whole a remarkable success; but its greatest interest is in showing what we may hope to see accomplished in the same direction.  </p> <p>source</p> <p>Balloon aerial photography is still a popular hobby; search internet for \u201cballoon aerial photography\u201d.</p>"},{"location":"intro/history-remote-sensing/#rocket-photography","title":"Rocket photography","text":"<p>In 1897, Alfred Nobel successfully took a photography from a rocket.  </p> <p> <p> </p> <p>The Alfred Nobel rocket camera</p> <p></p> <p>Twenty years later, Alfred Maul fired a rocket into the atmosphere that released a camera with a parachute and photographed the German countryside on it\u2019s descent.  </p> <p> <p></p> <p>Taking photographs from a skyrocket</p> <p> </p>"},{"location":"intro/history-remote-sensing/#i-photography-pigeons","title":"i  photography + pigeons =","text":"<p>Julius Neubranner loved photography and pigeons. In 1903, he brought his twin passions together and patented his \u201cbreast mounted pigeon camera\u201d.</p> <p> <p> </p> <p>source</p> <p> </p> <p>source</p> <p></p> <p>Pigeon photography is currently a niche hobby; search internet for \u201cpigeon aerial photography\u201d for the latest. </p>"},{"location":"intro/history-remote-sensing/#kite-photography","title":"Kite photography","text":"<p>George Lawrence used kites to hoist a camera 2000 feet above San Francisco and photographed the city after the 1906 earthquake. This is an early (if not the first) example of using aerial photography to document the aftermath of a \u201cnatural\u201d disaster.   </p> <p></p> <p>source</p> <p>Kite photography is still an active hobby enjoyed by more than a few people, particularly people with more time than money like graduate students; search internet for \u201ckite aerial photography\u201d if you are interested. </p>"},{"location":"intro/history-remote-sensing/#from-planes","title":"From planes","text":"<p>In 1909, Wilbur Wright took the first photograph from a plane. The method developed rapidly during World War I.  </p> <p></p> <p>Lieutenant S C Thynne circa 1916 </p> <p>Air photographs provided reconnaissance of battlefield theatres that were then schematized into maps by cartographers. </p> <p> <p> </p> <p></p> <p>German trenches near Hebuterne 1916 </p> <p> </p>"},{"location":"intro/history-remote-sensing/#early-satellites","title":"Early satellites","text":"<p>The Corona Photographic Surveillance satellites captured photographs of earth on film. They delivered the film to the dark room by releasing a canister which would eventually fall out of orbit, enter the atmosphere, and release a parachute, which a plane would then retrieve in flight.  </p> <p> </p> <p>source</p>"},{"location":"intro/history-remote-sensing/#the-mother-of-landsat","title":"The mother of Landsat","text":"<p>Q: I\u2019ve seen an image of Yosemite National Park\u2019s Half Dome taken by a Landsat 1 prototype. How did that come about?</p> <p>A: When NASA said, \u201cHow do you know this damn thing will work?\u201d we came up with the idea of taking the breadboard around to national parks. The Half Dome image was a tremendous hit.</p> <p>source </p> <p> </p> <p>Virginia Tower Norwood during her second or third year at MIT. Source: MIT Technology Review</p> <p>For Virginia Tower Norwood\u2019s biography, please read this article.   </p>"},{"location":"intro/history-remote-sensing/#summary","title":"Summary","text":"<p>Early efforts used a variety of vehicles to capture scenes on Earth from above on film. Even the first satellite systems used film. Virginia Norwood developed the first proof of the multiple spectral scanning concept. She lead the team that showed how it was possible to capture digital data in multiple spectral bands and the digital age of remote sensing was born.  </p>"},{"location":"intro/js101/","title":"Javascript 101","text":""},{"location":"intro/js101/#introduction","title":"Introduction","text":"<p>To use GEE, you will need to write code.    </p> <p>In this course, we will use the GEE Code Editor, which means that we will be coding in JavaScript.    </p>"},{"location":"intro/js101/#tutorial","title":"Tutorial","text":"<p>I made the videos below to help walk you through through some basic JavaScript syntax, data types, and methods. I broke the tutorial into a set of short videos, rather than recording one long one. You should work through all the videos in the set.     </p> <p>To follow along, you will need to open the GEE Code Editor in a web browser.  </p> <p>I recommend that you use Google Chrome when working with the GEE Code Editor.     </p> <p>This is the web address to the Code Editor: </p> <p>https://code.earthengine.google.com/</p> <p>Honestly, you might as well bookmark that page and move the bookmark to the left corner of your toolbar. You will be visiting this site a lot over the semester.  </p> <p>Below the video, you should find snippets for the code shown in the video. If you hover your cursor over the upper-right corner of the snippet, you should see a little button that you can click to copy the code. You can then paste the code into the Code Editor while you watch the video. My intention is to save you some time and reduce errors that come from typos.  </p>"},{"location":"intro/js101/#quick-tour","title":"Quick tour","text":""},{"location":"intro/js101/#new-repo-save-file","title":"New Repo, Save File","text":""},{"location":"intro/js101/#data-types-1","title":"Data types (1)","text":""},{"location":"intro/js101/#line-comment","title":"Line Comment","text":"<pre><code>// This is a line comment. \n</code></pre>"},{"location":"intro/js101/#string","title":"String","text":"<pre><code>'Hello, world'  // Single quotes defines a string. \n</code></pre>"},{"location":"intro/js101/#variable","title":"Variable","text":"<pre><code>// Use var keyword to define a variable to store data. \n\nvar hello = 'Hello, world!' // This variable stores a string. \n</code></pre>"},{"location":"intro/js101/#semi-colon","title":"Semi-colon","text":"<pre><code>// End statements with semi-colons so that the editor does not complain.\n\nvar hello_again = 'Hola Mundo';\n</code></pre>"},{"location":"intro/js101/#double-quotes","title":"Double quotes","text":"<pre><code>// You can also define strings with double quotes. \n\nvar who_dat = \"Who's there?\";\n</code></pre>"},{"location":"intro/js101/#parentheses","title":"Parentheses","text":"<pre><code>// You can pass variables to functions within parentheses. \n\nprint(hello_again);\n</code></pre>"},{"location":"intro/js101/#comma","title":"Comma","text":"<pre><code>// You can pass more than one variable separated by commas.\n\nprint(hello_again, who_dat);\n</code></pre>"},{"location":"intro/js101/#data-types-2","title":"Data types (2)","text":""},{"location":"intro/js101/#number","title":"Number","text":"<pre><code>// This variable stores a number. \n\nvar year = 2023;\n</code></pre>"},{"location":"intro/js101/#list","title":"List","text":"<pre><code>// Square brackets defines a list. \n\nvar some_vt_towns = ['Middlebury', 'New Haven', 'Bristol'];\n</code></pre>"},{"location":"intro/js101/#index","title":"Index","text":"<pre><code>// Use square brackets after list object to call index of items in list.\n\nprint(some_vt_towns, some_vt_towns[0]);\n</code></pre>"},{"location":"intro/js101/#methods","title":"Methods","text":"<pre><code>// Use dot notation to call methods associated with the data type. \n\nprint(some_vt_towns.sort());\n</code></pre>"},{"location":"intro/js101/#data-types-3","title":"Data types (3)","text":""},{"location":"intro/js101/#dictionary","title":"Dictionary","text":"<pre><code>// Use curly brackets (or braces) to define dictionaries. \n\nvar midd = {\n\"name\": \"Middlebury\",  // Dictionaries are composed of key:value pairs.\n\"pop_2010\": 8496,\n\"pop_2020\": 9152\n};\n\nprint('Middlebury', midd);\n</code></pre>"},{"location":"intro/js101/#key-values","title":"Key values","text":"<pre><code>// Use dot notation to call the value of object key.  \n\nprint(midd.name);\n\nprint(\"Population change\", midd.pop_2020 - midd.pop_2010);\n</code></pre>"},{"location":"intro/js101/#data-types-4","title":"Data types (4)","text":""},{"location":"intro/js101/#functions","title":"Functions","text":"<pre><code>// Functions can be defined as a way to reuse code and make it easier to read.  \n\nvar i_love_function = function(some_string) {\nreturn 'I love ' + some_string + '!';\n};\n\nprint(i_love_function('maps'));\n</code></pre>"},{"location":"intro/js101/#modules","title":"Modules","text":"<pre><code>// Modules can be used to share functions across multiple scripts by:\n\n// 1. storing the module as a variable,\n\nvar tool = require('users/jhowarth/eePrimer:modules/tissot.js');\n\n// 2. calling functions in the module as methods of this variable.\n\ntool.drawTissot();\n</code></pre>"},{"location":"intro/js101/#mercator-distortion","title":"Mercator distortion","text":"<p>The True Size of</p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.</p>"},{"location":"intro/qgis_gui/","title":"QGIS User Interface","text":""},{"location":"intro/qgis_gui/#introduction","title":"Introduction","text":"<p>QGIS is a powerful desktop GIS, but also a labyrinth of point-and-clicks. This tutorial provides a very brief introduction to the graphical user interface (GUI).  </p>"},{"location":"intro/qgis_gui/#graphical-user-interface-gui","title":"Graphical User Interface (GUI)","text":""},{"location":"intro/qgis_gui/#working-with-a-project","title":"Working with a Project","text":""},{"location":"intro/qgis_gui/#add-a-google-basemap-layer","title":"Add a Google basemap layer","text":""},{"location":"intro/qgis_gui/#google-satellite","title":"Google satellite","text":"<pre><code>https://mt1.google.com/vt/lyrs=s&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre>"},{"location":"intro/qgis_gui/#google-hybrid","title":"Google hybrid","text":"<pre><code>https://mt1.google.com/vt/lyrs=y&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre>"},{"location":"intro/qgis_gui/#google-terrain","title":"Google terrain","text":"<pre><code>https://mt1.google.com/vt/lyrs=p&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre>"},{"location":"intro/qgis_gui/#google-map","title":"Google map","text":"<pre><code>https://mt1.google.com/vt/lyrs=m&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre>"},{"location":"intro/qgis_gui/#de-emphasized-road-map","title":"De-emphasized road map","text":"<pre><code>https://mt1.google.com/vt/lyrs=r&amp;x={x}&amp;y={y}&amp;z={z}\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.</p>"},{"location":"rudiments/additive_color/","title":"In Additive Color","text":""},{"location":"rudiments/additive_color/#introduction","title":"Introduction","text":"<p>We see color because light enters our eyes. </p> <p>Light often enters our eyes because it reflects off an object\u2019s surface. We see color in the textiles of our clothing, the paint on a wall, the ink in a book, the plastic of a bottle. In all these cases, we see color because objects absorb some parts of the visible spectrum and reflect the difference.  </p> <p>Many people learn how color works by working with one of these materials. As a result, many people think that the primary colors are red, yellow, and blue and secondary colors are made by mixing these primaries: blue and yellow make green, red and yellow make orange, and red and blue make violet. </p> <p>This can make the following fact a little confusing: a computer monitor makes yellow by mixing red and green. </p> <p> <pre><code>graph LR\n  red[\"R\"]  --&gt; yellow[\" Y \"]  \n  green[\" G \"] --&gt; yellow  \n\n  style red fill:#FF0000,stroke-width:0px\n  style green fill:#00FF00,stroke-width:0px\n  style yellow fill:#FFFF00,stroke-width:0px</code></pre> <p></p> <p>This is because computer monitors emit light, rather than reflect it. As a result, computer monitors create color with the additive color system. This is a powerful method for visualizing data in images. This page aims to help you better understand how this color system works. </p>"},{"location":"rudiments/additive_color/#color-blindness","title":"Color blindness","text":"<p>Before we continue, we should first understand that not all people see color the same way. For example, about 6% of men will see the graphic above like this:</p> <p> <p></p> <p></p> <p>This is a common form of red-green color blindness called deuteranopia. I use a little program called Color Oracle to check how colors that I use on maps will look to people with different forms of color blindness in an effort to make information universally accessible. Using additive color to visualize images, however, challenges goals of universal design and some people may have difficulty reading RGB composites or will need to learn how to read them with additional scaffolding. If you know that you see colors differently, or if the two figures above do not look different to you, please be in contact with me so that we can figure out strategies to make this portion of the course accessible to you. Thank you.  </p>"},{"location":"rudiments/additive_color/#first-color-image","title":"First color image","text":"<p>Tartan Ribbon, by Thomas Sutton and James Clerk Maxwell, 1861 </p> <p></p> <p>Tartan Montage, by Celtus, 2008 </p>"},{"location":"rudiments/additive_color/#additive-color-system","title":"Additive color system","text":"<p>In the additive color system, three primary colors (red, green, blue) make three secondary colors (yellow, magenta, and cyan). The absence of all three primaries makes black, while full amounts of the three primaries make white.  </p> <p></p> <p>You can recreate these colors and explore other intermediary colors with the RGB mixer below.  </p> <p> </p>"},{"location":"rudiments/additive_color/#rgb-composites","title":"RGB Composites","text":"<p>Additive color is a powerful method to visualize pixels values across three rasters all at once. The image below shows an example. The image contains three bands that represent the brightness of nighttime lights in three different years (2013, 2003, 1993). For each band, the image displays brightness value with a different color channel; it shows pixel values in the first band (2013) with red, pixel values in the second band (2003) with green, and pixel values in the third band (1993) with blue. The result is called an RGB composite. The order of the bands (1,2,3) determines the colors used to display the band\u2019s pixel values (RGB).   </p> <p></p> <p>Change in nighttime lights 1993 - 2013, Shanghai, China</p>"},{"location":"rudiments/additive_color/#what-are-nighttime-lights","title":"What are nighttime lights?","text":"<p>Night Lights Change in the Middle East </p> <p>Old Night Vision Meets New </p> <p>DMSP OLS </p> <p>VIIRS Nighttime Lights</p> <p></p>"},{"location":"rudiments/additive_color/#workflow-for-image","title":"Workflow for image","text":"<p>The diagram below outlines how I used additive color to show changes in the DMSP OLS dataset with Earth Engine.  </p> <p></p>"},{"location":"rudiments/additive_color/#exploring-additive-color","title":"Exploring additive color","text":"<p>You can use the app below to explore this RGB composite and become more familiar with how additive color works as a method for visualizing geographic change.   </p> <p> </p> <p>Link to app </p>"},{"location":"rudiments/additive_color/#temporal-scale-and-change","title":"Temporal scale and change","text":"<p>You can also use the app to think a little about how the temporal scale of the change image may influence the kinds of change that you can see.   </p> <p> Temporal Concepts Changes in the Night image Value Average brightness of stable lights Resolution 1 year Interval 10 years Extent 20 years <p> </p> <p>What do the different visual patterns (Holiday Lights, Aurora, Heat, and Red Giant) tell you about the temporal characteristics of the physical changes to the Earth\u2019s surface?</p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"rudiments/hello_feature_collection/","title":"Hello Feature Collection","text":""},{"location":"rudiments/hello_feature_collection/#introduction","title":"Introduction","text":"<p>The videos below introduce geometry and feature objects in Google Earth Engine. They walk you through how to import a table as an asset, how to construct a feature from scratch in the Code Editor, and how to convert vector into raster in Earth Engine.  </p>"},{"location":"rudiments/hello_feature_collection/#start-a-new-script","title":"Start a new script","text":"<pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Hello Feature Collection\n//\n//  Jeff Howarth \n//  Geography 251\n//\n//  Oct 1, 2023\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre>"},{"location":"rudiments/hello_feature_collection/#import-a-table-as-an-asset","title":"Import a table as an Asset","text":""},{"location":"rudiments/hello_feature_collection/#load-feature-collection-from-string","title":"Load Feature Collection from String","text":"<pre><code>graph LR\n  method[\"ee.FeatureCollection.()\"] --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n  arg_att([pathname\\n\\nSTRING]) --&gt; method\n\n  style method fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att fill:#DCDCDC,stroke-width:0px</code></pre> <pre><code>// --------------------------------------------------------------------------\n//  Load Feature Collection from String (collection name). \n//\n//  Updated: 9/30/23\n// --------------------------------------------------------------------------\n\nvar hello_pond ;\n\nprint(\n'HELLO FEATURE COLLECTION:',\nhello_pond,\nhello_pond.size(),\nhello_pond.first()\n)\n;\n</code></pre>"},{"location":"rudiments/hello_feature_collection/#center-map-on-object","title":"Center map on Object","text":"<pre><code>// --------------------------------------------------------------------------\n//  Center Map on Object.\n//\n//  Updated: 9/30/23\n// -------------------------------------------------------------------------- \n\nMap.centerObject();\nMap.setOptions();\n</code></pre>"},{"location":"rudiments/hello_feature_collection/#add-feature-collection-as-map-layer","title":"Add Feature Collection as Map Layer","text":"<pre><code>// --------------------------------------------------------------------------\n//  Add Feature Collection as Map Layer.\n//\n//  Updated: 9/30/23\n// --------------------------------------------------------------------------\n\nMap.addLayer();\n</code></pre>"},{"location":"rudiments/hello_feature_collection/#create-a-geometry","title":"Create a geometry","text":"<pre><code>// --------------------------------------------------------------------------\n//  Create a Geometry.\n//\n//  Updated: 9/30/23\n// --------------------------------------------------------------------------\n\nprint(\n'Pond Geometry:',\ngeometry\n)\n;\n</code></pre>"},{"location":"rudiments/hello_feature_collection/#construct-a-feature","title":"Construct a feature","text":"<pre><code>graph LR\n  method[\"ee.Feature()\"] --&gt; output&gt;output\\n\\nFEATURE];\n  arg_geom([GEOMETRY]) --&gt; method;\n  arg_att([attributes\\n\\nDICTIONARY]) --&gt; method;\n\n  style method fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_geom fill:#E1C3E6,stroke-width:0px\n  style arg_att fill:#DCDCDC,stroke-width:0px</code></pre> <pre><code>// --------------------------------------------------------------------------\n//  Construct a Feature.\n//\n//  Updated: 9/30/23\n// --------------------------------------------------------------------------\n\nvar pond_attributes ;\n\nvar pond_feature ;\n\nprint(\n\"HELLO POND FEATURE:\",\n\"geometry:\", geometry,\n\"attributes:\", pond_attributes,\n\"feature:\", pond_feature\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"rudiments/hello_feature_collection/#convert-feature-collection-into-an-image","title":"Convert feature collection into an image","text":"<pre><code>graph LR\n  input[/input\\n\\nFEATURE COLLECTION/] --&gt; method[\".reduceToImage()\"]\n  method --&gt; output&gt;output\\n\\nIMAGE];\n  arg_att1([property key\\n\\nLIST]) --&gt; method;\n  arg_att2([\"ee.Reducer()\"]) --&gt; method;\n\n  style input fill:#E1C3E6,stroke-width:0px\n  style method fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#ADD8E6,stroke-width:0px</code></pre> <pre><code>// ---------------------------------------------------------------------------\n//  Convert feature collection into an image. \n//\n//  Updated: 10/01/23\n// ---------------------------------------------------------------------------\n\nvar pond_image ;\n\nprint(\n\"HELLO POND IMAGE:\", pond_image\n)\n;\n\nMap.addLayer();\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"rudiments/hello_vector/","title":"Hello Vector","text":""},{"location":"rudiments/hello_vector/#introduction","title":"Introduction","text":"<p>This tutorial introduces the vector data model with QGIS. It walks you through a simple task of creating and populating a vector table stored as a shapefile, and aims to get you thinking about relationships between detail, accuracy, map scale, and mapping purpose.  </p>"},{"location":"rudiments/hello_vector/#create-a-new-shapefile","title":"Create a new shapefile","text":""},{"location":"rudiments/hello_vector/#digitize-a-feature","title":"Digitize a feature","text":""},{"location":"rudiments/hello_vector/#add-a-new-field","title":"Add a new field","text":""},{"location":"rudiments/hello_vector/#display-by-attribute","title":"Display by attribute","text":"<p>Please note: I edited this video in YouTube Studio this morning (9/28) so that it should now end at 7:15 mark. Sometimes Studio takes some time to process edits, so if the video served to you keeps going after 7:15, you are welcome to stop it and move onto next one. Thanks. </p>"},{"location":"rudiments/hello_vector/#under-the-shapefile-hood","title":"Under the shapefile hood","text":""},{"location":"rudiments/hello_vector/#deliverable","title":"Deliverable","text":"<p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"rudiments/natural_and_false_color/","title":"In Natural and False Color","text":""},{"location":"rudiments/natural_and_false_color/#introduction","title":"Introduction","text":"<p>A remote sensing system observes conditions on Earth (or other planets) without making direct contact with the observed subject. This generally involves a sensor (typically onboard a vehicle) and a ground station (that receives data from the vehicle).  </p> <p>Some systems passively observe conditions by measuring energy that is generated by another source, while others emit energy in some form and measure how it returns.  </p> <p> <p> </p> <p></p> <p>source: Arkarjun (2013)</p> <p>Today we will focus on passive systems and try to better understand what they measure and how we can use additive color to see things in imagery that we cannot see in the real world.  </p>"},{"location":"rudiments/natural_and_false_color/#electromagnetic-spectrum","title":"Electromagnetic Spectrum","text":"<p>The electromagnetic spectrum describes the range of energy wavelengths in sunlight.  </p> <p> </p> <p>source: serc.carleton.edu</p>"},{"location":"rudiments/natural_and_false_color/#spectral-bands-of-sensors","title":"Spectral Bands of Sensors","text":"<p>A sensor onboard a vehicle will be able to measure the amount of energy that it receives in different spectral bands, or portions of the EM spectrum.  </p> <p></p> <p> Acronym Name MSS Multispectral Scanner TM Thematic Mapper ETM+ Enhanced Thematic Mapper OLI/OLI-2 Operational Land Imager TIRS/TIRS-2 Thermal Infrared Sensor <p></p>"},{"location":"rudiments/natural_and_false_color/#bands","title":"Bands","text":"<p>Each band captures the amount of energy at each pixel. The picture below shows the pixel values of an individual band that are displayed with a grayscale (black to white) palette.  </p> <p> <p></p> <p></p>"},{"location":"rudiments/natural_and_false_color/#stretch-enhancement","title":"Stretch enhancement","text":"<p>The image above looks a little drab because we are not using our display values very efficiently. We can improve the contrast of this image with stretch enhancement.  </p> <p> </p> <p>Link to app </p>"},{"location":"rudiments/natural_and_false_color/#natural-color","title":"Natural color","text":"<p>Now we can take advantage of additive color and display the bands that report the amount of energy in the red, green, and blue portions of the EM spectrum with the red, green, and blue color channels. The result is called a natural color composite because it looks natural to human eyes, or similar to the world that we experience, or at least it looks like the world that we can see from an airplane window.    </p> <p> <p></p> <p> </p> <p>In a natural color composite, we use a straight mapping between the EM band and the display color channel.  </p> <p> Band Color Channel Red Red Green Green Blue Blue <p></p>"},{"location":"rudiments/natural_and_false_color/#false-color","title":"False color","text":"<p>The remote sensing instruments onboard satellites will often report data in portions of the EM spectrum that we cannot see. When we use additive color to visualize energy that we cannot otherwise see, the results are called false color composites. The picture below shows a NIR false color. </p> <p></p> <p>So now the colors are false and this can be a little weird to think through, but the main point is to remember that we can use different colors to display different ranges of the EM spectrum (even though we naturally see some of these ranges as color).   </p> <p> Band Color Channel NIR Red Red Green Green Blue <p></p> <p>There are a lot of different false color composites that you can make with additive color. For example, here is another common false color composite that displays shortwave energy.</p> <p> <p></p> Band Color Channel SWIR2 Red NIR Green Green Blue <p></p>"},{"location":"rudiments/natural_and_false_color/#make-some-composites","title":"Make some composites","text":"<p>Go ahead and try to make the color composites shown above and use stretch enhancement to improve the contrast of each image.  </p> <p> </p> <p>Link to app. </p> <p>As a guide for exploring color composites, here is a very helpful resource that identifies useful band combinations for different thematic applications in environmental science and geography. </p>"},{"location":"rudiments/natural_and_false_color/#what-do-the-colors-mean","title":"What do the colors mean?","text":"<p>Spectral signature charts show how reflectance changes with wavelength for different land cover types.    </p> <p> </p> <p>source: Hartley Bulcock</p> <p>We can explore spectral signature with this app.</p> <p> </p> <p>Link to app </p> <p>S2 band spec sheet</p>"},{"location":"rudiments/natural_and_false_color/#summary","title":"Summary","text":"<p>Remote sensing involves capturing data about a place without being in contact with the place. We capture this data with sensors onboard vehicles, like satellites, drones, and airplanes. These sensors measure the amount of energy that reflects or radiates from the Earth, storing this data in each pixel of a raster dataset. Most sensors capture this data within specific ranges of the electromagnetic spectrum, which are called spectral bands; this includes both visible and non-visible portions of the spectrum. We can use additive color to display the values of three spectral bands at once and we can use stretch enhancement to improve the contrast of the resulting images. The color composites that result help us visualize three slices of the spectral signatures of land cover. We can also use the spectral signatures of land cover to help guide our choice of band combinations to make color composites.   </p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"rudiments/on_distance/","title":"On Distance","text":"<p>INCOMPLETE DRAFT October 5, 2023</p>"},{"location":"rudiments/on_distance/#introduction","title":"Introduction","text":"<p>I find working with distance methods on raster datasets in Earth Engine to be a little confusing, so I made the app below to better understand how these things work. The text below walks you through how to make sense of it. </p> <p> </p>"},{"location":"rudiments/on_distance/#test-point-feature-collection","title":"Test point feature collection","text":"<p>You should see a yellow point on the 50 yard line of Youngman Field. If you click on the Layers widget, you should see a list of layers that you can add to the map. When you first load the embedded app, the layer at the bottom should be the only one checked; this is the layer with the little yellow dot, called Test point (Feature Collection) because it is a feature collection with one feature in it.  </p>"},{"location":"rudiments/on_distance/#test-point-image","title":"Test point image","text":"<p>The next layer up from the bottom is called  Test Point Image. It is the same point at midfield, but now is is stored as a binary image. The little white pixel in the center marks the location of the test point; this pixel has a value of 1. All the black pixels have a value of 0.  </p> <p>If you zoom out a little (by clicking the - button on the upper left), you should see the extent of the image. There is an edge to the raster beyond which you can see the underlying satellite base map. The extent is 300 meters by 300 meters.  </p>"},{"location":"rudiments/on_distance/#simple-distance-image","title":"Simple distance image","text":"<p>Still moving from bottom up in the layer panel, the next layer is called Simple Test Distance Image and represents the distance from the test point image. The figure below shows how I made it.</p> <pre><code>graph LR\n  input[/test point image/] --&gt; method1[\".distance()\"] ;\n  method1 --&gt; method2([\"ee.Kernel.euclidean()\"])\n  arg_att1([\"radius: 100\"]) --&gt; method2;\n  arg_att2([\"units: 'meters'\"]) --&gt; method2;\n  method2 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px</code></pre> <p>Notice that the .distance() method takes the ee.Kernel.euclidian() method as an argument. (I use blue to indicate methods and rounded shapes to indicate arguments, or things that get put into a method\u2019s parentheses). </p> <p>A kernel is an analysis window. In this case, the kernel defines the spatial extent of the euclidean distance operation. When we say that we want the radius of the kernel to be 100 meters, we are defining the size of our analysis window. This is a little confusing, because I think Earth Engine actually uses a square as the kernel shape, not a circle, but more on that later.  </p> <p>In this case, the extent of the Simple Test Distance Image represents the kernel extent; it shows the size of the window that was centered on the only pixel in the binary image with a non-zero value. Within this kernel window, Earth Engine computed the Euclidean distance from the single non-zero pixel to all the other zero pixels in the kernel extent.</p> <p>The fact that the extent of the Simple Test Distance Image is smaller than the extent of the Test Point Image also tells us something important. Remember that the Test Point Image was the input to the distance method (I use the parallelogram shape to represent data inputs because I am trying to suggest they are moving or about to undergo change). So the difference between the two extents means that the .distance() method does not make computations across the entire extent of the input image. If it did, the extent of the output would be the same as the input. Instead, the .distance() method computes distance within the extent of the kernel that you feed it. Any locations outside of the kernel extent get masked. </p>"},{"location":"rudiments/on_distance/#simple-distance-threshold","title":"Simple distance threshold","text":"<p>You may have noticed that if you zoom out too far when looking at the test point image extent in the previous section, Earth Engine stops drawing the Simple Test Distance Image on the map. That is perhaps the first clue that something is weird here. </p> <p>Why would the ability to draw the layer depend on the zoom level? </p> <p>If this fuels a sense of doubt and you begin to wonder how much you should trust what the layer claims to show you, I would like to double-down on such concerns by looking at the next layer, called Threshold Simple Distance at 50 Yards. Here is how I made it:  </p> <pre><code>graph LR\n  input[/test point image/] \n  method1[\".lt()\"] ;\n  method2[\".selfMask()\"]\n  arg1([\"45.72\"]) \n  output&gt;output\\n\\nIMAGE];\n\n  input --&gt; method1 ;\n  arg1 --&gt; method1 ;\n  method1 --&gt; method2 ;\n  method2 --&gt; output\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg1 fill:#DCDCDC,stroke-width:0px</code></pre> <p>The output is a binary image, where all locations that are 50 yards (45.72 meters) or less from the midfield point are displayed in white and all other locations are masked. If you turn off all the other layers, you should be able to see the satellite base layer and compare this circle to hatch marks on the football field. The circle should reach the goal line, but it does not. It seems instead to leave a long field goal.      </p> <p>Why does this distance layer under represent distance? </p> <p>There are two things that help understand why this happens when we use the Code Editor: </p> <ol> <li>Pixel scale changes with zoom level.   </li> <li>Zoom level determines analysis scale, unless we specify otherwise. </li> </ol> <p>Google Earth Engine stores all image assets in a stack of different resolutions defined by zoom level. The idea is that each zoom level serves you an image with the same number of pixels. As a result, pixel scale changes as you move between zoom levels. Here is another way to think about this: you do not get more pixels on your monitor to see more detail, you simply get pixels that represent smaller distances on the Earth\u2019s surface.     </p> <p> source: Google</p> <p>The image above shows how each pixel generalizes the values of a 2x2 block of pixels at the next, more detailed zoom level. As a result, pixel scale resembles a pyramid as you move from small scale to large scale zoom levels. </p> <p>When you use a kernel method in the Code Editor, the zoom level of the map in the Code Editor determines the scale of the analysis. That is why the results appear to change as you zoom in and out; by changing the zoom level, you change the scale of the analysis. </p>"},{"location":"rudiments/on_distance/#distance-image-with-reprojectcrs","title":"Distance image with .reproject(crs)","text":"<p>To be continued\u2026</p> <pre><code>graph LR\n  input[/test point image/] --&gt; method1[\".distance()\"] ;\n  method1 --&gt; method2([\"ee.Kernel.euclidean()\"])\n  arg_att1([\"radius: 250\"]) --&gt; method2;\n  arg_att2([\"units: 'meters'\"]) --&gt; method2;\n  method2 --&gt; method3[\".reproject()\"]\n  arg_att3([\"crs: 'EPSG: 32145'\"]) --&gt; method3;\n  method3 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"rudiments/on_distance/#source-code","title":"Source code","text":"<pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  On distance in Earth Engine\n//\n//  Jeff Howarth\n//\n//  Updated: Oct 5, 2023\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n// -----------------------------------------------------------------------------\n// Make test point at 50 yard line.\n// -----------------------------------------------------------------------------\n\nvar test_point1 = ee.Geometry.Point([-73.17965925111653, 44.00167387729651]);\n\nMap.centerObject(test_point1, 17);\nMap.setOptions('HYBRID');\n\n// Map.addLayer(test_point, {color: 'red'}, \"Test Point\", false);\n\n// -----------------------------------------------------------------------------\n// Put test point in a feature collection.\n// -----------------------------------------------------------------------------\n\nvar test_fc = ee.FeatureCollection(\n[\nee.Feature(test_point1, {'tag': 1}),\n]\n);\n\nMap.addLayer(test_fc, {color: 'Yellow'}, \"Test point (Feature Collection)\");\n\n// -----------------------------------------------------------------------------\n// Define an abitrary test extent.\n// -----------------------------------------------------------------------------\n\nvar test_extent = test_point1.buffer(150).bounds();\n\n// -----------------------------------------------------------------------------\n// Convert point to an image.\n// -----------------------------------------------------------------------------\n\nvar crs = \"EPSG: 32145\";\n\nvar test_image = ee.FeatureCollection(test_fc)\n.reduceToImage([\"tag\"], ee.Reducer.max())\n.reproject({crs: crs})\n.unmask()\n.rename(\"test_image\")\n.clip(test_extent)\n;\n\nprint(\"test image\", test_image, test_image.projection());\n\nMap.addLayer(test_image, {min:0, max:1}, \"Test point Image\", false);\n\n// -----------------------------------------------------------------------------\n// Make test distance image without .reproject(crs).\n// -----------------------------------------------------------------------------\n\nvar kernel_radius = ee.Number(100);\n\nvar test_distance_image_without_crs = test_image\n.distance(ee.Kernel.euclidean({radius: kernel_radius, units: 'meters'}))\n// .reproject({crs: crs})                                         \n.rename('distance')\n;\n\nprint(\"test distance image:\", test_distance_image_without_crs, test_distance_image_without_crs.projection());\n\nvar inferno = [\"#000004\", \"#320A5A\", \"#781B6C\", \"#BB3654\", \"#EC6824\", \"#FBB41A\", \"#FCFFA4\"].reverse();\n\nMap.addLayer(test_distance_image_without_crs,  {min:0, max: 100, palette: inferno}, \"Simple Test Distance Image\", false);\n\n// -----------------------------------------------------------------------------\n// Threshold distance image without crs at 50 yards. \n// -----------------------------------------------------------------------------\n\nvar test_image_buffer_without_crs = test_distance_image_without_crs.lt(45.72).selfMask();\n\nMap.addLayer(test_image_buffer_without_crs, {min:0, max:1}, 'Threshold Simple Distance at 50 Yards', false);\n\n\n// -----------------------------------------------------------------------------\n// Make test distance image with .reproject(crs).\n// -----------------------------------------------------------------------------\n\nvar test_distance_image_with_crs = test_image\n.distance(ee.Kernel.euclidean({radius: 100, units: 'meters'}))\n.reproject({crs: crs})                                         .rename('distance')\n;\n\nprint(\"test distance image:\", test_distance_image_with_crs, test_distance_image_with_crs.projection());\n\nvar inferno = [\"#000004\", \"#320A5A\", \"#781B6C\", \"#BB3654\", \"#EC6824\", \"#FBB41A\", \"#FCFFA4\"].reverse();\n\nMap.addLayer(test_distance_image_with_crs,  {min:0, max: 100, palette: inferno}, \"Test Distance Image with Reproject\", false);\n\n// -----------------------------------------------------------------------------\n// Threshold distance image with crs at 50 yards. \n// -----------------------------------------------------------------------------\n\nvar test_image_buffer_with_crs = test_distance_image_with_crs.lt(45.72).selfMask();\n\nMap.addLayer(test_image_buffer_with_crs, {min:0, max:1}, 'Thresholded Test Distance Image with Reproject ', false);\n\n// -----------------------------------------------------------------------------\n// Convert threshold image with crs to vector. \n// -----------------------------------------------------------------------------\n\nvar test_image_buffer_to_vector_without_crs = test_image_buffer_without_crs.reduceToVectors(\n{\nreducer: ee.Reducer.countEvery(), geometry: test_extent, scale: 1, geometryType: 'polygon', eightConnected: true, crs: crs,\nmaxPixels: 1e12, geometryInNativeProjection: true\n}\n);\n\nMap.addLayer(test_image_buffer_to_vector_without_crs, {color: 'magenta'}, \"Threshold Simple Distance Image Converted to Feature\", false);\n\n\n// -----------------------------------------------------------------------------\n// Convert threshold image with crs to vector. \n// -----------------------------------------------------------------------------\n\nvar test_image_buffer_to_vector_with_crs = test_image_buffer_with_crs.reduceToVectors(\n{\nreducer: ee.Reducer.countEvery(), geometry: test_extent, scale: 1, geometryType: 'polygon', eightConnected: true, crs: crs,\nmaxPixels: 1e12, geometryInNativeProjection: true\n}\n);\n\nMap.addLayer(test_image_buffer_to_vector_with_crs, {color: 'cyan'}, \"Threshold Distance Image with Reproject Converted to Feature\", false);\n\n\n// -----------------------------------------------------------------------------\n// Buffer vector at 50 yards.\n// -----------------------------------------------------------------------------\n\nvar makeBuffer = function(f) {\nreturn f.buffer(45.72);\n};\n\nvar test_buffer_vector = test_fc.map(makeBuffer);\n\nMap.addLayer(test_buffer_vector, {color: 'Yellow'}, \"Vector buffer Method\", false);\n\n// -----------------------------------------------------------------------------\n// What is the shape of the Euclidean Kernel?\n// -----------------------------------------------------------------------------\n\nvar kernel_extent = test_distance_image_with_crs.gte(0).reduceToVectors(\n{\nreducer: ee.Reducer.countEvery(), geometry: null, scale: 1, geometryType: 'bb', eightConnected: true, crs: \"EPSG: 32145\", maxPixels: 1e12, geometryInNativeProjection: true\n}\n);\n\nMap.addLayer(kernel_extent, {color: 'White'}, \"Kernel Extent Test Image with Reproject\", false);\n\n\nvar test_kernel_max = test_distance_image_with_crs.reduceRegion(\n{\nreducer: ee.Reducer.max(), geometry: kernel_extent, scale: 1, crs: \"EPSG: 32145\", maxPixels: 1e12, tileScale: 1\n}\n);\n\nvar pythag = kernel_radius.multiply(kernel_radius).multiply(2).sqrt();\n\nprint(\n\"Test Kernel max:\", test_kernel_max,\n\"pythag diagonal:\", pythag\n)\n;\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"starters/landsat5/","title":"Landsat 5","text":"<p>Open in Code Editor</p> <pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_L5.js\n//  Author:       Jeff Howarth\n//  Last edited:  10/18/2023\n//\n//  Starter for Landsat 5 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geometry = ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 8);\n\n// ------------------------------------------------------------------------\n//  Scale and offset  \n// ------------------------------------------------------------------------\n\nfunction scale_L5(image) {\nvar opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);\nvar thermalBand = image.select('ST_B6').multiply(0.00341802).add(149.0);\nreturn image.addBands(opticalBands, null, true)\n.addBands(thermalBand, null, true);\n}\n\n// ------------------------------------------------------------------------\n//  Cloud mask   \n// ------------------------------------------------------------------------\n\nfunction cloudMask_L5(image) {\nvar qa = image.select('QA_PIXEL');\n\nvar dilatedCloudBitMask = 1 &lt;&lt; 1;  var cloudBitMask = 1 &lt;&lt; 3;\nvar cloudShadowBitMask = 1 &lt;&lt; 4;\n\n// Both flags shoudl be set to zero, indicating clear conditions. \n\nvar mask = qa.bitwiseAnd(cloudBitMask).eq(0)\n.and(qa.bitwiseAnd(cloudShadowBitMask).eq(0))\n.and(qa.bitwiseAnd(dilatedCloudBitMask).eq(0))\n;\n\nreturn image.updateMask(mask);\n}\n\n// ------------------------------------------------------------------------\n//  Filter ingredients   \n// ------------------------------------------------------------------------\n\nvar output = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2')\n.filterBounds(geometry)\n// .filter(ee.Filter.calendarRange(1995, 1995, 'year'))\n.filter(ee.Filter.calendarRange(1, 3, 'month'))\n// .filter(ee.Filter.calendarRange(1, 1, 'day_of_year'))\n// .filter(ee.Filter.lt('CLOUD_COVER', 20))\n.map(scale_L5)\n.map(cloudMask_L5)\n.median()\n;\n\nprint(\noutput\n)\n;\n\n// ------------------------------------------------------------------------\n//  Display  \n// ------------------------------------------------------------------------\n\nvar viz = {\nbands: ['SR_B3', 'SR_B2', 'SR_B1'],\nmin: 0.0,\nmax: 0.3,\n};\n\nMap.addLayer(output, viz, 'Output', 1);\n</code></pre>"},{"location":"starters/landsat7/","title":"Landsat 7","text":"<p>Open in Code Editor </p> <pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_L7.js\n//  Author:       Jeff Howarth\n//  Last edited:  10/18/2023\n//\n//  Starter for Landsat 7 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geometry = ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 8);\n\n// ------------------------------------------------------------------------\n//  Scale and offset\n// ------------------------------------------------------------------------\n\nfunction scale_L7(image) {\nvar opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);\nvar thermalBand = image.select('ST_B6').multiply(0.00341802).add(149.0);\nreturn image.addBands(opticalBands, null, true)\n.addBands(thermalBand, null, true);\n}\n\n// ------------------------------------------------------------------------\n//  Cloud mask \n// ------------------------------------------------------------------------\n\nfunction cloudMask_L7(image) {\nvar qa = image.select('QA_PIXEL');\n\nvar dilatedCloudBitMask = 1 &lt;&lt; 1;  var cloudBitMask = 1 &lt;&lt; 3;\nvar cloudShadowBitMask = 1 &lt;&lt; 4;\n\n// Both flags shoudl be set to zero, indicating clear conditions. \n\nvar mask = qa.bitwiseAnd(cloudBitMask).eq(0)\n.and(qa.bitwiseAnd(cloudShadowBitMask).eq(0))\n.and(qa.bitwiseAnd(dilatedCloudBitMask).eq(0))\n;\n\nreturn image.updateMask(mask);\n}\n\n// ------------------------------------------------------------------------\n//  Filter ingredients   \n// ------------------------------------------------------------------------\n\nvar output = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2')\n.filterBounds(geometry)\n// .filter(ee.Filter.calendarRange(2000, 2000, 'year'))     // January 1999\u2013April 2022\n.filter(ee.Filter.calendarRange(1, 3, 'month'))\n// .filter(ee.Filter.calendarRange(1, 1, 'day_of_year'))\n// .filter(ee.Filter.lt('CLOUD_COVER', 20))\n.map(scale_L7)\n.map(cloudMask_L7)\n.median()\n;\n\nprint(\noutput\n)\n;\n\n// ------------------------------------------------------------------------\n//  Display  \n// ------------------------------------------------------------------------\n\nvar viz = {\nbands: ['SR_B3', 'SR_B2', 'SR_B1'],\nmin: 0.0,\nmax: 0.3,\n};\n\nMap.addLayer(output, viz, 'Output', 1);\n</code></pre>"},{"location":"starters/landsat8/","title":"Landsat 8","text":"<p>Open in Code Editor </p> <pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_L8.js\n//  Author:       Jeff Howarth\n//  Last edited:  10/18/2023\n//\n//  Starter for Landsat 8 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geometry = ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 8);\n\n// ------------------------------------------------------------------------\n//  Scale and offset  \n// ------------------------------------------------------------------------\n\nfunction scale_L8(image) {\nvar opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);\nvar thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0);\nreturn image.addBands(opticalBands, null, true)\n.addBands(thermalBands, null, true);\n} // ------------------------------------------------------------------------\n//  Cloud mask  \n// ------------------------------------------------------------------------\n\nfunction cloudMask_L8(image) {\nvar qa = image.select('QA_PIXEL');\n\nvar dilatedCloudBitMask = 1 &lt;&lt; 2;  var cirrusBitMask = 1 &lt;&lt; 2;  var cloudBitMask = 1 &lt;&lt; 3;\nvar cloudShadowBitMask = 1 &lt;&lt; 4;\n\n// Both flags shoudl be set to zero, indicating clear conditions. \n\nvar mask = qa.bitwiseAnd(cloudBitMask).eq(0)\n.and(qa.bitwiseAnd(cloudShadowBitMask).eq(0))\n.and(qa.bitwiseAnd(dilatedCloudBitMask).eq(0))\n.and(qa.bitwiseAnd(cirrusBitMask).eq(0))\n;\n\nreturn image.updateMask(mask);\n\n}\n\n// ----------------------------------------------------------------------\n// Filter ingredients\n// ----------------------------------------------------------------------\n\nvar output = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\n.filterBounds(geometry)\n// .filter(ee.Filter.calendarRange(2015, 2015, 'year'))\n.filter(ee.Filter.calendarRange(1, 3, 'month')) // .filter(ee.Filter.calendarRange(1, 1, 'day_of_year')) \n// .filter(ee.Filter.lt('CLOUD_COVER',20))\n.map(scale_L8)\n.map(cloudMask_L8)\n.median()\n;\n\nprint(output);\n\n// ----------------------------------------------------------------------\n// Display\n// ----------------------------------------------------------------------\n\nvar viz = {\nbands: ['SR_B4', 'SR_B3', 'SR_B2'],\nmin: 0.0,\nmax: 0.25,\n};\n\nMap.addLayer(output, viz, 'Landsat 8 imagery');\n</code></pre>"},{"location":"starters/landsat9/","title":"Landsat 9","text":"<p>Open in Code Editor</p> <pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_L9.js\n//  Author:       Jeff Howarth\n//  Last edited:  10/18/2023\n//\n//  Starter for Landsat 9 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geometry = ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 8);\n\n// ------------------------------------------------------------------------\n//  Scale and offset  \n// ------------------------------------------------------------------------\n\nfunction scale_L9(image) {\nvar opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);\nvar thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0);\nreturn image.addBands(opticalBands, null, true)\n.addBands(thermalBands, null, true);\n} // ------------------------------------------------------------------------\n//  Cloud mask  \n// ------------------------------------------------------------------------\n\nfunction cloudMask_L9(image) {\nvar qa = image.select('QA_PIXEL');\n\nvar dilatedCloudBitMask = 1 &lt;&lt; 2;  var cirrusBitMask = 1 &lt;&lt; 2;  var cloudBitMask = 1 &lt;&lt; 3;\nvar cloudShadowBitMask = 1 &lt;&lt; 4;\n\n// Both flags shoudl be set to zero, indicating clear conditions. \n\nvar mask = qa.bitwiseAnd(cloudBitMask).eq(0)\n.and(qa.bitwiseAnd(cloudShadowBitMask).eq(0))\n.and(qa.bitwiseAnd(dilatedCloudBitMask).eq(0))\n.and(qa.bitwiseAnd(cirrusBitMask).eq(0))\n;\n\nreturn image.updateMask(mask);\n\n}\n\n// ----------------------------------------------------------------------\n// Filter ingredients\n// ----------------------------------------------------------------------\n\nvar output = ee.ImageCollection(\"LANDSAT/LC09/C02/T1_L2\")\n.filterBounds(geometry)\n// .filter(ee.Filter.calendarRange(2022, 2022, 'year'))\n.filter(ee.Filter.calendarRange(1, 3, 'month')) // .filter(ee.Filter.calendarRange(1, 1, 'day_of_year')) \n// .filter(ee.Filter.lt('CLOUD_COVER',20))\n.map(scale_L9)\n.map(cloudMask_L9)\n.median()\n;\n\nprint(output);\n\n// ----------------------------------------------------------------------\n// Display\n// ----------------------------------------------------------------------\n\nvar viz = {\nbands: ['SR_B4', 'SR_B3', 'SR_B2'],\nmin: 0.0,\nmax: 0.25,\n};\n\nMap.addLayer(output, viz, 'Landsat 9 imagery');\n</code></pre>"},{"location":"starters/modis/","title":"MODIS","text":"<p>Forthcoming</p>"},{"location":"starters/naip/","title":"NAIP","text":"<p>Forthcoming</p>"},{"location":"starters/overview/","title":"Overview","text":"<p>This section contains a set of starter scripts for working with different satellite products in Earth Engine. The scripts include the following:  </p> <ul> <li>a function to apply scale and offsets;</li> <li>a function to  mask clouds;  </li> <li>a chain to process a collection with a number of common ingredients, including location, date, and image property;</li> <li>the chain also maps the scaling and cloud mask functions across images in the collection and reduces the collection to an image;</li> <li>viz parameters for a natural color composite;</li> <li>a statement to add the output as a layer on the map.  </li> </ul> <p>The link at the top of the page will open the script in the Code Editor. Alternatively, you can copy and paste the script from the page. </p> <p>The point of interest (poi) in the scripts marks Mount Kilimanjaro in Tanzania. This variable is called \u201cgeometry\u201d. This should allow you to comment out the line, choose a different poi with the drawing tools, and rerun the script to observe a different part of the world. </p>"},{"location":"starters/sentinel2/","title":"Sentinel 2","text":""},{"location":"starters/sentinel2/#mission","title":"Mission","text":"<p>Sentinel-2 Mission Guide </p>"},{"location":"starters/sentinel2/#bands","title":"Bands","text":"<p>Sentinel Band Chart </p>"},{"location":"starters/sentinel2/#starter-code","title":"Starter Code","text":"<p>Open in Code Editor</p> <pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_S2.js\n//  Author:       Jeff Howarth\n//  Last edited:  10/24/2023\n//\n//  Starter for Sentinel 2 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geometry = ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 8);\n\n// ------------------------------------------------------------------------\n//  Scale and offset  \n// ------------------------------------------------------------------------\n\nfunction scale_S2(image) {\n\nreturn image.multiply(0.0001);\n} // ------------------------------------------------------------------------\n//  Cloud mask  \n// ------------------------------------------------------------------------\n\nfunction cloudMask_S2 (image) {\nvar qa = image.select('QA60');\n\nvar cloudBitMask = 1 &lt;&lt; 10;\nvar cirrusBitMask = 1 &lt;&lt; 11;\n\nvar SCL = image.select('SCL')\n.remap(\n[1,2,3,4,5,6,7,8,9,10,11],\n[0,1,0,1,1,1,0,0,0, 0, 1]\n);\n\n\n// Both flags shoudl be set to zero, indicating clear conditions. \n\nvar mask = qa.bitwiseAnd(cloudBitMask).eq(0)\n.and(qa.bitwiseAnd(cirrusBitMask).eq(0))\n;\n\nreturn image\n.updateMask(mask)\n.updateMask(SCL);\n\n}\n\n// ----------------------------------------------------------------------\n// Filter ingredients\n// ----------------------------------------------------------------------\n\n\nvar output = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n.filterBounds(geometry)\n// .filter(ee.Filter.calendarRange(2020, 2020, 'year'))\n.filter(ee.Filter.calendarRange(1, 3, 'month')) .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20))\n.map(cloudMask_S2)\n.map(scale_S2)\n.median()\n\n;\n\nprint(output);\n\n// ----------------------------------------------------------------------\n// Display\n// ----------------------------------------------------------------------\n\nvar viz_bands = ['B4', 'B3', 'B2'];\n\nvar viz = {\nbands: viz_bands,\nmin: 0.0,\nmax: 0.3,\n};\n\nMap.addLayer(output, viz, 'From Sentinel 2 Collection');\n</code></pre>"},{"location":"toolbox/GEE/","title":"Google Earth Engine","text":""},{"location":"toolbox/GEE/#introduction","title":"Introduction","text":"<p>Google Earth Engine (GEE) is cloud-based geographic information system (GIS) that is (currently) free to use for educational and research purposes. We will be using GEE for most of the heavy lifting in this course: accessing large datasets, crunching them in computational workflows, and visualizing them with web maps. The lovely thing about GEE is that all of this work gets done on Google\u2019s servers in the cloud. All you will need to work with GEE is a web browser, preferably Google Chrome, and a decent internet connection. All you need to do is sign up for the Google Earth Engine cloud service. </p> <p>Please complete the steps below on the first day of class (or 24 hours before our first lab meeting). </p>"},{"location":"toolbox/GEE/#sign-up-for-earth-engine","title":"Sign up for Earth Engine","text":"<ol> <li> <p>Go to the bottom of the Google Earth Engine page and click \u2018Sign Up Now\u2019.</p> <p></p> </li> <li> <p>You want to sign up for a noncommercial cloud project. The next page will likely only show one option, so go ahead and click that.</p> <p></p> </li> <li> <p>As a student, you do not have to pay for your use of Earth Engine. So click \u2018Unpaid usage\u2019 and then select \u2018Academic and Research\u2019 from the pull-down options. Click \u2018Next\u2019 to move on.   </p> <p></p> </li> <li> <p>You should create a new Google Cloud Project. You can try doing this under the middlebury.edu organization. Your user name should be \u2018ee-your-midd-email-address-name\u2019 with no spaces. For example, \u2018ee-jhowarth\u2019. Then click \u2018Continue to Summary\u2019.    </p> <p></p> </li> <li> <p>Affirm the summary to finalize the project. </p> </li> <li> <p>It may take a little time for you to receive approval. When you are successful, you should be able to open the Code Editor and get to a page that looks similar to the one below. </p> <p></p> </li> </ol>"},{"location":"toolbox/QGIS/","title":"QGIS","text":""},{"location":"toolbox/QGIS/#introduction","title":"Introduction","text":"<p>QGIS is a free, open-source, and powerful geographic information system (GIS). We will be using QGIS for some light lifting in this course: mostly data visualization and layouts. Because QGIS is free and powerful, I would like you to know your way around it and be comfortable moving data from GEE to QGIS and vice versa. </p> <p>Unlike GEE, QGIS is a desktop GIS, which means in most cases the program needs to be installed on a local computer. All of the workstations in the Geography Department computer lab have QGIS installed, so you can use any of these computers to complete course work that requires QGIS. It will be far more convenient for you to keep up with the study materials in this course, however, if you install QGIS on your laptop. It\u2019s free and the software runs on both a Mac and Windows.  </p> <p>Please complete the steps below before our first lab meeting.</p>"},{"location":"toolbox/QGIS/#install-qgis-for-first-time","title":"Install QGIS for first time","text":"<ol> <li>Go to QGIS home page. </li> <li>Click \u2018Download Now\u2019. </li> <li>Choose your Operating System. This will start the download, which may take some time to finish.  </li> <li>Double-click the downloaded installer and follow the directions.  </li> </ol> <p>If on a Mac, after installation is complete: </p> <ol> <li>Navigate to application folder.</li> <li>Right-click on QGIS app.</li> <li>Select \u2018Open\u2019. </li> <li>You will see a warning that you have downloaded the app from the internet and questioning whether you trust the source. Affirm. </li> </ol> <p>After you have told your OS to trust the app, you can open the app through Spotlight in the future.  </p>"},{"location":"toolbox/QGIS/#on-updating-your-qgis-version","title":"On updating your QGIS version","text":"<p>If you have installed QGIS recently (2022-2023), you should be fine. </p> <p>We will be using GEE for most of the heavy lifting in this course and will largely use QGIS for some visualization and layout tasks. My QGIS demos will use 3.32.2-Lima (accessed 9.6.23), but it is ok if your version predates this a little. </p> <p>If you want to update your version, I tend to first remove the existing version and then install the new version. </p>"},{"location":"workflows/CZU-fire-complex/","title":"CZU Fire Complex","text":""},{"location":"workflows/CZU-fire-complex/#introduction","title":"Introduction","text":"<p>This tutorial introduces a general workflow to map the burn severity of wildfire with Sentinel-2 data and compare the result to a global dataset of building footprints. </p> <p>We will use the CZU Lightning Complex fires on California\u2019s Slow Coast as a case study.  </p> <p>As you work through the tutorial, you may find it helpful to refer to the fire scars page in the glossary and the Sentinel-2 page in the starters. </p> <p>Your final result should look and work like the map in the app below.  </p> <p> </p> <p>Link to app</p>"},{"location":"workflows/CZU-fire-complex/#start-a-new-file","title":"Start a new file","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n//  Title: wk07_CZU_fire_complex.js \n//  Author: Jeff Howarth \n//  Date: Oct 24, 2023\n\n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre>"},{"location":"workflows/CZU-fire-complex/#sentinel-2-starter-script","title":"Sentinel-2 starter script","text":""},{"location":"workflows/CZU-fire-complex/#define-aoi","title":"Define aoi","text":""},{"location":"workflows/CZU-fire-complex/#adjust-ingredients","title":"Adjust ingredients","text":""},{"location":"workflows/CZU-fire-complex/#adjust-display","title":"Adjust display","text":"<pre><code>// Import image tools module.   \n\nvar tools = require('users/jhowarth/eePrimer:modules/image_tools.js');\n\n// Make a histogram to see data distribution.  \n\nvar histogram = tools.makeHistogram(\noutput,              viz_bands[2],\n30,\n0,\n0.5\n)\n;\n\n// Print, print, print...\n\nprint(\n\"Histogram\", histogram\n)\n;\n</code></pre>"},{"location":"workflows/CZU-fire-complex/#write-function","title":"Write function","text":"<pre><code>// ----------------------------------------------------------------------\n//  Write image processing workflow as a function. \n// ----------------------------------------------------------------------\n</code></pre>"},{"location":"workflows/CZU-fire-complex/#apply-function","title":"Apply function","text":"<pre><code>// ----------------------------------------------------------------------\n//  Apply function to create a post- and pre- burn image. \n// ----------------------------------------------------------------------\n\nvar post_burn ;\nvar pre_burn ;\n\n// Display both as map layers.\n</code></pre>"},{"location":"workflows/CZU-fire-complex/#calculate-nbr","title":"Calculate NBR","text":"<pre><code>// ----------------------------------------------------------------------\n//  Calculate normalized burn ratio for both snapshots.  \n// ----------------------------------------------------------------------\n\n// var spectral = require(\"users/dmlmont/spectral:spectral\");\n\n// print(spectral);\n\n// // Test the method. \n\nvar nbr_test ;\n\n// Write a function to estimate normalized burn ratio.\n\nvar makeBurnRatio ;\n\n// Apply function to post- and pre- conditions.\n\nvar post_burn_ratio ;\nvar pre_burn_ratio ;\n\n// Display as map layers.\n</code></pre>"},{"location":"workflows/CZU-fire-complex/#calculate-burn-severity","title":"Calculate burn severity","text":"<pre><code>// -------------------------------------------------------------\n// Calculate burn severity index.  \n// -------------------------------------------------------------\n\n// Subtract NBR values of post-conditions from values of pre-conditions.\n\nvar burn_severity ;\n\n// Add as map layer. \n</code></pre>"},{"location":"workflows/CZU-fire-complex/#classify-burn-severity","title":"Classify burn severity","text":"<pre><code>// -------------------------------------------------------------\n// Classify burn severity based on USGS thresholds.  \n// -------------------------------------------------------------\n\n// Apply additive thresholds to burn severity image.\n\nvar burn_severity_classes ;\n\n// Quickly see results  \n</code></pre>"},{"location":"workflows/CZU-fire-complex/#display-layer-with-color","title":"Display layer with color","text":"<pre><code>// -------------------------------------------------------------\n// Display result as a map layer\n// -------------------------------------------------------------\n\n// Make viz parameters for classified layer.\n\nvar bsc_viz = {\nmin: 0,\nmax: 6,\npalette: [\n'#778735', '#a7c04f', '#07e444', '#f6fc0d', '#f7b140', '#f86819', '#a601d4'\n]\n};\n\nMap.addLayer(\nburn_severity_classes, bsc_viz, 'Burn severity classes',\ntrue,\n0.6\n)\n;\n</code></pre>"},{"location":"workflows/CZU-fire-complex/#display-class-key","title":"Display class key","text":"<pre><code>// -------------------------------------------------------------\n// Add key (legend) for burn severity classes. \n// -------------------------------------------------------------\n\n// Create a list of labels for classes.\n// The length of this list must equal the length of class values.  \n\nvar bsc_labels = [\n'High post-fire regrowth',\n'Low post-fire regrowth',\n'Unburned',\n'Low Severity',\n'Moderate-low Severity',\n'Moderate-high Severity',\n'High Severity'\n]\n;\n\nvar cart = require('users/jhowarth/eePrimer:modules/cart.js');\n\nvar legend = cart                                     .makeLegend(\n'Burn severity index',                        bsc_viz.palette,                              bsc_labels,\n'bottom-left'                                 );\n\nMap.add(legend);\n</code></pre>"},{"location":"workflows/CZU-fire-complex/#create-ocean-mask","title":"Create ocean mask","text":"<pre><code>// -------------------------------------------------------------\n// Create a mask to hide the ocean. \n// -------------------------------------------------------------\n\nvar ocean_mask ;\n</code></pre>"},{"location":"workflows/CZU-fire-complex/#get-building-footprints","title":"Get building footprints","text":"<pre><code>// ----------------------------------------------------------------------\n//  Get building footprints  \n// ----------------------------------------------------------------------\n\nvar ee_folder ;\n\n// print(ee_folder);\n\nvar buildings ;\n\n// print(buildings.size());\n\n// Add layer to map.  \n</code></pre>"},{"location":"workflows/CZU-fire-complex/#select-burned-buildings","title":"Select burned buildings","text":"<pre><code>// ----------------------------------------------------------------------\n//  Select buildings in moderately to severely burned areas     \n// ----------------------------------------------------------------------\n\nvar burn_severity_buildings ;\n\nvar burned_buildings ;\n\nprint(\n\"Number of burned buildings\",\nburned_buildings.size()\n);\n</code></pre>"},{"location":"workflows/CZU-fire-complex/#display-building-centroids","title":"Display building centroids","text":"<pre><code>// ----------------------------------------------------------------------\n//  Display centroids on map    \n// ----------------------------------------------------------------------\n\n//  Make a centroid function\n\nvar makeCentroid ;\n\n// Apply function\n\nvar burned_centroids ;\n\n// Display as layer. \n</code></pre>"},{"location":"workflows/CZU-fire-complex/#checks-for-tutorial","title":"Checks for tutorial","text":"<p>After you have completed this tutorial, please copy and paste this code block at the end of your script, then run your script, and complete the tutorial quiz on Canvas. </p> <p>Please note that these checks simply provide a means to quickly assess if you have successfully reproduced the workflow demonstrated in the tutorial. Developing skills in map interpretation \u2013  understanding what the results can tell us even though they represent a model of the world and not an exact replica of it \u2013  complements skills in map production. The checks below, however, simply provide a scalable method to evaluate the latter. The former we will explore more through class discussions.   </p> <pre><code>// ----------------------------------------------------------------------\n//  Tutorial checks. \n//\n//  This code block assumes that you have followed ALL the naming \n//   variable names used in the tutorial videos.  \n// ----------------------------------------------------------------------\n\nvar check = require('users/jhowarth/eePrimer:modules/checks.js');\n\nprint(\n\"CHECK 01:\", aoi.area(1),\n\"CHECK 02:\", check.t07(post_burn.select(\"B8\")),\n\"CHECK 03:\", check.t07(pre_burn.select(\"B8\")),\n\"CHECK 04:\", check.t07(post_burn_ratio),\n\"CHECK 05:\", check.t07(pre_burn_ratio),\n\"CHECK 06:\", check.t07(burn_severity),\n\"CHECK 07:\", check.t07(burn_severity_classes),\n\"CHECK 08\",  burn_severity_buildings.first().get(\"max\"),\n\"CHECK 09\",  burned_buildings.first().get(\"max\"),\n\"CHECK 10\",  burned_centroids.first().geometry()  )\n;\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"workflows/LST-anomalies-in-regions/","title":"LST Anomalies in Regions","text":""},{"location":"workflows/LST-anomalies-in-regions/#introduction","title":"Introduction","text":"<p>This tutorial introduces a general workflow to map land surface temperature (LST) anomalies for locations in a region.  </p> <p>We use Baltimore, MD as a case to develop the model. We then test and adapt the model by changing our area of interest to Houston, Texas.   </p> <p>As you work through the tutorial, you may find it helpful to refer to the land surface temperature and anomalies pages in the Glossary. </p> <p>The app below shows what your final result should look like for the Test Case (Houston) by the end of the tutorial.   </p> <p> </p> <p>Link to app</p>"},{"location":"workflows/LST-anomalies-in-regions/#start-a-new-script","title":"Start a new script","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Name:         wk08_tutorial_lst_spatial_anomalies.js \n//  Problem:      LST anomalies within urban areas\n//  Date:         10/29/2023  \n//  Author:       Jeff Howarth  \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre>"},{"location":"workflows/LST-anomalies-in-regions/#define-area-of-interest","title":"Define area of interest","text":"<pre><code>// ------------------------------------------------------------------------\n//  Define area of interest\n// ------------------------------------------------------------------------\n\n// Import feature collection of Census 2020 Urban Areas from \"projects/ee-primer/assets/regions_usa/uac20\" \n// Filter for Baltimore, MD.\n\nvar aoi ;\n\nprint(\n'Urban Area'\n)\n;\n</code></pre> <p>2020 Tiger/Line Shapefiles </p>"},{"location":"workflows/LST-anomalies-in-regions/#define-aoi-extent-rectangle","title":"Define AOI extent rectangle","text":"<pre><code>// ------------------------------------------------------------------------\n//  Define area of interest extent rectangle.\n// ------------------------------------------------------------------------\n\nvar aoi_extent ;\n\n// Map.centerObject(aoi_extent, 10);\n// Map.setOptions('hybrid');\n\n\nprint(\n\"AOI\",\n\"EXTENT\"\n)\n;\n</code></pre>"},{"location":"workflows/LST-anomalies-in-regions/#calculate-lst-from-landsat","title":"Calculate LST from Landsat","text":"<pre><code>// ------------------------------------------------------------------------\n//  Calculate LST from Landsat Collection.\n// ------------------------------------------------------------------------\n\n// Import module for LST computation from 'users/sofiaermida/landsat_smw_lst:modules/Landsat_LST.js'\n\nvar LandsatLST = require('users/sofiaermida/landsat_smw_lst:modules/Landsat_LST.js');\n\n// Apply module to produce image collection.\n// Use the 'L8' collection.\n// Start: '2020-07-01'. End: '2022-09-01'.\n\nvar dataset = LandsatLST\n.collection\n(\n// landsat collection\n// start date  \n// end date\n// filter by aoi extent rectangle\n)\n;\n\n// Print first image in collection and size of collection.\n\nprint(\n'LST collection'\n)\n;\n</code></pre>"},{"location":"workflows/LST-anomalies-in-regions/#filter-collection","title":"Filter collection","text":"<pre><code>// ------------------------------------------------------------------------\n//  Filter Landsat image collection.\n// ------------------------------------------------------------------------\n\n// Filter the dataset for images collected in summer months (July and August)\n// with cloud cover less that 10 percent.\n// Also select only the 'LST' band from the images.\n\nvar output\n;\n\n// Print first image and size of collection.  \n\nprint(\n'Filtered Output'\n)\n;\n</code></pre>"},{"location":"workflows/LST-anomalies-in-regions/#reduce-collection-to-image","title":"Reduce collection to image","text":"<pre><code>// --------------------------------------------------------------------------------\n//  Reduce image collection to image.  \n// --------------------------------------------------------------------------------\n\n// Process image collection as follows:  \n//  (1) calculate the average (mean) temperature of summer month for each pixel; \n//  (2) convert units of reduced image from Kelvin to Fahrenheit;\n//  (3) clip to the aoi bounding geometry\n//  (4) rename the band \"AVG_LST_F\" in the output image.\n//\n// K to F conversion involves three steps:  \n//  (1) Subtract 273.15 from Kelvin temperature\n//  (2) Multiply by 1.8 \n//  (3) Add 32\n\nvar output_image ;\n\n// Print your result. \n\nprint(\n'Output image'\n)\n;\n</code></pre>"},{"location":"workflows/LST-anomalies-in-regions/#display-as-map-layer","title":"Display as map layer","text":"<pre><code>// ---------------------------------------------------------------------\n//  Display image as a map layer.  \n// ---------------------------------------------------------------------\n\n// Import modules.   \n\nvar tools = require('users/jhowarth/eePrimer:modules/image_tools.js');\nvar palettes = require('users/gena/packages:palettes');\n\n\n// Define viz parameters.\n\nvar output_viz = {\n// bands: [],\nmin: [0],\nmax: [150],\npalette: palettes.colorbrewer.YlOrRd[9]\n};\n\n// Make a histogram to see data distribution.  \n\n// var histogram = tools.makeHistogram(\n//         // Must be an image (not an image collection)\n//         // Select one band at a time.\n//         // Pixel resolution of image.\n//         // Minimum value of x-axis\n//         // Maximum value of x-axis.\n//   )\n// ;\n\n// Print, print, print...\n\nprint(\n\"Histogram\"\n)\n;\n</code></pre>"},{"location":"workflows/LST-anomalies-in-regions/#calculate-median-of-aoi","title":"Calculate median of AOI","text":"<pre><code>// ---------------------------------------------------------------------\n//  Calculate median LST value for the urban area. \n// ---------------------------------------------------------------------\n\nvar median_LST = ;\n\nprint(\n\"Median LST\"\n)\n;\n</code></pre>"},{"location":"workflows/LST-anomalies-in-regions/#convert-feature-collection-to-image","title":"Convert feature collection to image","text":"<pre><code>// ---------------------------------------------------------------------\n//  Convert to image. \n// ---------------------------------------------------------------------\n\nvar median_LST_image ;\n</code></pre>"},{"location":"workflows/LST-anomalies-in-regions/#calculate-anomalies","title":"Calculate anomalies","text":"<pre><code>// ---------------------------------------------------------------------\n//  Calculate anomalies as percent difference from regional median \n// ---------------------------------------------------------------------\n\nvar anomaly ;\n\nvar anomaly_viz ;\n\n// Make a histogram to see data distribution.  \n\n// var histogram = tools.makeHistogram(\n//     // Must be an image (not an image collection)\n//     // Select one band at a time.\n//     // Pixel resolution of image.\n//     // Minimum value of x-axis\n//     // Maximum value of x-axis.\n//   )\n// ;\n\n// Print, print, print...\n\nprint(\n\"Histogram\"\n)\n;\n\n// Display as layer.\n</code></pre>"},{"location":"workflows/LST-anomalies-in-regions/#add-legend","title":"Add legend","text":"<pre><code>// ---------------------------------------------------------------------\n//  Add legend \n// ---------------------------------------------------------------------\n\n//  Load cart module.\n\nvar cart = require('users/jhowarth/eePrimer:modules/cart.js');\n\n// Call makeGradientLegend function and pass three parameters.\n\n// var legend = cart                                                     // module\n//   .makeGradientLegend(                                                // function\n//       // viz parameters\n//       // a title for legend\n//       // position on map\n//   )\n// ;\n\n// Map.add(legend);\n</code></pre>"},{"location":"workflows/LST-anomalies-in-regions/#test-model-on-another-region","title":"Test model on another region","text":""},{"location":"workflows/LST-anomalies-in-regions/#tutorial-checks","title":"Tutorial Checks","text":"<pre><code>// --------------------------------------------------------------------------------\n//  Tutorial Checks  \n// --------------------------------------------------------------------------------\n\nvar check = require('users/jhowarth/eePrimer:modules/checks.js');\n\n// Please be sure to modify the model to fit the Test Case (Houston).\n// Please be prepared to report the following checks on the tutorial quiz.\n// These checks assume that you followed the names used in the tutorial. \n\n\nprint(\n\"CHECK 01:\", aoi.first().geometry().area(1).divide(1000000),\n\"CHECK 02:\", aoi_extent.area(1).divide(1000000),\n\"CHECK 03:\", dataset.size(),\n\"CHECK 04:\", output.size(),\n\"CHECK 05:\", check.t08(output_image, aoi),\n\"CHECK 06:\", median_LST.first().get(\"median\"),\n\"CHECK 07:\", check.t08(anomaly, aoi)\n);\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"workflows/changes_in_the_night/","title":"Changes in the Night","text":""},{"location":"workflows/changes_in_the_night/#introduction","title":"Introduction","text":"<p>This tutorial walks you through how to construct an RGB composite that visualizes change in the DMSP/OLS dataset between 1993 and 2013 like the image shown in the additive color chapter.  </p> <p>The diagram below illustrates the general workflow.  </p> <p></p> <p>The tutorial also shows you how to compose your script (using a dictionary and a custom function) so that you can easily change the three years used to define the RGB composite. In other words, the purpose of your script is not simply to deliver a map product, but instead to create a flexible tool for exploring and visualizing the nighttime lights dataset with additive color. </p>"},{"location":"workflows/changes_in_the_night/#start-a-new-script","title":"Start a new script","text":"<pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Name:     changes_in_the_night.js \n//  Author:   Jeff Howarth\n//  Date:     10/10/2023 \n//  Purpose:  Introduce additive color, nighttime lights, and patterns of change.\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  \n</code></pre>"},{"location":"workflows/changes_in_the_night/#load-image-collection-and-select-a-band","title":"Load image collection and select a band","text":"<pre><code>graph LR\n  arg1([\"pathname\\n\\nSTRING\"]) --&gt; method1[\"ee.ImageCollection()\"] ;\n  method1 --&gt; method2[\".select()\"] ;\n  arg2([\"band name\\n\\nSTRING\"]) --&gt; method2 ;\n  method2 --&gt; output&gt;\"output\\n\\nIMAGE COLLECTION\"];\n\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style arg1 fill:#DCDCDC,stroke-width:0px\n  style arg2 fill:#DCDCDC,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n</code></pre> <pre><code>// -----------------------------------------------------------------------\n//  Load image collection and select a band.  \n// -----------------------------------------------------------------------\n\n// Image Collection pathname: \"NOAA/DMSP-OLS/NIGHTTIME_LIGHTS\"\n// Band: \"stable_lights\"\n\nvar collection ;\n\nprint(\n\"Collection\",\ncollection,\ncollection.size(),                            collection.first(),\ncollection.first().bandNames()                )\n;\n</code></pre>"},{"location":"workflows/changes_in_the_night/#create-dictionary-for-study-years","title":"Create dictionary for study years","text":"<pre><code>// -----------------------------------------------------------------------\n//  Create a dictionary for study years to assign band 1, 2, 3\n// -----------------------------------------------------------------------\n\n// Your goal is to display pixel values in each layer with these colors:\n//  2013 with red,\n//  2003 with green,\n//  1992 with blue.\n\nvar yrs = {\n\n};\n</code></pre>"},{"location":"workflows/changes_in_the_night/#make-image-for-band-1","title":"Make image for Band 1","text":"<pre><code>graph LR\n  input[/\"collection\\n\\nIMAGE COLLECTION\"/] --&gt; method1[\".filter()\"] ;\n  arg1([\"study year\\n\\nDICTIONARY KEY\"]) --&gt; method2([\"ee.Filter.calendarRange()\"]) ;\n  arg2([\"time unit\\n\\nSTRING\"]) --&gt; method2 ;\n  method2 --&gt; method1 ;\n  method1 --&gt; method3[\".first()\"] ;\n  method3 --&gt; method4[\".rename()\"] ;\n  method5([\"String()\\n\\nFUNCTION\"]) --&gt; method4 ;\n  arg1 --&gt; method5 ;\n  method4 --&gt; output&gt;\"output\\n\\nIMAGE\"] ;\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style method4 fill:#ADD8E6,stroke-width:0px\n  style method5 fill:#ADD8E6,stroke-width:0px\n  style arg1 fill:#DCDCDC,stroke-width:0px\n  style arg2 fill:#DCDCDC,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n</code></pre> <pre><code>// -----------------------------------------------------------------------\n//  Make an image for band 1  \n// -----------------------------------------------------------------------\n\nvar b1 = collection\n;\n\nprint(\n\"Band 1:\",\nb1\n)\n;\n</code></pre>"},{"location":"workflows/changes_in_the_night/#display-image-as-a-map-layer","title":"Display image as a map layer","text":"<pre><code>// -----------------------------------------------------------------------\n//  Display image as layer on the map.\n// -----------------------------------------------------------------------\n\nMap.setCenter(126.8, 33.485, 5);\nMap.setOptions('HYBRID');\n\nvar viz ;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/changes_in_the_night/#make-and-display-image-for-band-2","title":"Make and display image for Band 2","text":"<pre><code>graph LR\n  input[/\"collection\\n\\nIMAGE COLLECTION\"/] --&gt; method1[\".filter()\"] ;\n  arg1([\"study year\\n\\nDICTIONARY KEY\"]) --&gt; method2([\"ee.Filter.calendarRange()\"]) ;\n  arg2([\"time unit\\n\\nSTRING\"]) --&gt; method2 ;\n  method2 --&gt; method1 ;\n  method1 --&gt; method3[\".mean()\"] ;\n  method3 --&gt; method4[\".rename()\"] ;\n  method5([\"String()\\n\\nFUNCTION\"]) --&gt; method4 ;\n  arg1 --&gt; method5 ;\n  method4 --&gt; output&gt;\"output\\n\\nIMAGE\"];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style method4 fill:#ADD8E6,stroke-width:0px\n  style method5 fill:#ADD8E6,stroke-width:0px\n  style arg1 fill:#DCDCDC,stroke-width:0px\n  style arg2 fill:#DCDCDC,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n</code></pre> <pre><code>// -----------------------------------------------------------------------\n//  Make and display image for band 2.  \n// -----------------------------------------------------------------------\n\nvar b2 ;\n\nprint(\n\"Band 2:\",\nb2\n)\n;\n\nMap.addLayer();\n</code></pre> <p>Source</p>"},{"location":"workflows/changes_in_the_night/#write-a-function","title":"Write a function","text":"<pre><code>// -----------------------------------------------------------------------\n//  Write a function  \n// -----------------------------------------------------------------------\n\nvar makeImageForBand ;\n\n// Call the function\n\nvar b1 ;\n\n// Display result as a layer. \n\n// Map.addLayer();\n</code></pre>"},{"location":"workflows/changes_in_the_night/#test-generality-of-function","title":"Test generality of function","text":"<pre><code>// -----------------------------------------------------------------------\n//  Test generality of function.  \n// -----------------------------------------------------------------------\n\n// Does .first() and .mean() deliver identical results for b1 case?\n\nvar test ;\n\n// Map.addLayer();\n</code></pre>"},{"location":"workflows/changes_in_the_night/#revise-script-to-apply-function","title":"Revise script to apply function","text":"<pre><code>// -----------------------------------------------------------------------\n//  Revise script to apply function. \n// -----------------------------------------------------------------------\n\n// 1. Comment out sections above that made and drew b1 and b2;\n\n// 2. Redefine map options and viz parameters (that were commented out).\n\nMap.setCenter(126.8, 33.485, 5);\nMap.setOptions('HYBRID');\n\nvar viz = {min:0, max: 63};\n\n// 3. Call function to remake all bands\n\nvar b1 ;\nvar b2 ;\nvar b3 ;\n\n// 4. Add results as layers to map.\n\nMap.addLayer();\n// \n</code></pre>"},{"location":"workflows/changes_in_the_night/#make-and-display-rgb-composite-image","title":"Make and display RGB composite image","text":"<pre><code>graph LR\n  input[/\"Band 1\\n\\nIMAGE\"/] --&gt; method1[\".addBands()\"] ;\n  method1 --&gt; method2[\".addBands()\"] ;\n  arg1([\"Band 2\\n\\nIMAGE\"]) --&gt; method1 ;\n  arg2([\"Band 3\\n\\nIMAGE\"]) --&gt; method2 ;\n  method2 --&gt; output&gt;\"output\\n\\nIMAGE\"];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style arg1 fill:#C5E6A1,stroke-width:0px\n  style arg2 fill:#C5E6A1,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n</code></pre> <pre><code>// -----------------------------------------------------------------------\n//  Construct and display three band image from the three images.  \n// -----------------------------------------------------------------------\n\n// Create image. \n\nvar change_image ;\n\nprint(\n\"Change Image\",\nchange_image\n)\n;\n\n// Display result as a map layer. \n\nMap.addLayer();\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"workflows/global-forest-loss/","title":"Global Forest Change","text":""},{"location":"workflows/global-forest-loss/#introduction","title":"Introduction","text":"<p>The three tutorials linked below will show you how to work with Matthew Hansen\u2019s Global Forest Change dataset in Earth Engine. This dataset shows loss and recovery of tree canopy at 30 meter spatial resolution for every year since 2000 across much of the Earth. </p> <p>You can use the app below to explore the dataset. At the bottom of the panel on the right side, select an Example Location from the pick list and then click Zoom to area.  </p> <p> </p> <p>Open app in a new tab</p> <p>After exploring the dataset through the app, please work through the three tutorials linked below.  </p>"},{"location":"workflows/global-forest-loss/#introduction-to-global-forest-change-data","title":"Introduction to Global Forest Change Data","text":"<p>Please start a new script and save it to your repository.  </p> <pre><code>// //  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Name:         wk09_tutorial_hansen_global_forest_dataset.js \n//  Problem:      Quantifying Forest Change\n//  Date:         \n//  Author:         \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre> <p>Open up the first tutorial and work through it. </p> <p>You may find it helpful to use the code snippet below as a frame to copy and paste the code blocks in the tutorial. The checks at the end of the tutorial will ask you to report results that you print to Console. These checks reference the Code Block numbers in the snippets below to help you find the results to report. </p> <pre><code>// -----------------------------------------------------------------------\n//  I. Introduction to Hansen at al. Global Forest Change Data\n// -----------------------------------------------------------------------\n\n// -- CODE BLOCK 1 --\n\n\n// -- CODE BLOCK 2 --\n\n\n// -- CODE BLOCK 3 --\n\n\n// -- CODE BLOCK 4 --\n\n\n// -- CODE BLOCK 5 --\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n//  PALETTES\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n\n// -- CODE BLOCK 6 --\n\n\n// -- CODE BLOCK 7 --\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n//  MASKING\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n\n// -- CODE BLOCK 8 --\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n//  EXAMPLE\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n\n// -- CODE BLOCK 9 --\n</code></pre>"},{"location":"workflows/global-forest-loss/#quantifying-forest-loss","title":"Quantifying Forest Loss","text":"<p>Open up the second tutorial and work through it. </p> <pre><code>// -----------------------------------------------------------------------\n//  II. Quantifying Forest Change  \n// -----------------------------------------------------------------------\n\n// -- Code Block 1 --\n\n\n\n// -- Code Block 2 --\n\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n//  Quantifyin Forest Change in a Region\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n// -- Code Block 3 --\n\n\n\n// -- Code Block 4 --\n\n\n\n// -- Code Block 5 --\n\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n//  Calculating Pixel Areas  \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n// -- Code Block 6 --\n\n\n\n// -- Code Block 7 --\n</code></pre>"},{"location":"workflows/global-forest-loss/#charting-yearly-forest-loss","title":"Charting Yearly Forest Loss","text":"<p>Open up the third tutorial and work through it. </p> <pre><code>// -----------------------------------------------------------------------\n//  III. CHARTING YEARLY FOREST LOSS\n// -----------------------------------------------------------------------\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n//  Calculating Yearly Forest Loss   \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n// -- Code Block 1 --\n\n\n\n// -- Code Block 2 --\n\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n//  Calculating Yearly Forest Loss   \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n// -- Code Block 3 --\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/","title":"Grassland Bird Habitat","text":""},{"location":"workflows/grassland_bird_habitat/#introduction","title":"Introduction","text":"<p>This tutorial aims to answer the question:  </p> <p>In 2016, where was the best potential habitat for grassland birds in the Champlain Valley that was owned by Middlebury College?</p> <p>To answer this question, we will develop a model based on these guidelines developed by the Vermont Agency of Natural Resources.  </p>"},{"location":"workflows/grassland_bird_habitat/#background","title":"Background","text":"<p>The Bobolink (Dolichonyx oryzivorus) is a grassland bird species with a bubbling song and a remarkable life cycle. Bobolinks winter in South America, primarily Paraguay, Argentina, and Bolivia. In the spring, they migrate back to their breeding habitats in North America, including grassland habitat here in the Champlain Valley. Interestingly, Bobolinks seem to have keen spatial memory and sense of place; they tend to return to the same specific field each summer to breed and research indicates that this \u201csite fidelity\u201d improves breeding success. </p> <p></p> <p>source: iNaturalist</p> <p>Bobolinks are also an interesting example of a \u201cnew native\u201d species. During Abenaki times, Bobolinks did not breed in Vermont, because there was very little grassland habitat for them to do so. Open, grassy habitat was uncommon in what we now call the Champlain Valley; the landscape here was largely forested, save for the margins of water bodies and places where Abekai cultivated crops or set fires at a frequency that prevented trees from growing. Following the American Revolution, white migrants appropriated Abenaki lands in the Champlain Valley and pitched farms, claiming the land by clearing it of trees. This created large expanses of open habitat in the formerly forested landscape. Bobolinks soon colonized this new habitat, migrating from native breeding territories on the midwestern prairies of North America.  </p> <p>Today, Vermont plays an important role in the conservation of Bobolinks and other native North American grassland species. Since the 1940s, breeding populations of Bobolinks have significantly declined across North America, primarily from habitat loss caused by both changes in agricultural practices and the conversion of agricultural land into other land uses. </p> <p>This tutorial develops a model with Earth Engine to identify where Middlebury College owns land that could contribute to the conservation of native North American grassland bird species by protecting the open structure of the habitat and working with farmers to adapt land use practices that do not conflict with breeding cycles of grassland birds.   </p>"},{"location":"workflows/grassland_bird_habitat/#criteria","title":"Criteria","text":"<p>According to the ANR guidelines, the best potential habitat for Bobolink and other grassland bird species should meet the following criteria: </p> <ol> <li>Open land cover (grass/shrub, water, bare);</li> <li>Buffered from the edge, or with a core area that is at least 50 meters from closed habitat structure (tree canopy) or developed land (roads, buildings, pavement, etc);  </li> <li>Large, or at least 20 acres in area;</li> <li>With a large interior, or a perimeter-area ratio of 0.015 or less. </li> </ol>"},{"location":"workflows/grassland_bird_habitat/#workflow-overview","title":"Workflow overview","text":"<p>The diagram below shows the general workflow for the model, or how each step in the tutorial connects to other steps. The color represents the format of the result (or output) of each step as shown below.  </p> <p> <pre><code>graph TD\n  vector[vector] ;\n  raster[raster] ;\n  task[task] ;\n\nstyle vector fill:#E1C3E6,stroke-width:0px\nstyle raster fill:#C5E6A1,stroke-width:0px\nstyle task fill:#ADD8E6,stroke-width:0px</code></pre> <p></p> <p>Here is how each step in the workflow connects to another step.     </p> <p> <pre><code>graph LR\n  step01[1] ;\n  step02[2] ;\n  step03[3] ;\n  step04[4] ;\n  step05[5] ;\n  step06[6] ;\n  step07[7] ;\n  step08[8] ;\n  step09[9] ;\n  step10[10] ;\n  step11[11] ;\n  step12[12] ;\n  step13[13] ;\n  step14[14] ;\n  step15[15] ;\n  step16[16] ;\n\n  step01 --&gt; step02 --&gt; step03  \n  step04 --&gt; step05\n  step03 --&gt; step06\n  step05 --&gt; step06\n  step06 --&gt; step07 \n  step07 --&gt; step08  \n  step08 --&gt; step09\n  step02 --&gt; step10\n  step09 --&gt; step10  \n  step09 --&gt; step11\n  step11 --&gt; step12\n  step03 --&gt; step12\n  step12 --&gt; step13  \n  step02 --&gt; step13\n  step13 --&gt; step14  \n  step14 --&gt; step15\n  step15 --&gt; step16\n\n  style step01 fill:#E1C3E6,stroke-width:0px\n  style step02 fill:#E1C3E6,stroke-width:0px\n  style step03 fill:#E1C3E6,stroke-width:0px\n  style step04 fill:#C5E6A1,stroke-width:0px\n  style step05 fill:#C5E6A1,stroke-width:0px\n  style step06 fill:#C5E6A1,stroke-width:0px\n  style step07 fill:#C5E6A1,stroke-width:0px\n  style step08 fill:#C5E6A1,stroke-width:0px\n  style step09 fill:#C5E6A1,stroke-width:0px\n  style step10 fill:#E1C3E6,stroke-width:0px\n  style step11 fill:#C5E6A1,stroke-width:0px\n  style step12 fill:#E1C3E6,stroke-width:0px\n  style step13 fill:#E1C3E6,stroke-width:0px\n  style step14 fill:#E1C3E6,stroke-width:0px\n  style step15 fill:#E1C3E6,stroke-width:0px\n  style step16 fill:#ADD8E6,stroke-width:0px</code></pre> <p></p> <p>The connections are made because the output of one step provides an input or argument for another step. This makes the workflow one long chain, or a series of connected input-method-output links. </p> <p>The videos below walk you through each step in this workflow.    </p>"},{"location":"workflows/grassland_bird_habitat/#start-a-new-script","title":"Start a new script","text":"<pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//\n//  Grassland bird habitat on Middlebury College Lands in Champlain Valley. \n//  \n//  Jeff Howarth \n//  Sept 30, 2023\n//\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#1-load-feature-collection-and-filter-by-attribute","title":"1. Load feature collection and filter by attribute","text":""},{"location":"workflows/grassland_bird_habitat/#template","title":"template","text":"<pre><code>// Load feature collection and filter by attribute.    \n\nvar output = ee.FeatureCollection(\"path\")\n.filter(ee.Filter.eq(\"propertyKey\", \"value\"))\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram","title":"diagram","text":"<pre><code>graph LR\n  method1[\"ee.FeatureCollection()\"] ;\n  arg_att1([pathname\\n\\nSTRING]) --&gt; method1;\n\n  method1 --&gt; method2[\".filter()\"];\n  method2 --&gt; method3([\"ee.Filter.eq()\"]);\n\n  method3 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n  arg_att2([property key\\n\\nSTRING]) --&gt; method3;\n  arg_att3([value\\n\\nSTRING]) --&gt; method3;\n\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  1. Load feature collection and filter by attribute.\n//\n//  Isolate Champlain Lowlands.\n// ---------------------------------------------------------------------------\n\nvar region = ee.FeatureCollection(\"projects/conservation-atlas/assets/regions/Ecoregion_07232023\");\n\nprint(\n\"STEP 1:\"\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#2-load-feature-collection-and-filter-by-location","title":"2. Load feature collection and filter by location","text":""},{"location":"workflows/grassland_bird_habitat/#template_1","title":"template","text":"<pre><code>// Load feature collection and filter by location.  \n\nvar output = ee.FeatureCollection(\"path\")\n.filterBounds(target)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_1","title":"diagram","text":"<pre><code>graph LR\n  method1[\"ee.FeatureCollection()\"] ;\n  arg_att1([path\\n\\nSTRING]) --&gt; method1;\n\n  method1 --&gt; method2[\".filterBounds()\"];\n  method2 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n  arg_att2([target\\n\\nGEOMETRY or FEATURE]) --&gt; method2;\n\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#E1C3E6,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_1","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_1","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  2. Load feature collection and filter by location,\n//\n//  Isolate College Lands in Champlain Valley.\n// ---------------------------------------------------------------------------\n\nvar college_lands = ee.FeatureCollection(\"projects/conservation-atlas/assets/cadastre/Midd_College_Parcels_withattributes\");\n\nprint(\n\"STEP 2:\"\n)\n;\n\nMap.centerObject();\nMap.setOptions();\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#3-define-study-region","title":"3. Define study region","text":""},{"location":"workflows/grassland_bird_habitat/#template_2","title":"template","text":"<pre><code>// Define study region  \n\nvar output = FC\n.union(maxError)       .geometry() .bounds(maxError) .buffer(distance, maxError)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_2","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nFEATURE COLLECTION/] --&gt; method1[\".union()\"] ;\n\n  method1 --&gt; method2[\".geometry()\"];\n  method2 --&gt; method3[\".bounds()\"];\n  method3 --&gt; method4[\".buffer()\"]\n  method4 --&gt; output&gt;output\\n\\nGEOMETRY];\n\n  arg_att1([maxError\\n\\nNUMBER]) --&gt; method1 ;\n  arg_att2([maxError\\n\\nNUMBER])  --&gt; method3 ;\n  arg_att3([distance\\n\\nNUMBER])  --&gt; method4 ;\n  arg_att4([maxError\\n\\nNUMBER])  --&gt; method4 ;\n\n\n  style input fill:#E1C3E6,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style method4 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px\n  style arg_att4 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_2","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_2","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n// 3. Define study region\n// ---------------------------------------------------------------------------\n\nvar bounds ;\n\nprint(\n\"STEP 3:\",\nbounds\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#4-load-an-image","title":"4. Load an image","text":""},{"location":"workflows/grassland_bird_habitat/#template_3","title":"template","text":"<pre><code>// Load an image.  \n\nvar output = ee.Image(\"path\")\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_3","title":"diagram","text":"<pre><code>graph LR\n  method1[\"ee.Image()\"] ;\n  arg_att1([path\\n\\nSTRING]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_3","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_3","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  4. Load an image\n//\n//  Import land cover image for Vermont.\n// ---------------------------------------------------------------------------\n\nvar lc ;\n\nvar lc_viz = {\nmin: 1,\nmax: 8,\npalette: [\n'#ABD998',    //   1. Tree Canopy  \n'#EBF09C',    //   2. Grass/Shrub \n'#f7f7f7',    //   3. Bare soil\n'#95E6D5',    //   4. Water\n'#525252',    //   5. Buildings    \n'#F7F7F7',    //   6. Roads\n'#cccccc',    //   7. 0ther pavement\n'#F7F7F7',    //   8. Railroads  \n]\n};\n\nprint(\n\"STEP 4:\", lc,\nlc.projection()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#5-reclassify-an-image","title":"5. Reclassify an image","text":""},{"location":"workflows/grassland_bird_habitat/#template_4","title":"template","text":"<pre><code>// Reclassify an image.  \n\nvar output = input.remap(\n[\"o\",\"l\",\"d\"],\n[\"n\",\"e\",\"w\"],\n);\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_4","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".remap()\"] ;\n  arg_att1([old values\\n\\nLIST]) --&gt; method1;\n  arg_att2([new values\\n\\nLIST]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_4","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_4","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  5. Reclassify an image\n//\n//  Make a binary image of grasslands.  \n// ---------------------------------------------------------------------------\n\nvar lc_binary ;\n\nprint(\n\"STEP 5:\",\nlc_binary,\nlc_binary.projection()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#6-clip-image-by-region","title":"6. Clip image by region","text":""},{"location":"workflows/grassland_bird_habitat/#template_5","title":"template","text":"<pre><code>// Clip image by region.  \n\nvar output = input.clip(region)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_5","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".clip()\"] ;\n  arg_att1([region or aoi\\n\\nGEOMETRY, FEATURE or\\nFEATURE COLLECTION]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_5","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_5","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  6. Clip image by region\n//\n//  Isolate grasslands in study region. \n// ---------------------------------------------------------------------------\n\nvar lc_binary_bounds ;\n\nprint(\n\"STEP 6:\",\nlc_binary_bounds,\nlc_binary_bounds.projection()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#7-select-by-pixel-value","title":"7. Select by pixel value","text":""},{"location":"workflows/grassland_bird_habitat/#template_6","title":"template","text":"<pre><code>// Select a pixel value (make a binary).\n\nvar output = input.ee(value)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_6","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".eq()\"] ;\n  arg_att1([value\\n\\nNUMBER]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_6","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_6","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  7. Select by pixel value.\n//\n//  Invert the grassland binary. \n// ---------------------------------------------------------------------------\n\nvar invert_binary ;\n\nprint(\n\"STEP 7:\",\ninvert_binary,\ninvert_binary.projection()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#8-compute-distance","title":"8. Compute distance","text":""},{"location":"workflows/grassland_bird_habitat/#template_7","title":"template","text":"<pre><code>// Compute distance with a euclidean kernel.   \n\nvar output = input\n.distance(\nee.Kernel.euclidean(radius, \"units\")\n)\n.reproject(\"crs\")       // When should you comment out this line?\n.unmask(value)          )\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_7","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".distance()\"] ;\n  method1 --&gt; method2([\"ee.Kernel.euclidean()\"])\n  arg_att1([radius\\n\\nNUMBER]) --&gt; method2;\n  arg_att2([units\\n\\nSTRING]) --&gt; method2;\n  method2 --&gt; method3[\".reproject()\"]\n  arg_att3([crs\\n\\nSTRING]) --&gt; method3;\n  method3 --&gt; method4(\".unmask()\")\n  arg_att4([value\\n\\nNUMBER]) --&gt; method4;\n  method4 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style method4 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px\n  style arg_att4 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_7","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_7","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  8. Compute distance \n//\n//  Calculate distance from edge of grasslands towards interior\n// ---------------------------------------------------------------------------\n\nvar crs = \"EPSG: 32145\"; // Vermont State Plane North American Datum 1983\n\nvar grassland_distance ;\n\nprint(\n\"Step 8:\",\ngrassland_distance,\ngrassland_distance.projection()\n)\n;\n\n// Here is a nice palette that looks good for distance when you reverse it.\n\nvar inferno = [\"#000004\", \"#320A5A\", \"#781B6C\", \"#BB3654\", \"#EC6824\", \"#FBB41A\", \"#FCFFA4\"].reverse();\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#9-select-by-a-threshold-value","title":"9. Select by a threshold value","text":""},{"location":"workflows/grassland_bird_habitat/#template_8","title":"template","text":"<pre><code>// Select by threshold value (and output a binary).\n\nvar output = input.gt(value)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_8","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".gt()\"] ;\n  arg_att1([value\\n\\nNUMBER]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_8","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_8","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  9. Select by threshold value \n//\n//  Isolate all pixels that are greater than 50 meters from grassland edge. \n// ---------------------------------------------------------------------------\n\nvar grassland_cores ;\n\nprint(\n\"Step 9:\",\ngrassland_cores,\ngrassland_cores.projection()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#10-zonal-overlay","title":"10. Zonal overlay","text":""},{"location":"workflows/grassland_bird_habitat/#template_9","title":"template","text":"<pre><code>// Zonal overlay.\n\nvar output = input.reduceRegions(\n{\ncollection: cutter,\nreducer: ee.Reducer(),\nscale: number,\ncrs: \"string\"\n}\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_9","title":"diagram","text":"<pre><code>graph LR\n  input[/\"input 'dough'\"\\n\\nIMAGE/] --&gt; method1[\".reduceRegions()\"] ;\n  arg_att1([\"collection 'cutter'\"\\n\\nFEATURE COLLECTION]) --&gt; method1;\n  arg_att2([reducer\\n\\nREDUCER]) --&gt; method1;\n  arg_att3([scale\\n\\nNUMBER]) --&gt; method1;\n  arg_att4([crs\\n\\nSTRING]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#E1C3E6,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px\n  style arg_att4 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_9","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_9","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  10. Zonal overlay \n//\n//  Find college parcels that overlap core grassland habitat. \n// ---------------------------------------------------------------------------\n\nvar college_with_core ;\n\nvar college_with_core_filter ;\n\nprint(\n\"STEP 10:\",\ncollege_with_core.size(),\ncollege_with_core_filter.size()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#11-mask-an-image","title":"11. Mask an image.","text":""},{"location":"workflows/grassland_bird_habitat/#template_10","title":"template","text":"<p>Case 1: to use an image to mask another image.</p> <pre><code>/// Use an image to mask another image.  \n\nvar output = input.updateMask(mask)\n;\n</code></pre> <p>Case 2: to use an image to mask itself.  </p> <pre><code>/// Use an image to mask itself.  \n\nvar output = input.selfMask()\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_10","title":"diagram","text":"<p>Case 1: to use an image to mask another image.</p> <pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".updateMask()\"] ;\n  arg_att1([mask\\n\\nIMAGE]) --&gt; method1;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px\n  style arg_att1 fill:#C5E6A1,stroke-width:0px</code></pre> <p>Case 2: to use an image to mask itself.  </p> <pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".selfMask()\"] ;\n  method1 --&gt; output&gt;output\\n\\nIMAGE];\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#C5E6A1,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_10","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_10","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  11. Mask an image\n//\n//  Ignore all pixels that are not grasslands. \n// ---------------------------------------------------------------------------\n\nvar grassland_cores_masked;      print(\n\"STEP 11:\",\ngrassland_cores_masked,\ngrassland_cores_masked.projection()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#12-make-objects","title":"12. Make objects","text":""},{"location":"workflows/grassland_bird_habitat/#template_11","title":"template","text":"<pre><code>// Make objects from a binary image. \n\nvar output = input.reduceToVectors(\n{\nreducer: ee.Reducer(),\ngeometry: aoi, // area of interest   \nscale: number,\ngeometryType: \"string\",\neightConnected: boolean,  maxPixels: 1e12, geometryInNativeProjection: boolean }\n);\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_11","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nIMAGE/] --&gt; method1[\".reduceToVectors()\"] ;\n  method1 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n  arg_att1([reducer\\n\\nREDUCER]) --&gt; method1;\n  arg_att2([aoi\\n\\nGEOMETRY]) --&gt; method1;\n  arg_att3([scale\\n\\nNUMBER]) --&gt; method1;\n  arg_att4([geometryType\\n\\nSTRING]) --&gt; method1;\n  arg_att5([eightConnected\\n\\nBOOLEAN]) --&gt; method1;\n  arg_att6([maxPixels\\n\\nNUMBER]) --&gt; method1;\n  arg_att7([geometryInNativeProjection\\n\\nBOOLEAN]) --&gt; method1;\n\n  style input fill:#C5E6A1,stroke-width:0px\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n\n  style arg_att1 fill:#ADD8E6,stroke-width:0px\n  style arg_att2 fill:#E1C3E6,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px\n  style arg_att4 fill:#DCDCDC,stroke-width:0px\n  style arg_att5 fill:#DCDCDC,stroke-width:0px\n  style arg_att6 fill:#DCDCDC,stroke-width:0px\n  style arg_att7 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_11","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_11","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  12. Make objects. \n//\n//  Identify contiguous regions of grassland. \n// ---------------------------------------------------------------------------\n\nvar grassland_objects ;\n\nprint(\n\"STEP 12:\",\ngrassland_objects\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#13-select-by-location","title":"13. Select by location","text":""},{"location":"workflows/grassland_bird_habitat/#template_12","title":"template","text":"<pre><code>// Select by location.  \n\nvar output = input\n.filterBounds(target)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_12","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nFEATURE COLLECTION/] --&gt; method2[\".filterBounds()\"];\n  method2 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n  arg_att1([target\\n\\nGEOMETRY or FEATURE]) --&gt; method2;\n\n  style input fill:#E1C3E6,stroke-width:0px  \n  style method2 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#E1C3E6,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_12","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_12","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  13. Select by location.\n//\n//  Isolate grasslands on College Lands. \n// ---------------------------------------------------------------------------\n\nvar college_grasslands ;\n\nprint(\n\"STEP 13:\",\ncollege_grasslands.size(),\ncollege_grasslands.first()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#14-map-function-over-collection","title":"14. Map function over collection","text":""},{"location":"workflows/grassland_bird_habitat/#template_13","title":"template","text":"<pre><code>// Step 1: Write a function that takes a feature input. \n\nvar myFunction = function(feature) {\n\nvar crs = string ; var area = feature.area(1, crs) ;\n\nreturn feature.set(\"area\", area) ;\n}\n\n// Step 2: Apply the function to every feature in a collection.   \n\nvar output = input.map(myFunction)\n;\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_13","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nFEATURE COLLECTION/] --&gt; method2[\".map()\"];\n  method2 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n  arg_att1([getArea\\n\\nFUNCTION]) --&gt; method2;\n\n  style input fill:#E1C3E6,stroke-width:0px  \n  style method2 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#ADD8E6,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_13","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_13","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  14. Compute spatial attributes.\n//\n//  Calculate area and perimeter-area ratios.\n// ---------------------------------------------------------------------------\n\nvar getArea = function(f) {\nvar crs = \"EPSG: 32145\"; // Vermont State Plane North American Datum 1983\nvar area = f.area(1, crs).divide(4046.86);\nvar pa = f.perimeter(1, crs).divide(f.area(1, crs));\nreturn f.set({\"area\": area, \"pa\": pa});\n};\n\nvar grasslands_with_criteria ;\n\nprint(\n\"STEP 14:\",\ngrasslands_with_criteria.size(),\ngrasslands_with_criteria.first()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#15-select-by-two-attributes","title":"15. Select by two attributes","text":""},{"location":"workflows/grassland_bird_habitat/#template_14","title":"template","text":"<pre><code>// Select features from a collection by two attributes.\n\nvar output = input.filter(\nee.Filter.and(\nee.Filter.first(\"property\",\"value\"),\nee.Filter.second(\"property\",\"value\")\n)\n);\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_14","title":"diagram","text":"<pre><code>graph LR\n  input[/input\\n\\nFEATURE COLLECTION/] --&gt; method1[\".filter()\"];\n  method1 --&gt; method2([\"ee.Filter.and()\"])\n\n  method3([\"ee.Filter.gt()\"]) --&gt; method2;\n  method4([\"ee.Filter.lte()\"]) --&gt; method2;\n\n  arg_att1([property\\n\\nSTRING]) --&gt;method3;\n  arg_att2([value\\n\\nNUMBER]) --&gt;method3;\n\n  arg_att3([property\\n\\nSTRING]) --&gt;method4;\n  arg_att4([value\\n\\nNUMBER]) --&gt;method4;\n\n  method2 --&gt; output&gt;output\\n\\nFEATURE COLLECTION];\n\n\n  style input fill:#E1C3E6,stroke-width:0px  \n  style method1 fill:#ADD8E6,stroke-width:0px\n  style method2 fill:#ADD8E6,stroke-width:0px\n  style method3 fill:#ADD8E6,stroke-width:0px\n  style method4 fill:#ADD8E6,stroke-width:0px\n  style output fill:#E1C3E6,stroke-width:0px\n  style arg_att1 fill:#DCDCDC,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px\n  style arg_att4 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_14","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_14","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  15. Select by two attributes\n//\n//  Identify grasslands that meet both criteria.\n// ---------------------------------------------------------------------------\n\nvar best_grassland_habitat ;\n\nprint(\n\"STEP 15:\",\nbest_grassland_habitat.size(),\nbest_grassland_habitat.first()\n)\n;\n\nMap.addLayer();\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#16-export-to-ee-asset","title":"16. Export to EE Asset","text":""},{"location":"workflows/grassland_bird_habitat/#template_15","title":"template","text":"<pre><code>// Export feature collection to Asset.  \n\nExport.table.toAsset({\ncollection: FeatureCollection, description: \"string\", assetId: \"string\"\n}\n);\n</code></pre>"},{"location":"workflows/grassland_bird_habitat/#diagram_15","title":"diagram","text":"<pre><code>graph LR\n  method1[\"Export.table.toAsset()\"] --&gt; output&gt;output\\n\\nTASK];\n\n  arg_att1([collection\\n\\nFEATURE COLLECTION]) --&gt; method1;\n  arg_att2([description\\n\\nSTRING]) --&gt; method1\n  arg_att3([assetId\\n\\nSTRING]) --&gt; method1\n\n  style method1 fill:#ADD8E6,stroke-width:0px\n  style output fill:#ADD8E6,stroke-width:0px\n  style arg_att1 fill:#E1C3E6,stroke-width:0px\n  style arg_att2 fill:#DCDCDC,stroke-width:0px\n  style arg_att3 fill:#DCDCDC,stroke-width:0px</code></pre>"},{"location":"workflows/grassland_bird_habitat/#demo_15","title":"demo","text":""},{"location":"workflows/grassland_bird_habitat/#demo-code_15","title":"demo code","text":"<pre><code>// ---------------------------------------------------------------------------\n//  16. Export to EE Asset\n//\n//  To run workflow with crs condition on distance (Step 10).\n// ---------------------------------------------------------------------------\n\nvar x_name = \"Best_college_grasslands_0930_2023\"; Export.table.toAsset({\ncollection: best_grassland_habitat, description: x_name, assetId: x_name\n}\n);\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"workflows/image_collections/","title":"Basic Image Collections","text":""},{"location":"workflows/image_collections/#introduction","title":"Introduction","text":"<p>This tutorial introduces a common workflow for processing and visualizing image collections with Earth Engine. You will use a MODIS Land Surface Temperature product to make a map that shows the mean LST for January 2023 in degrees Celsius. By the end of the tutorial, you should have a map that looks like the image below. </p> <p></p>"},{"location":"workflows/image_collections/#start-a-new-script","title":"Start a new script","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  TITLE:      wk02_tutorial.js\n//  AUTHOR:     your name\n//  DATE:       today's date\n//  PURPOSE:    A basic workflow for processing image collections.     \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n\n// Load check module. \n\nvar check = require('users/jhowarth/eePrimer:modules/checks.js');\n\n// ----------------------------------------------------------------\n//  Process the image collection.\n// ----------------------------------------------------------------\n</code></pre>"},{"location":"workflows/image_collections/#load-image-collection","title":"Load image collection","text":"<pre><code>// Step 1: Load image collection\n\nvar step_1 = ee.ImageCollection();\n</code></pre>"},{"location":"workflows/image_collections/#filter-by-date","title":"Filter by date","text":"<pre><code>// Step 2: Filter image collection by date.\n\nvar step_2 = step_1.filter(ee.Filter.date());\n</code></pre>"},{"location":"workflows/image_collections/#select-band","title":"Select band","text":"<pre><code>// Step 3: Select band.\n\nvar step_3 = step_2.select();\n</code></pre>"},{"location":"workflows/image_collections/#reduce-to-image","title":"Reduce to image","text":"<pre><code>// Step 4: Reduce image collection.\n\nvar step_4 = step_3;\n</code></pre>"},{"location":"workflows/image_collections/#scale-data-if-necessary","title":"Scale data (if necessary)","text":"<pre><code>// Step 5: Apply scalar (if EE data catalog tells you the data are scaled).\n\nvar step_5 = step_4;\n</code></pre>"},{"location":"workflows/image_collections/#convert-units-if-necessary","title":"Convert units (if necessary)","text":"<pre><code>// Step 6: Convert units (if units need conversion).\n\nvar step_6 = step_5;\n</code></pre>"},{"location":"workflows/image_collections/#visualize-results-as-layer","title":"Visualize results as layer","text":"<pre><code>// ----------------------------------------------------------------\n//  Visualize results as layer.\n// ----------------------------------------------------------------\n\n//  Set base map.\n\n\n\n//  Load community palettes. \n\nvar palettes = require('users/gena/packages:palettes');\n\n// print('Community palettes', palettes);\n\n//  Define visualization parameters. \n\n// var viz = {\n//   bands: ,\n//   min: ,\n//   max: , \n//   palette: palettes.colorbrewer.RdBu[11]\n// };\n\n//  Display the data values with the visualization parameters.\n\n// Map.addLayer();\n</code></pre>"},{"location":"workflows/image_collections/#add-a-legend","title":"Add a legend","text":"<pre><code>// ---------------------------------------------------------------------\n//  Add a legend.\n// ---------------------------------------------------------------------\n\n//  Load cart module.\n\nvar cart = require('users/jhowarth/eePrimer:modules/cart.js');\n\n// Call makeGradientLegend function and pass three parameters.\n\nvar legend = cart                                           // module\n.makeGradientLegend(                                      // function\nviz,                                                    // viz parameters\n'degrees (C)',                                          // a label for legend\n'bottom-left'                                           // position on map\n)\n;\n\n// Add legend to map. \n\n// Map.add();\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"workflows/island-biogeography/","title":"Island Biogeography","text":""},{"location":"workflows/island-biogeography/#introduction","title":"Introduction","text":"<p>This tutorial introduces a general workflow to chart islands by area, distance, and recent geological history based on digital elevation models (DEM).  </p> <p>We use the California Channel Islands as a case to develop the model. Your script should produce a map like the one shown below. </p> <p> </p> <p>Link to app</p> <p>In addition, your script should produce a chart like the one shown below (but without the \u201cdemo\u201d tag). </p> <p></p>"},{"location":"workflows/island-biogeography/#define-key-terms","title":"Define key terms","text":"<pre><code>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n//  Title: wk10_island_biogeography.js \n//  Author: Jeff Howarth \n//  Date: Nov 15, 2023\n\n// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n//  Module\n\nvar palettes = require('users/gena/packages:palettes');\n\n//  Key variable\n\nvar ice_age_sea_level = -140;  // meters\n\n//  A. Wenner and D. Johnson, \"Land Vertebrates on the California Islands: \n//  Sweepstakes or Bridges?\" In The California Islands: Proceedings of a\n//  Multidisciplinary Symposium. Edited by D Power. SBMNH: Santa Barbara.\n//  1980: 497-530.\n</code></pre>"},{"location":"workflows/island-biogeography/#load-and-display-bathymetry","title":"Load and display bathymetry","text":"<pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n//  ACT 1: ICE\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n// --------------------------------------------------------------------\n//  1.1. Load and display bathymetry \n// --------------------------------------------------------------------\n\n//  Load image collection from \"projects/sat-io/open-datasets/gebco/gebco_grid\"\n//  Reduce collection to an image of median values.\n//  Clip the image by the study region.\n\nvar gebco_grid  ;\n\n//  Define viz parameters. \n\nvar bath_viz = {\nmin: -3000.0,\nmax: 3000.0,\npalette: palettes.colorbrewer.Blues[9].reverse(),\n};\n\n//  Set up map. \n\nMap.centerObject(geometry);\nMap.setOptions('satellite');\n\n//  Display as map layer. \n//  Apply viz parameters. \n//  Name the layer \"1.1. Bathymetry\".\n//  Display by default. \n</code></pre>"},{"location":"workflows/island-biogeography/#make-land-binary","title":"Make land binary","text":"<pre><code>// --------------------------------------------------------------------\n//  1.2. Make and display land binary for Pleistocene. \n// --------------------------------------------------------------------\n\n//  Make land binary for Pleistocene. \n//  Rename \"land\".\n\nvar land_pleistocene ;\n\n//  Display as map layer.\n//  Use \"#D3D3D3\" for palette. \n//  Name the layer \"1.2. Pleistocene Land\"\n</code></pre>"},{"location":"workflows/island-biogeography/#make-islands","title":"Make islands","text":"<pre><code>// --------------------------------------------------------------------\n//  1.3. Make and display Pleistocene islands. \n// --------------------------------------------------------------------\n\n//  Write a function to make islands from land binary. \n\nvar makeIslands ;\n\n//  Apply the function for Pleistocene land binary. \n\nvar islands_pleistocene ;\n\n//  Display as map layer. \n//  Name the layer \"1.3. Pleistocene islands\"\n</code></pre>"},{"location":"workflows/island-biogeography/#select-mainland","title":"Select mainland","text":"<pre><code>// --------------------------------------------------------------------\n//  1.4. Select Pleistocene mainland\n// --------------------------------------------------------------------\n\n//  Write a function to select mainland from \"islands\". \n\nvar selectMainland ;\n\n//  Apply the function for Pleistocene islands. \n\nvar mainland_target ;\n\n//  Display as map layer. \n//  Use color: \"Yellow\"\n//  Name the layer \"1.4. Mainland Pleistocene\"\n</code></pre>"},{"location":"workflows/island-biogeography/#find-minimum-distance","title":"Find minimum distance","text":"<pre><code>// --------------------------------------------------------------------\n//  1.5. Find minimum distance between each island and the mainland\n// --------------------------------------------------------------------\n\n//  Write a function to find the minimum distance from the mainland for an island.\n\nvar islandDistance ;\n\n//  Apply the function over all Pleistocene islands. \n//  Remove the mainland from the collection.\n\nvar distance_pleistocene ;\n\n//  CHECK 01: How many islands are in your final result for Act I? \n\nprint(\n\"CHECK 01\"\n);\n</code></pre>"},{"location":"workflows/island-biogeography/#act-ii-current-conditions","title":"Act II: Current conditions","text":"<pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n//  ACT 2: NOW\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n// --------------------------------------------------------------------\n//  2.1 Make land binary\n// --------------------------------------------------------------------\n\n// Load dataset \n\n// var dem = ee.Image('MERIT/DEM/v1_0_3')\n//     .clip(geometry)\n//     ;\n\n// Make land binary (use 1 m above sea level to define coasts)\n// Multiply binary by 2\n// Rename band \"land\"\n\nvar land_now ;\n\n// Add layer to map\n// Use \"#242E33\" for palette.\n// Name the map layer  \"2.1. Land Now\"\n\n\n\n// --------------------------------------------------------------------\n//  2.2 Create modern island objects\n// --------------------------------------------------------------------\n\n//  Make islands for current conditions\n//  Filter for islands where \"area_sq_km\" is greater than 0.1.\n\nvar islands_now ;\n\n// CHECK 2: How many island objects are in the collection?\n\n\n// Add layer to map.\n// Name the layer \"2.2. Islands Now objects\"\n\n\n// --------------------------------------------------------------------\n//  2.3. Distinguish mainland from islands\n// --------------------------------------------------------------------\n\n// Select the mainland from the current islands. \n\nvar mainland_target ;\n\n//  Display mainland on the map as a layer\n//  Use \"Yellow\" color.\n//  Name the layer \"2.3. Mainland Now\"\n\n\n\n// --------------------------------------------------------------------\n//  2.4. Find minimum distance between each island and the mainland\n// --------------------------------------------------------------------\n\n//  Calculate the distance of each island from the mainland.\n//  Remove the mainland from the collection. \n\nvar islands_distance ;\n\n//  CHECK 3: How many islands are in the collection?\n\n\n//  Display result as a map layer.\n//  Name the layer \"2.4. Islands with area and distance\"\n</code></pre>"},{"location":"workflows/island-biogeography/#identify-oceanic-islands","title":"Identify oceanic islands","text":"<pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n//  ACT 3: ACROSS TIMES\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n// --------------------------------------------------------------------\n//  3.1. Identify Oceanic Islands\n// --------------------------------------------------------------------\n\n//  Convert Pleistocene islands to image. \n\nvar pleistocene_islands_image ;\n\n//  Identify current islands that overlap pleistocene islands. \n\nvar now_and_then ;\n\n//  Isolate oceanic islands. \n\nvar islands_oceanic\n;\n</code></pre>"},{"location":"workflows/island-biogeography/#identify-and-tag-continental-islands","title":"Identify and tag continental islands","text":"<pre><code>// --------------------------------------------------------------------\n//  3.2. Identify and tag continental islands \n// --------------------------------------------------------------------\n\n//  Write a function to tag continental islands. \n\nvar tagContinental\n;\n\n// Create an continental islands feature collection and apply the function. \n\nvar islands_continental\n;\n</code></pre>"},{"location":"workflows/island-biogeography/#combine-islands-with-history-classes","title":"Combine islands with history classes","text":"<pre><code>// --------------------------------------------------------------------\n//  3.3. Combine islands with history classes. \n// --------------------------------------------------------------------\n\n//  Merge all the islands into a single collection.\n\nvar all_islands ;\n\n//  Display as map layer.\n//  Name layer \"3.3. Islands with history\"\n</code></pre>"},{"location":"workflows/island-biogeography/#make-area-distance-chart","title":"Make area-distance chart","text":"<pre><code>// --------------------------------------------------------------------\n//  3.4. Make area - distance chart\n// --------------------------------------------------------------------\n\n// Define the chart and print it to the console.\n\nvar chart = ui.Chart.feature.groups(\n{\nfeatures: all_islands.sort(\"land\"), xProperty: 'distance_km', yProperty: 'area_sq_km',\nseriesProperty: 'land'\n\n})\n.setChartType('ScatterChart')\n.setOptions(\n{\ntitle: 'Area vs Distance',\nhAxis: {\ntitle: 'km',\ntitleTextStyle: {italic: false, bold: true}\n},\nvAxis: {\ntitle: 'square km',\ntitleTextStyle: {italic: false, bold: true}\n},\npointSize: 10,\ncolors: ['#A8A422', \"#D3D3D3\", \"#227BA8\"],\nposition: 'bottom-left'\n\n}\n)\n\n;\n\nprint(chart);\n</code></pre>"},{"location":"workflows/island-biogeography/#make-a-highlighter-layer","title":"Make a highlighter layer","text":"<pre><code>// --------------------------------------------------------------------\n//  3.5. Highlight Islands\n// --------------------------------------------------------------------\n\n//  Define target properties\n\n// var target_property = \"area_sq_km\";\n// // var target_property = \"distance_km\";\n\n//  Define target value\n\nvar target_value = ee.Number(-9999);\n\n//  Make target layer.\n\nvar target ;\n\n//  Display as map layer. \n//  Use color \"Orchid\".\n//  Name the layer \"3.5. Selected Feature\"\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"workflows/landsat-wipe-map/","title":"Landsat Wipe Map","text":""},{"location":"workflows/landsat-wipe-map/#introduction","title":"Introduction","text":"<p>This tutorial introduces a general workflow to make a wipe map for exploring land cover changes with satellite imagery. We will use surface reflectance data from the Landsat 5 image collection to identify spring-time scenes with few clouds of Shanghai, China that are taken 25 years apart. We will then develop natural and false color composites to display the imagery and make a false color composite that aims to be more accessible to color blind map readers. Finally, we will display the two images with a wipe map to help people compare differences between the two time steps. Our final result should look and work like the map in the app below.      </p> <p> </p>"},{"location":"workflows/landsat-wipe-map/#start-a-new-script","title":"Start a new script","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  TITLE:      wk06_tutorial_rgb_composites.js\n//  AUTHOR:     your name\n//  DATE:       today's date\n//  PURPOSE:    A template for comparing color composites at two times.     \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n</code></pre>"},{"location":"workflows/landsat-wipe-map/#start-to-compose-a-map","title":"Start to compose a map","text":"<pre><code>// ---------------------------------------------------------------------\n//  Start a map.\n// ---------------------------------------------------------------------\n\n//  Define a point of interest (poi) on Shanghai.\n\nvar geometry = ee.Geometry.Point([121.46337, 31.221248]);\n\n//  Center map on geometry (poi) and zoom level 11.\n\n\n\n//  Set base map to satellite with labels (hybrid).\n</code></pre>"},{"location":"workflows/landsat-wipe-map/#load-l5-collection","title":"Load L5 collection","text":"<pre><code>// ---------------------------------------------------------------------\n//  Load Landsat 5 image collection.\n// ---------------------------------------------------------------------\n\n// Load L5 collection from this address: \"LANDSAT/LT05/C02/T1_L2\"\n\nvar ic ;\n</code></pre>"},{"location":"workflows/landsat-wipe-map/#work-out-processing-routine","title":"Work out processing routine","text":"<pre><code>// ---------------------------------------------------------------------\n//  Work out how to process the image collection.  \n// ---------------------------------------------------------------------\n\n// Go to the L5 page on EE Catalog and grab their script for scale factors.\n\n// Develop the processing workflow.  \n\nvar practice ;\n\n// Check your results. \n\nprint(\n\"Practice\"\n)\n;\n</code></pre>"},{"location":"workflows/landsat-wipe-map/#write-routine-as-a-function","title":"Write routine as a function","text":"<pre><code>// ---------------------------------------------------------------------\n//  Wrap up the workflow as a function.  \n// ---------------------------------------------------------------------\n\nvar makeImage ;\n\n// Apply function to make base image (April 1984).\n\nvar yr1984 ;\n</code></pre>"},{"location":"workflows/landsat-wipe-map/#check","title":"CHECK","text":"<pre><code>// ---------------------------------------------------------------------\n// CHECK\n// ---------------------------------------------------------------------\n\nvar check = require('users/jhowarth/eePrimer:modules/checks.js');\n\n// print(\n//   \"CHECK 01:\",\n//   yr1984.size(),\n//   \"CHECK 02:\",\n//   check.cu06(yr1984)\n//   )\n// ;\n</code></pre>"},{"location":"workflows/landsat-wipe-map/#stretch-enhancement-and-natural-color","title":"Stretch Enhancement and Natural Color","text":"<pre><code>// ---------------------------------------------------------------------\n//  Figure out stretch enhancement.  \n// ---------------------------------------------------------------------\n\n// Import image tools module.   \n\nvar tools = require('users/jhowarth/eePrimer:modules/image_tools.js');\n\n// Make a histogram to see data distribution.  \n\n// var histogram = tools.makeHistogram(\n//   yr1984.first(),               // Must be an image (not an image collection)\n//   \"SR_B3\",                      // Select one band at a time.\n//   30,                           // Pixel resolution of image.\n//   0,                            // Minimum value of x-axis\n//   0.5                           // Maximum value of x-axis.\n//   )\n// ;\n\n// Print, print, print...\n\n// print(\n//   \"Year 3\", \n//   yr1984,\n//   yr1984.first().bandNames(),\n//   histogram\n//   )\n// ;\n\n// Viz for natural color composite. \n\nvar nat_viz ;\n</code></pre>"},{"location":"workflows/landsat-wipe-map/#check_1","title":"CHECK","text":"<pre><code>// ---------------------------------------------------------------------\n// CHECK\n// ---------------------------------------------------------------------\n\n\nprint(\n\"CHECK 03:\",\nnat_viz.min[1]\n)\n;\n</code></pre>"},{"location":"workflows/landsat-wipe-map/#false-color","title":"False color","text":"<pre><code>// ---------------------------------------------------------------------\n// Make viz and display false color (on their own. \n// ---------------------------------------------------------------------\n\n// Use histograms to figure out viz parameters with good contrast for \n//  \"SR_B7\", \"SR_B4\", \"SR_B2\" in a 742 composite.\n\nvar false_viz ;\n\n// Display base year in false color. \n</code></pre>"},{"location":"workflows/landsat-wipe-map/#try-to-accommodate-color-blindness","title":"Try to accommodate color blindness","text":"<pre><code>// ---------------------------------------------------------------------\n// Try to accommodate color blindness. \n// ---------------------------------------------------------------------\n\n// Swap the G and B bands to avoid magenta and green.\n\nvar cb_viz ;\n\n// Add as map layer.\n</code></pre>"},{"location":"workflows/landsat-wipe-map/#check_2","title":"CHECK","text":"<pre><code>// ---------------------------------------------------------------------\n// CHECK\n// ---------------------------------------------------------------------\n\nprint(\n\"CHECK 04:\",\nfalse_viz.max[1],\n\"CHECK 05:\",\ncb_viz.max[1]\n)\n;\n</code></pre>"},{"location":"workflows/landsat-wipe-map/#explore-potential-time-2-layers","title":"Explore Potential Time 2 Layers","text":"<pre><code>// ---------------------------------------------------------------------\n//  Explore potential Time 2 layers  \n// ---------------------------------------------------------------------\n\n// How does 1994 look and work?\n\nvar yr1994 ;\n\n// Or 2004?\n\nvar yr2004 ;\n\n// Or 2009?\n\nvar yr2009 ;\n</code></pre>"},{"location":"workflows/landsat-wipe-map/#check_3","title":"CHECK","text":"<pre><code>// ---------------------------------------------------------------------\n// CHECK\n// ---------------------------------------------------------------------\n\n// print(\n//   \"CHECK 06:\",\n//   yr1994.size(),\n//   \"CHECK 07:\",\n//   check.cu06(yr1994),\n//   \"CHECK 08:\",\n//   yr2004.size(),\n//   \"CHECK 09:\",\n//   check.cu06(yr2004),\n//   \"CHECK 10:\",\n//   yr2009.size(),\n//   \"CHECK 11:\",\n//   check.cu06(yr2009)\n//   )\n// ;\n</code></pre>"},{"location":"workflows/landsat-wipe-map/#wipe-template","title":"Wipe template","text":"<pre><code>// -------------------------------------------------------------------------------\n// Wipe Template  \n// -------------------------------------------------------------------------------\n\n// Make another map and add a color-NIR composite to it.\n\nvar linkedMap = ui.Map();\n\n// Link the default Map to the other map.\n\nvar linker = ui.Map.Linker([ui.root.widgets().get(0), linkedMap]);\n\n// Create a SplitPanel which holds the linked maps side-by-side.\n\nvar splitPanel = ui.SplitPanel({\nfirstPanel: linker.get(0),\nsecondPanel: linker.get(1),\norientation: 'horizontal',\nwipe: true,\nstyle: {stretch: 'both'}\n});\n\n// Set the SplitPanel as the only thing in root.\n\nui.root.widgets().reset([splitPanel]);\n</code></pre>"},{"location":"workflows/landsat-wipe-map/#fix-the-linked-map","title":"Fix the linked map","text":"<pre><code>// -------------------------------------------------------------------------------\n//  Work out the linked map. \n// -------------------------------------------------------------------------------\n\n// Center the linked map.  \n\n\n\n// Recreate Time 2 image (if we commented it out). \n\n// var yr2009 = ;\n\n// Display Time 2 image as natural, false color, and accessible false color.   \n</code></pre>"},{"location":"workflows/landsat-wipe-map/#link-to-your-code","title":"Link to your code","text":"<p> Loading\u2026 <p></p> <p>If the embedded form does not work for you, here is a link.</p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"}]}